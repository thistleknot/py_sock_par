{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842ae64-4502-42d2-aeab-22d1cd96e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install clustergram pandas_profiling scipy sklearn statsmodels IPython dtale matplotlib rpy2 seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49edd-ccdb-4a5a-9ede-a9b3c081ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in ~/.bashrc\n",
    "#LD_PRELOAD=\"/mnt/distvol/R/4.1.2/lib64/R/lib/LibR.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96046e-bb6b-420f-b6b1-9524e60fe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fracdiff import fdiff\n",
    "#import urbangrammar-graphics as ugg\n",
    "%matplotlib inline\n",
    "import os\n",
    "from clustergram import Clustergram\n",
    "from concurrent.futures import ALL_COMPLETED\n",
    "from concurrent.futures import wait\n",
    "from dask.distributed import as_completed\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import Semaphore\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from numpy import absolute\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from pandas_profiling import ProfileReport\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from pmdarima.utils import diff_inv\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.rinterface_lib import openrlib\n",
    "from scipy import stats\n",
    "from scipy.cluster.vq import vq\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import *\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "from sklearn.utils import as_float_array\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import IPython\n",
    "import concurrent.futures\n",
    "import dask.dataframe as dd\n",
    "import datetime\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import pmdarima\n",
    "import pycorrelate\n",
    "import random\n",
    "import re\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.situation\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import shap\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "import sys\n",
    "import time\n",
    "if not sys.warnoptions:\n",
    "\timport warnings\n",
    "\twarnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a8c73-5c94-4d9a-bf1b-9ffbe6836975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = get_config()\n",
    "libpath = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = (\n",
    "    rpy2.situation.r_ld_library_path_from_subprocess(openrlib.R_HOME) +\n",
    "    libpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45c105-205f-4f2b-9526-b8373682df9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465a19f-5039-4627-8b7b-23d0b18f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001  \n",
    "    if p < alpha: \n",
    "        # null hypothesis: x comes from a normal distribution\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def returnYeo (x,training=False):\n",
    "    if(bool(training)):\n",
    "        xt, _ = stats.yeojohnson(x.loc[training])\n",
    "        xt = pd.DataFrame(xt)\n",
    "    else:\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        xt = pd.DataFrame(xt)        \n",
    "    return([xt,_])\n",
    "\n",
    "def regress(dd_df,numCV=2):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    print(\"y needs to be named 'target', regress only uses the variable names, it doesn't use index's.  You apply that using .fit on this functions return\")\n",
    "    #dd_df = data_final\n",
    "    variables=dd_df.columns\n",
    "    target = variables[0]\n",
    "    te = pd.DataFrame(dd_df['target']) \n",
    "    te.index = ([*dd_df.index])\n",
    "    #te.columns = ['target']\n",
    "    col_names = variables[~variables.isin(['target'])].ravel()\n",
    "\n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(col_names)*.05), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=1,\n",
    "              cv=numCV)\n",
    "\n",
    "    return (s_f_s)\n",
    "\n",
    "def last_day_of_month(date):\n",
    "    return date.replace(day=1) + relativedelta(months=1) - relativedelta(days=1)\n",
    "\n",
    "def findknee(xdata):\n",
    "    rate_of_change=(xdata[0]-xdata[-1])/(len(xdata)-1)\n",
    "    #print(rate_of_change)\n",
    "    delta = xdata-xdata[-1]\n",
    "    deltas = []\n",
    "    deltas.append(delta[0])\n",
    "    for d in range(1,len(xdata)):\n",
    "        deltas.append(deltas[d-1]-rate_of_change)\n",
    "    #print(deltas)\n",
    "    for d in range(0,len(xdata)):\n",
    "        deltas[d]=delta[d]-deltas[d]\n",
    "    return(np.abs(deltas))\n",
    "    \n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def formula_from_cols(df, y):\n",
    "    return y + ' ~ ' + ' + '.join([col for col in df.columns if not col==y])\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "#yeho\n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    if (len(data.columns)==1):\n",
    "        inner_scale, l = returnYeo(data)\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)        \n",
    "    else:\n",
    "        for i in range(0,len(data.columns)):\n",
    "            inner_scale, l = returnYeo(data.iloc[:,i])\n",
    "            inner_scale.set_index(data.index)\n",
    "\n",
    "            transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "            transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "\n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, regularization=1e-5, copy=False):\n",
    "      self.regularization = regularization\n",
    "      self.copy = copy\n",
    "  def fit(self, X, y=None):\n",
    "      X = as_float_array(X, copy=self.copy)\n",
    "      self.mean_ = np.mean(X, axis=0)\n",
    "      X = X - self.mean_\n",
    "      sigma = np.dot(X.T, X) / (X.shape[0] - 1)\n",
    "      U, S, V = np.linalg.svd(sigma)\n",
    "      tmp = np.dot(U, np.diag(1 / np.sqrt(S + self.regularization)))\n",
    "      self.components_ = np.dot(tmp, U.T)\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "      X_transformed = X - self.mean_\n",
    "      X_transformed = np.dot(X_transformed, self.components_.T)\n",
    "      return X_transformed\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "    \"\"\"\n",
    "    Cross correlation with a maximum number of lags.\n",
    "\n",
    "    `x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "    The return vaue has length 2*maxlag + 1.\n",
    "    \"\"\"\n",
    "    py = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "    T = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "                   strides=(-py.strides[0], py.strides[0]))\n",
    "    px = np.pad(x, maxlag, mode='constant')\n",
    "    if mode == 'dot':       # get lagged dot product\n",
    "        return T.dot(px)\n",
    "    elif mode == 'corr':    # gets Pearson correlation\n",
    "        return (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "               (np.std(T, axis=1) * np.std(px)) \n",
    "    \n",
    "def ret_ccf(npa_):\n",
    "    y_name = npa_[0]\n",
    "    x_name = npa_[1]\n",
    "    index = npa_[2]\n",
    "    \n",
    "    data = cleaned.loc[index].dropna()\n",
    "    \n",
    "    y = np.array(data.iloc[:,data.columns==y_name]).ravel()\n",
    "    \n",
    "    x = np.array(data.iloc[:,data.columns==x_name]).ravel()\n",
    "    #print(x)\n",
    "    #ccf = statsmodels.tsa.stattools.ccf(x,y)\n",
    "    ccf = crosscorrelation(x,y, ccf_max_lag, mode='corr')\n",
    "    #print(ccf)\n",
    "    return([y_name,x_name,ccf])\n",
    "\n",
    "def train(partition):\n",
    "    est = LinearRegression()\n",
    "    est.fit(partition[New_Names].values, partition['target'])\n",
    "    return est\n",
    "\n",
    "    '''\n",
    "    \n",
    "def nv_diff_sets(v_of_i,dataset,f_casts):\n",
    "\n",
    "  s_=sndif_[which(colnames(raw)==var_of_int)]\n",
    "  d_=ndif_[which(colnames(raw)==var_of_int)]\n",
    "  \n",
    "  startRow = c()\n",
    "  for (r in rownames(dataset[1:d_,,drop=FALSE])):\n",
    "    startRow = c(startRow,which(rownames(raw)==r))\n",
    "  \n",
    "  data_ = c(na.omit(c(dataset[,var_of_int], f_casts)))\n",
    "  \n",
    "  if(s_==0):\n",
    "    inv_d = diffinv(data_,differences=d_,xi=raw[startRow,var_of_int])\n",
    "  else:  \n",
    "    inv_d = diffinv(diffinv(data_,differences = d_, xi=raw[startRow,var_of_int]), differences = s_,xi=raw[startRow:(startRow+season-1),var_of_int])\n",
    "    \n",
    "  return(inv_d)\n",
    "'''\n",
    "#define F-test function\n",
    "def f_test(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    f = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic \n",
    "    dfn = x.size-1 #define degrees of freedom numerator \n",
    "    dfd = y.size-1 #define degrees of freedom denominator \n",
    "    p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic \n",
    "    return f, p\n",
    "\n",
    "def lagpad(x, k):\n",
    "    length=np.full(abs(k), np.NaN)\n",
    "    #print(length)\n",
    "    #k=k-1\n",
    "    if (k>0):\n",
    "        result = np.concatenate([length,x[0:(len(x)-k)]])\n",
    "    elif (k<0):\n",
    "        result= np.concatenate([(x[abs(k):(len(x))]),length])\n",
    "    else:\n",
    "        result= x\n",
    "    return(result)\n",
    "\n",
    "def lag(data):\n",
    "    return lagpad(data,1)\n",
    "\n",
    "def sndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[2]\n",
    "    #print(index)\n",
    "    data = raw_int[name].loc[index]\n",
    "    #print(data)\n",
    "    return([name,pmdarima.arima.nsdiffs(data.dropna(),m=npa_[1])])\n",
    "\n",
    "def ndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[1]\n",
    "    data = deseasoned[name].loc[index]\n",
    "\n",
    "    score = pmdarima.arima.ndiffs(data.dropna())\n",
    "    \n",
    "    if(score==0):\n",
    "        score = 1\n",
    "    return([name,score])\n",
    "\n",
    "def collect():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "def clientFunction(function_name,vars_):\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    future_ = client.map(function_name,vars_)\n",
    "    \n",
    "    results = []\n",
    "    #my intent was to capture future objects vs results and this gave me results\n",
    "    for f_ in as_completed(future_):\n",
    "        if(f_.status==\"error\"):\n",
    "            results.append(\"error\")\n",
    "        else:\n",
    "            results.append(f_.result()) \n",
    "\n",
    "    client.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "def returnElement(v):\n",
    "    return(v[0])\n",
    "\n",
    "def returnResults(v):\n",
    "    return(v[1])\n",
    "\n",
    "def restartClientFunction():\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    client.restart()\n",
    "    client.close()\n",
    "\n",
    "def ts_cv_split (dataset):\n",
    "    #rmse = []\n",
    "\n",
    "    both_ = []\n",
    "    #train_ = []\n",
    "    #test_ = []\n",
    "    for train_index, test_index in tscv.split(outer_dataset.index):\n",
    "        #train_.append(train_index)\n",
    "        #test_.append(test_index)\n",
    "        both_.append([train_index,test_index])    \n",
    "    return(both_)\n",
    "\n",
    "def return_ts_cv_data (indexes):\n",
    "    dataset=outer_dataset\n",
    "    #print(indexes[0])\n",
    "    return([dataset.iloc[indexes[0]],dataset.iloc[indexes[1]]])\n",
    "\n",
    "def cv_pcor_check (npa_):\n",
    "    \n",
    "    #data = npa_\n",
    "    n = npa_[2]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "    #print(npa_[0])\n",
    "    \n",
    "    #dataset= outer_dataset\n",
    "    #train_index = npa_[0]\n",
    "    #print(train_index)\n",
    "    #test_index = npa_[1]\n",
    "    \n",
    "    #I don't need it to do training/test splits, but I had advanced ideas that would apply linear models to a test partition and go with the best error reduction... \n",
    "    # but partial correlations are just that except they don't take into consideration training/test partitions\n",
    "\n",
    "    #target.iloc[training].iloc[train_index]\n",
    "    subset_train = npa_[0]#dataset.iloc[train_index]\n",
    "    train_index = subset_train.index\n",
    "    subset_train = subset_train.dropna()\n",
    "    subset_test = npa_[1]#dataset.iloc[test_index]\n",
    "    #return(subset_test)\n",
    "    test_index = subset_test.index\n",
    "    subset_test = subset_test.dropna()\n",
    "    \n",
    "    y_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train['target'])\n",
    "    y_fore_no_x = y_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    y_resid_no_x = y_fore_no_x.ravel()-subset_test['target']\n",
    "    \n",
    "    x_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train[n])\n",
    "    x_fore_no_x = x_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    x_resid_no_x = x_fore_no_x.ravel()-subset_test[n]\n",
    "    \n",
    "    cor_resid = pd.concat([pd.DataFrame(y_resid_no_x),pd.DataFrame(x_resid_no_x)],axis=1).corr()\n",
    "    #model_name = ols(formula_from_cols(subset, 'target'),data=data_final_dask_w_y[subset.columns].compute().iloc[train_index]).fit()\n",
    "    #print(model_name.summary())\n",
    "\n",
    "    #skip y and states\n",
    "    #set_ = subset.loc[:, ~subset.columns.isin([target])].columns.tolist()\n",
    "    \n",
    "    c_value = np.array(cor_resid).ravel()[1]\n",
    "    \n",
    "    return(c_value)\n",
    "\n",
    "#correlation p values\n",
    "def pvalues(n):\n",
    "    #n = New_Names[0]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "\n",
    "    p_values = pd.DataFrame()\n",
    "    #inner_c_values = []\n",
    "\n",
    "    #outer_dataset is derived from trainings\n",
    "    indexes = ts_cv_split(outer_dataset)\n",
    "    \n",
    "    data = clientFunction(return_ts_cv_data,indexes)\n",
    "    #print(data)\n",
    "    #print(data)\n",
    "    new_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        #print(d[0])\n",
    "        #print(d[1])\n",
    "        #print(n)\n",
    "        new_data.append([d[0],d[1],n])\n",
    "    #inner_c_values = []\n",
    "    #print(new_data[0][0])\n",
    "    #print(cv_pcor_check(new_data[0]))\n",
    "    #here test against holdout data is done\n",
    "    inner_c_values = clientFunction(cv_pcor_check,new_data)\n",
    "    print(inner_c_values)\n",
    "    #loops\n",
    "    \n",
    "    #for d in data:\n",
    "        #inner_c_values.append(cv_pcor_check(d))\n",
    "\n",
    "    n_ = len(indexes[1][0]) \n",
    "\n",
    "    dist = scipy.stats.beta(n_/2 - 1, n_/2 - 1, loc=-1, scale=2)\n",
    "    p_value = 2*dist.cdf(-abs(np.mean(inner_c_values)))\n",
    "    temp = pd.DataFrame([chosen,n,p_value]).T\n",
    "    temp.columns = ['target','test','p']\n",
    "\n",
    "    if(np.isnan(p_value)):\n",
    "        #print(n)\n",
    "        #print(inner_c_values)\n",
    "        p_value = 0\n",
    "    #p_values = pd.concat([p_values,temp],axis=0)\n",
    "    return(p_value)\n",
    "\n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "\n",
    "def undiff(data, seasonal, nonseasonal, xi):\n",
    "    \n",
    "    print(\"you have to know what xi for which use case you are going to use\")\n",
    "    \n",
    "    #nonseasonal\n",
    "    if(nonseasonal!=0 and seasonal==0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,1,nonseasonal)\n",
    "        return(temp_[-len(data):])\n",
    "        \n",
    "    #seasonal\n",
    "    if(seasonal!=0 and nonseasonal == 0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,season,1)\n",
    "        return(temp_[-len(data):])\n",
    "    \n",
    "    #both\n",
    "    if(seasonal==1 and nonseasonal == 1):\n",
    "        \n",
    "        '''\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        #print(temp)\n",
    "        temp_ = temp\n",
    "        \n",
    "        print(type(xi))\n",
    "        initial_non_seasonal_delta = xi.iloc[season+nonseasonal]-xi.iloc[season]\n",
    "        print(initial_non_seasonal_delta)\n",
    "        \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        #print(initial_seasonal_delta)\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(temp_)])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "        '''\n",
    "                #temp = data\n",
    "\n",
    "        temp_ = np.concatenate([np.array(xi),np.array(data)])\n",
    "        \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(data.dropna())])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "\n",
    "    #non seasonal\n",
    "    #undiff(temp_test['target'].dropna(), 0, nonseasonal,[raw_int[chosen].loc[temp_train['target'].index[-1]]])\n",
    "    #test\n",
    "    #undiff(temp_test[chosen],seasonal,nonseasonal,raw_int[chosen].loc[temp_train['target'].index[-1:]])\n",
    "    #train\n",
    "    #train_prior_date = raw_int[chosen].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal]\n",
    "    #train_xi=[raw_int[chosen].loc[train_prior_date]]\n",
    "    #undiff(temp_train['target'], seasonal, nonseasonal,xi)\n",
    "\n",
    "    #seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).dropna(),1,0,raw_int[chosen][0:season])\n",
    "\n",
    "    #non seasonal and seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).diff().dropna(),seasonal,nonseasonal,raw_int[chosen][0:season+nonseasonal])\n",
    "\n",
    "def difference(data, seasonal, nonseasonal):\n",
    "\n",
    "    if seasonal > 0:\n",
    "        return(data.diff(periods=season).diff(nonseasonal))\n",
    "    elif season > 0:\n",
    "        return(data.diff(nonseasonal))\n",
    "    else:\n",
    "        return(data)\n",
    "    \n",
    "'''\n",
    "def do_task_returnCCFs(x, sem):\n",
    "    with sem:\n",
    "        time.sleep(1)\n",
    "        return returnCCFs(x)\n",
    "'''\n",
    "    \n",
    "def returnCCFs(chosen):\n",
    "    #chosen = 'LXXRCSA'\n",
    "\n",
    "    ccf_ = []\n",
    "\n",
    "    npa = []\n",
    "\n",
    "    #chosen = cleaned.columns[random.randint(0,len(cleaned.columns)-1)]\n",
    "    #chosen = 'MSPUS'\n",
    "    #chosen = 'LXXRCSA'\n",
    "    \n",
    "    y_name = cleaned.columns[cleaned.columns==chosen].values[0]\n",
    "    #x_names = cleaned.columns[(cleaned.columns!=cleaned.columns[0])]\n",
    "    x_names = cleaned.columns\n",
    "\n",
    "    for s in range(0,len(cleaned.columns)):\n",
    "        #y_name = y_name_\n",
    "        x_name = x_names[s]\n",
    "        #print(x_name)\n",
    "        npa.append([y_name,x_name,training])\n",
    "\n",
    "    ccf_ = list(map(ret_ccf,npa))\n",
    "    #clientFunction(ret_ccf,npa)\n",
    "    \n",
    "    y_name = cleaned.columns[cleaned.columns==chosen].values[0]\n",
    "\n",
    "    x_names = cleaned.columns[cleaned.columns!=chosen]\n",
    "\n",
    "    y = np.array(cleaned.iloc[:,cleaned.columns==y_name]).ravel()\n",
    "    x = y\n",
    "    #last one is for comparing with itself to ensure 0 lag ccf is 1\n",
    "    #ccf_.append([y_name,y_name,crosscorrelation(x,y, ccf_max_lag, mode='corr')])\n",
    "    #ccf_.append([np.array([y_name,y_name]).reshape(2,1),crosscorrelation(x,y, 4, mode='corr')])#\n",
    "\n",
    "    range_ = [*range(-ccf_max_lag,ccf_max_lag+1)].copy()\n",
    "\n",
    "    ccf_scores = pd.DataFrame()\n",
    "\n",
    "    for c in ccf_:\n",
    "        y = c[0]\n",
    "        x = c[1]\n",
    "        ar_ = pd.DataFrame(c[2])\n",
    "        ar_.index = range_\n",
    "        ar_.columns = [x]\n",
    "        ccf_scores = pd.concat([ccf_scores,ar_],axis=1)\n",
    "\n",
    "    #derive optimally lagged dataset\n",
    "\n",
    "    data_final = pd.DataFrame()\n",
    "\n",
    "    best_lags = []\n",
    "    #don't want the last one because it's a repeat of chosen?  causes an error?\n",
    "    #for c in ccf_scores.columns[:-1]:\n",
    "    for c in ccf_scores.columns:\n",
    "        #print(c)\n",
    "        temp = ccf_scores[ccf_scores.index>0][c]\n",
    "        bl = ccf_scores.index[ccf_scores.index>0][np.argmax(abs(temp))]\n",
    "        best_lags.append(bl)\n",
    "        data = pd.DataFrame(lagpad(cleaned[c],bl))\n",
    "        data.index = cleaned[c].index\n",
    "        data.columns = [c]\n",
    "        data_final = pd.concat([data_final,data],axis=1)\n",
    "\n",
    "    #doesn't need to be shift, because all other values are offset by at least 1 lag\n",
    "    temp = pd.DataFrame(cleaned[chosen])\n",
    "    temp.columns = ['target']\n",
    "    data_final = pd.concat([temp,data_final],axis=1)\n",
    "\n",
    "    return([ccf_,data_final,ccf_scores, best_lags])\n",
    "\n",
    "def fit_sfs_models(CCF_package):\n",
    "\n",
    "    name = CCF_package[0][0][0]\n",
    "    #print(name)\n",
    "    data_final = CCF_package[1]\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[training].dropna()\n",
    "    temp_test = data_final.loc[testing].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    s_f_s = regress(temp_train)\n",
    "\n",
    "    target = temp_train.columns[0]\n",
    "    #.fit is X, y format\n",
    "    if not sys.warnoptions:\n",
    "        import warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        fitted = s_f_s.fit(temp_train.loc[:, ~temp_train.columns.isin(['target'])], pd.DataFrame(temp_train['target']))\n",
    "        \n",
    "    return([name,fitted])\n",
    "\n",
    "def getDataMetrics(CCF_package):\n",
    "\n",
    "    name = CCF_package[0][0][0]\n",
    "    #print(name)\n",
    "    data_final = CCF_package[1]\n",
    "    \n",
    "    if(str(CCF_package[0][0][2][0])=='nan'):\n",
    "        return([name,['error','error']])\n",
    "    else:\n",
    "\n",
    "        #print(data_final).describe()\n",
    "        #data_final = list(data_final)\n",
    "        #.compute().loc[training],training,testing\n",
    "        temp_train = data_final.loc[training].dropna()\n",
    "        temp_test = data_final.loc[testing].dropna()\n",
    "\n",
    "        #drop zero variance columns\n",
    "        drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "        temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "        #if p < .05, we reject the null hypothesis that the two populations have equal variance.\n",
    "        training_vs_holdout_f_test = f_test(temp_train['target'],temp_test['target'])\n",
    "\n",
    "        t_test = []\n",
    "        equal_var = False\n",
    "\n",
    "        if(training_vs_holdout_f_test[1]>.05):\n",
    "            equal_var = True\n",
    "            t_test.append(stats.ttest_ind(temp_train['target'],temp_test['target'],equal_var=True))\n",
    "        else:\n",
    "            t_test.append(stats.ttest_ind(temp_train['target'],temp_test['target'],equal_var=False))\n",
    "\n",
    "        equal_mean = False\n",
    "        #test if equal mean\n",
    "        if(t_test[0][1]>.05):\n",
    "            equal_mean = True\n",
    "\n",
    "        return([name,[equal_var,equal_mean]])\n",
    "\n",
    "def deriveWinners(npa_):\n",
    "    \n",
    "    CCF_package = npa_[1]\n",
    "    \n",
    "    name = CCF_package[0][0][0]\n",
    "\n",
    "    ccf_scores = CCF_package[2]\n",
    "    \n",
    "    models_results_ = npa_[0]\n",
    "\n",
    "    best_lags = CCF_package[3]\n",
    "    #print(best_lags)\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "\n",
    "    #model_pos = np.where(models_results_.index==name)[0][0]\n",
    "    #model_pos = np.where(np.array(models_results)==name)[0][0]\n",
    "\n",
    "    #print(name)\n",
    "    data_final = CCF_package[1]\n",
    "    \n",
    "    if(str(CCF_package[0][0][2][0])=='nan'):\n",
    "            return([name,'error'])    \n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[training].dropna()\n",
    "    temp_test = data_final.loc[testing].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    #return(name)\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    fitted = models_results_[0]\n",
    "\n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "\n",
    "    winners = metric_table[metric_table['avg_score']<(np.std(metric_table['avg_score'])+np.min(metric_table['avg_score']))].tail(1)['feature_names'].index\n",
    "    winners_ = np.asarray(fitted.get_metric_dict()[winners[0]]['feature_names'])\n",
    "\n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_ = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "\n",
    "    return([name,winners_])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ef083-5f57-410b-8c5a-0b476293b4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6b876-1953-4937-bc06-3c05123d53b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e958a51-c9e2-4aa4-a56a-fa7b21fef44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCV = 2\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "\n",
    "ccf_max_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a75df-bb32-49a6-9fb6-1275c50118bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8522fc-a4da-4a03-a113-ab647a07910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"all_data.csv\",index_col=0)\n",
    "raw.index = pd.to_datetime(raw.index)\n",
    "\n",
    "#fillna(method='bfill')\n",
    "raw_int = raw.interpolate(method='time').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f46ab1-885b-445b-aad6-d4216c46acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381b0b6-e08c-4b8e-ab95-f18116a375e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_test_split(raw_int.index, test_size=.33, random_state=0, shuffle=False)\n",
    "\n",
    "test_sets = []\n",
    "\n",
    "for i in indexes:\n",
    "    test_sets.append(raw_int.index.difference(i))\n",
    "    \n",
    "training = indexes[0]\n",
    "testing = indexes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31cb10-77cb-49e6-95fe-daf9070147a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539ddc5-f4d2-405a-b6b5-463192afa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta = (raw_int-raw_int.shift()).dropna()\n",
    "#raw_delta = (raw_int - raw_int.apply(lag,0)).dropna()\n",
    "#raw_delta.head()\n",
    "\n",
    "#raw_delta.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd80bd-da12-4330-bb5d-fa81b6a9eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3655-065a-4b5f-bf22-1f20181c718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0,len(raw_int.columns)):\n",
    "        \n",
    "#np.max(sndif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a754c9b-7e97-41d4-85be-74b8ea10e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95b5fa-44cc-4ea7-adb1-7f21bd8b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.diff().dropna().apply(pmdarima.arima.nsdiffs(m=4))\n",
    "\n",
    "sndif = []\n",
    "\n",
    "season = 4\n",
    "maxn = season\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],maxn,training])\n",
    "    \n",
    "sndif = clientFunction(sndif_,npa)\n",
    "\n",
    "results_sndif = pd.DataFrame(pd.DataFrame([item[1] for item in sndif])).set_index(item[0] for item in sndif)\n",
    "\n",
    "sndif_results = results_sndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ababf-02b0-4970-8b22-749ccc9fc087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72172de8-1877-4150-a2a5-d2c4176d5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sndif_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6555d44-61b8-4a1d-8243-7d90c20a91ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224b0db-c35f-4fd3-b689-f8c48f95ff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f04907-0899-47f3-b0ba-2b49ccd31f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76094108-7c4b-42a8-8165-2e392c6dc8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed4047-3025-4b11-87d3-4de4587550ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510867fd-2eaf-4ca6-b9e5-886d31f91af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fbb73-2973-4ca1-9d6f-e1dee5d9487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't preserve na's...\n",
    "#len(pmdarima.utils.diff(temp,1,1).ravel())\n",
    "\n",
    "deseasoned = pd.DataFrame()\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = sndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    if(compare*season == 0):\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "    else:\n",
    "        #print(compare)\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "        if(compare>0):\n",
    "            for d in range(0,compare):\n",
    "                temp = pd.DataFrame(temp.values.ravel()-lagpad(temp.values.ravel(),1*season)).set_index(temp.index)\n",
    "                temp.columns = raw_int.iloc[:,[i]].columns\n",
    "    deseasoned = pd.concat([deseasoned,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070ea74-f10c-44be-8afa-bcadf80835f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([pd.DataFrame(raw_int[names].columns),pd.DataFrame(raw_int.columns)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c31988-eb80-4626-acf7-b058904f7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f34f6d-9da4-460f-9f4b-ad79333d480b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f972-961c-4202-aae0-d6d9b3445422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_(npa[0])\n",
    "#sndif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee439e23-992e-4dce-8cad-524c2f95eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif = []\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],training])\n",
    "    \n",
    "ndif = clientFunction(ndif_,npa)    \n",
    "\n",
    "results_ndif = pd.DataFrame(pd.DataFrame([item[1] for item in ndif])).set_index(item[0] for item in ndif)\n",
    "\n",
    "ndif_results = results_ndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556689a-0f4e-4111-a5fa-30da2d1985da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaa60d-8804-4476-af02-bc5813637247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2455f-2517-4844-a92d-f0870c4ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876d330-9fc9-484b-8be9-562cebe91ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bbabb-94ff-47b2-8ee3-56fe70ff46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = ndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    temp_ = deseasoned[[raw_int.columns[i]]]\n",
    "    colnames = temp_.columns\n",
    "    if compare>0:\n",
    "        #print(ndif[i])\n",
    "        for d in range(0,compare):\n",
    "            #print(d)\n",
    "            #\n",
    "            #print(temp_.columns)\n",
    "            #temp_ = pd.DataFrame(temp_.values.ravel()-lagpad(temp_.values.ravel(),1)).set_index(temp_.index)\n",
    "            #temp_.columns = colnames\n",
    "            temp = temp_.diff()\n",
    "    temp.columns = temp_.columns\n",
    "    deseasoned_differenced = pd.concat([deseasoned_differenced,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0674d6d-026c-4d0f-bfb5-6d076165a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6874c8-c189-422d-8743-6d398590d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309a8f4-665b-473b-b35f-ceb1cbcb7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.interpolate(method='time').isna().sum().sum()\n",
    "#.fillna(method='bfill')\n",
    "#raw_int = raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7c307-5b10-4e14-936c-3665c4579e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfebf96-1bd9-41ed-855d-7ada55f8682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445377f0-481e-4147-8396-662f98b29fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "cleaned = deseasoned_differenced.interpolate(method='time')#.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc1b23-ea20-462b-a7eb-187202d5254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c28a1-d38f-4a76-a0e4-6867ccd7fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_csv(\"cleaned.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20c01-c2c8-40d6-9fbe-1e0f65b15b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b78028-85ae-436f-808c-1cddf0378cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f822cb-9735-4ddc-b9e9-59cb4cfd1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(skew).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844722f-c44b-4c74-9fa6-30e62bbce479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(kurtosis).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80396d-33c8-41b7-988c-23784d06bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(adfuller).iloc[1,].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec687a0-fe63-4c31-9c00-fd7fe14afe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc83c74-4729-4b1f-9fd4-6f1ec4f1ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415e0c7-f5dc-4f8d-a5d9-a2b5d7aa9078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8ab6-1c71-465c-8e78-cead6902b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_list = []\n",
    "\n",
    "for c in cleaned.columns:\n",
    "\n",
    "    normal_list.append(testNormal(cleaned[[c]].loc[training].dropna()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94dc80-0ed0-484e-b90b-60b80cf6832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76476328-04a1-42f1-a12b-1e9c748e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = pd.DataFrame()\n",
    "lambdas = []\n",
    "for c in range(0,len(cleaned.columns)):\n",
    "    if(normal_list[c]==1):\n",
    "\n",
    "        newData = pd.concat([newData,cleaned[cleaned.columns[c]]],axis=1)\n",
    "        lambdas.append(0)\n",
    "    else:\n",
    "        train_, l = transform_boxcox(cleaned[[cleaned.columns[c]]].loc[training].dropna())\n",
    "        train_.index = cleaned[[cleaned.columns[c]]].loc[training].dropna().index\n",
    "        test_ = transform_boxcox_l(cleaned[[cleaned.columns[c]]].loc[testing],l)   \n",
    "        \n",
    "        newData = pd.concat([newData,pd.concat([train_,test_])],axis=1)\n",
    "        lambdas.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ababa-7c07-4961-a4ff-57b4455ad8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#plt.plot(newData.dropna().iloc[:,102])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f551c10-3c73-4146-9dad-06d284671e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf510b6-1a26-4b71-a0fe-5930fc33a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv(\"newData.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85aaac8-a8e5-4eaf-987b-8d314cff6536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86f1b6-2583-4dfd-98a8-16e07cd6806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#%matplotlib inline\n",
    "#testNormal(cleaned.iloc[:,num]).dropna().plot.hist()\n",
    "#plt.show()\n",
    "#cleaned.iloc[:,num].dropna().plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c6968-d2c6-4ee8-9fb9-8e0521118c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a320-0a65-4655-a883-7979a533bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb0918-211c-4e91-96d2-ed65662ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are stationary?\n",
    "%matplotlib inline\n",
    "pd.DataFrame(cleaned.dropna().apply(adfuller).iloc[1,]).iloc[:,0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44357db8-49cd-4001-b834-7708f0b0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in cleaned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64a2b4-4999-44c7-a16a-022499effcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6f0e4-00b9-4d1f-a0d5-c96148ba8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.cumsum(x_names=='BOGZ1FL105015105Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10040ac7-710f-4822-ac65-dd624ea1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(cleaned.iloc[:,raw.columns=='BACDINA066MNFRBNY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f5bde-8c64-44d0-97c6-955504a29dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in cleaned.columns:\n",
    "    #print(y_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb03f9-0620-4717-aa8b-d42d540bac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cc7dd-2b41-45c8-8968-0570b4db0d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17870b03-f234-4f36-adb6-c072d3ff5f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3842ba-3b4a-4abb-ac5d-2a210de4d076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117df49-d347-468a-a616-8639af7cd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbab82-1828-4023-b9d3-d969a007ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af3d68-47a0-49b7-9d13-22e7af5708f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed004af-9d43-4dd1-87d9-3b80b81b076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "future = client.map(returnCCFs, cleaned.columns)\n",
    "\n",
    "CCFs = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "'''\n",
    "#for chosen in small_set:\n",
    "#    run_analysis(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb830e-ccfd-4206-abf2-5d35bae8abf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12160ac-7d89-477a-9d35-6360fcae1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(CCFs[113][0][0][2][0])=='nan'\n",
    "\n",
    "\n",
    "metrics = clientFunction(getDataMetrics,np.array(CCFs))\n",
    "\n",
    "data_metrics = pd.DataFrame([item[1] for item in metrics]).set_index([[item[0] for item in metrics]]).loc[raw_int.columns]\n",
    "data_metrics.columns = ['equal_var','equal_mean']\n",
    "'''\n",
    "metrics = []\n",
    "\n",
    "for a in range(0,len(CCFs)):\n",
    "    if(str(CCFs[a][0][0][2][0])=='nan'):\n",
    "        print(a)\n",
    "        print(raw_int.columns[a])\n",
    "        metrics.append('nan')\n",
    "    else:\n",
    "        metrics.append(getDataMetrics(np.array(CCFs)[a]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f87df-4385-4067-be9b-a4fa5cbbf932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1561-60ed-47cc-b13d-64fbded0713f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd6018-f934-4cfb-a4f5-3e44c2e972ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = np.where(cleaned.columns==chosen)\n",
    "#list(CCFs[pos[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1f770-1fe4-4482-a467-f125e366036f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a09c9d-7b90-4970-80e8-63ea3b53afca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161d336-6dcd-465f-86e5-d26a29a38cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_sfs_models(CCFs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4668ce3-caf9-4a13-9795-8088f967b9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708134a-fba0-4520-a906-551b18de0606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69099516-9fc4-4257-871d-4d155238a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch parallel\n",
    "\n",
    "r_s = []\n",
    "\n",
    "#queue size\n",
    "distance = 104\n",
    "\n",
    "for r_ in range(0, len(CCFs), distance):\n",
    "    r_s.append(r_)\n",
    "\n",
    "models_ = []\n",
    "\n",
    "for r in range(0,(len(r_s))):\n",
    "    \n",
    "    print(r_s[r])\n",
    "    print((r_s[r]+distance))\n",
    "    batchset = CCFs[r_s[r]:min(r_s[r]+distance,len(CCFs))]\n",
    "\n",
    "    client = Client('192.168.3.100:8786')\n",
    "    #clear ram before starting queue\n",
    "    client.restart()\n",
    "\n",
    "    future = clientFunction(fit_sfs_models, batchset)\n",
    "\n",
    "    for m in future:\n",
    "        models_.append(m)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "#nonbatch\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "future = client.map(fit_sfs_models, CCFs, batch_size=64)\n",
    "\n",
    "models_ = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f8173-6f05-438f-9540-c8efa77a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cad131-3bc7-4aea-b391-0119e7de6c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb6d78-cf31-4a12-b28e-f3c8058ec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([item[0] for item in models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312c98c-6b7d-46b9-aba1-d96839a57987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78009921-5472-4085-8e91-8b3e40263aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_models_ = pd.DataFrame([item[1] for item in models_])#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_models_.index = [item[0] for item in models_]\n",
    "\n",
    "models_results = results_models_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bd868-c8a1-4474-abc9-21a8bb279f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2b098-3bd4-496f-a9f4-52a34c4f27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df88414-e90c-44c8-baf9-3cd01687d778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0065-c6f1-4011-9cef-570729ca106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b4431-0885-483f-8dcd-c3b9d8385bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62f9d3-79ac-470d-8150-eceac3506248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7acd51-a0b1-48b1-b102-f5baffecff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#str(models_results.loc[models_results.index[113]].values)=='[nan]'\n",
    "'''\n",
    "start = 0\n",
    "for m in models_results.index:\n",
    "    start = start + 1\n",
    "    print(start)\n",
    "    #if(np.isnan(models_results.loc[m])):\n",
    "    #if(models_results.loc[m]):\n",
    "    print(models_results.loc[m])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71414428-917d-4757-ad2d-e4ab5b4092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_order = []\n",
    "for m in models_results:\n",
    "    if(m[1]=='error'):\n",
    "        print('do nothing')\n",
    "        #model_order.append('error')\n",
    "    else:\n",
    "        model_order.append(m[1])\n",
    "     \n",
    "#valid positions due to error (investigating showed large # of 0's in independent term).    \n",
    "pos = []\n",
    "for m in model_order:\n",
    "    if (m=='error'):\n",
    "        print('do nothing')\n",
    "    else:\n",
    "        pos.append(*np.where(np.array(cleaned.columns)==m)[0])\n",
    "        \n",
    "mask = np.ones(len(cleaned.columns), dtype=bool)\n",
    "mask[pos] = False\n",
    "\n",
    "failedresults = []\n",
    "for m in cleaned.columns[mask]:\n",
    "    failedresults.append(m)\n",
    "                \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa089ada-47d6-46fe-a6a7-c7bd635beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isnan(np.array(models_results)[113][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f8bca-b18f-4aa1-b33a-54f570d5d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models with errors\n",
    "\n",
    "problem_children = []\n",
    "\n",
    "for m in range(0,len(models_results.index)):\n",
    "    if(str(models_results.loc[models_results.index[m]].values)=='[nan]'):\n",
    "        problem_children.append(models_results.index[m])\n",
    "        \n",
    "        #print problematic models\n",
    "#plt.plot(raw_int.loc[:,['USREC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6e31-e8dc-4635-aadb-7e0e6f5f37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problem_children)\n",
    "#for p in problem_children:\n",
    "#    print(np.where(models_results.index==p)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a16f94-59f8-48a1-8837-e13ee3df164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoveredModels = []\n",
    "\n",
    "#check why\n",
    "'''\n",
    "for f in failedresults:\n",
    "    CCF_pos = np.where(np.array(cleaned.columns)==f)[0][0]\n",
    "    #CCFs[CCF_pos]\n",
    "    recoveredModels.append(fit_sfs_models(CCFs[CCF_pos]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370fd8e-ea5b-457d-951d-601e9b95671d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc629167-a16a-4add-9ff1-fa1bbcf6e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[c[0][0][0] for c in CCFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ee7f9-929e-47be-a8c1-28f9ebbf7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37145b4d-e1ef-4308-b9a5-eecd5578b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dd022-112a-4df6-bf15-82cb9e2d092a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b518132-fc03-4c4d-96a0-dd13a4ee57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380ee71-ce13-4068-acca-0518ad9c574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a4ee9-aeb3-4d06-9ebb-bf2a7aa17d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c374c-358b-4663-af29-84cdd6118a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for c in range(0,len(CCFs)):\n",
    "    npa.append([models_results.iloc[c],CCFs[c]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312414cd-da8f-46d3-8bb2-f556d4d0c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36f618-f6d4-4169-ae95-020c6c3b27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275fe2a-8d23-4eed-a7e9-64c5c09787f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cc210-f210-4975-8fba-0fbcd5c5d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_ = clientFunction(deriveWinners,npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711a43-eae4-46e3-9953-b002713df0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_\n",
    "\n",
    "\n",
    "results_winners_ = ([item[1] for item in winners_])#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_winners_index = [item[0] for item in winners_]\n",
    "\n",
    "#winners_results = results_winners_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989166e3-cf1d-4277-ba15-8799011f836e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd17564-5d2c-40ff-b888-e57373a932e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winner_ = \n",
    "#pd.DataFrame([item[1] for item in winner_s]).set_index([[item[0] for item in winner_]]).loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929194b-5575-45cd-a308-379a80be0cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378030e9-57b7-402b-b2bf-63178dfebc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_results = pd.DataFrame([results_winners_]).T\n",
    "winners_results.index = results_winners_index\n",
    "winners_results = winners_results.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e9903-a22e-40e1-92b8-b5704f5ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10893-9a8f-4790-b2d6-5b3130df0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c74aa-d6f8-4eb1-b5a9-a3792c6a557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def runModels(npa_):\n",
    "    \n",
    "    winners_ = npa_[0][0]\n",
    "    CCF_package = npa_[1][0]\n",
    "    nonseasonal = CCF_package = npa_[2]\n",
    "    seasonal = CCF_package = npa_[3]\n",
    "    \n",
    "    name = npa_[1][0][0][0]\n",
    "    \n",
    "    ccf_scores = npa_[1][2]\n",
    "    \n",
    "    best_lags = npa_[1][3]\n",
    "    #print(best_lags)\n",
    "    #print(best_lags)\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "    \n",
    "    model_pos = np.where(models_results.index==name)[0][0]\n",
    "    #model_pos = np.where(np.array(models_results)==name)[0][0]\n",
    "    \n",
    "    #print(name)\n",
    "    data_final = npa_[1][1]\n",
    "    \n",
    "    if(str(npa_[1][0][0][2][0])=='nan'):\n",
    "            return([name,['error','error'],'error','error','error','error'])        \n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[training].dropna()\n",
    "    temp_test = data_final.loc[testing].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    #return(name)\n",
    "    \n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "    \n",
    "    #fitted = models_results.loc[name][0]\n",
    "    #models_[model_pos][1]\n",
    "\n",
    "    #models = []\n",
    "    \n",
    "    #winners_ = model_winners[model_pos]\n",
    "\n",
    "    #return(winners_)\n",
    "    #return(len(temp_train[winners_]))\n",
    "    \n",
    "    #lagposition = []\n",
    "    lagatposition = []\n",
    "    lagatposition.append([name,0])\n",
    "    #print(len(winners_))\n",
    "    for s in range(0,len(winners_)):\n",
    "        print(winners_[s])\n",
    "        #lagposition.append(np.where(ccf_scores.columns==winners_[s])[0][0])\n",
    "        #print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        lagatposition.append([winners_[s],best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]]])\n",
    "\n",
    "    #return([lagposition,lagatposition])\n",
    "    \n",
    "    #print(temp_train)\n",
    "    #print(winners_)\n",
    "    #print(temp_train[winners_])\n",
    "    X = sm.add_constant(temp_train[winners_])\n",
    "    results = sm.OLS(temp_train['target'],X).fit()\n",
    "    #models.append(results)\n",
    "    model = results\n",
    "\n",
    "    #summaries = []\n",
    "\n",
    "    #summaries.append(results.summary())\n",
    "    \n",
    "    summary = results.summary()\n",
    "\n",
    "    #value = np.where(raw_int.columns==name)[0][0]\n",
    "\n",
    "    train_forecast = results.predict(temp_train[np.concatenate([['target'],winners_])])\n",
    "    test_forecast = results.predict(temp_test[np.concatenate([['target'],winners_])])\n",
    "\n",
    "    #MAPEs = []\n",
    "    MAPE_in_sample = MAPE(temp_train['target'],train_forecast)\n",
    "    MAPE_out_sample = MAPE(temp_test['target'],test_forecast)\n",
    "\n",
    "    #index_ = []\n",
    "    \n",
    "    inverses = []\n",
    "\n",
    "    inverses.append([name,sndif_results.loc[name][0],ndif_results.loc[name][0]])    \n",
    "\n",
    "    for w in winners_:\n",
    "        #value = np.where(raw_int.columns==w)[0][0]\n",
    "        #index_.append(value)\n",
    "        inverses.append([w,sndif_results.loc[w][0],ndif_results.loc[w][0]])\n",
    "        #print(sndif_results.loc[w][0])\n",
    "    #print(\"inverses\")\n",
    "    #print(inverses)        \n",
    "    '''\n",
    "    \n",
    "    #seasonal = inverses[0][1][1]\n",
    "    #nonseasonal = inverses[0][2][1]\n",
    "    \n",
    "    #print(season, seasonal, nonseasonal)\n",
    "\n",
    "    #print(raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0])])\n",
    "    \n",
    "    train_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    train_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    print(train_prior_date)\n",
    "    #print(train_prior_date_1)\n",
    "    train_xi=raw_int[name].loc[train_prior_date:train_prior_date_1]\n",
    "\n",
    "    undiffed_train = pd.DataFrame(undiff(temp_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "    undiffed_train_forecast = pd.DataFrame(undiff(train_forecast, seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "\n",
    "    test_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    test_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    test_xi = raw_int[name].loc[test_prior_date:test_prior_date_1]\n",
    "\n",
    "    #[raw_int[name].loc[temp_train['target'].index[-1]]]\n",
    "    undiffed_test_forecast = pd.DataFrame(undiff(test_forecast, seasonal, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "    undiffed_test = pd.DataFrame(undiff(temp_test['target'].dropna(), 0, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "    plt.plot(raw_int[name])\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_test],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train_forecast,undiffed_test_forecast],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_train_forecast],axis=1))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_test,undiffed_test_forecast],axis=1))\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi=raw_int[name].loc[prior_date:prior_date_1]\n",
    "\n",
    "    undiffed_ = pd.DataFrame(undiff(data_final['target'].dropna(), seasonal, nonseasonal, xi),columns=['target']).set_index(data_final['target'].dropna().index)\n",
    "\n",
    "    prior_date_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi_=raw_int[name].loc[prior_date_:prior_date_1_]\n",
    "\n",
    "    undiffed_forecast = pd.DataFrame(undiff(results.fittedvalues, seasonal, nonseasonal, xi_),columns=['target']).set_index(results.fittedvalues.index)\n",
    "\n",
    "    '''\n",
    "    return([name,[MAPE_in_sample,MAPE_out_sample],model,summary,lagatposition,inverses])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78e55037-21f5-449d-a6af-d44499515f43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815310d1-b261-4a4d-88e9-33da92a6428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for c in range(0,len(CCFs)):\n",
    "    #ndif_results.iloc[c],sndif_results.iloc[c]\n",
    "    npa.append([winners_results.iloc[c],CCFs[c],ndif_results.iloc[c],sndif_results.iloc[c]])\n",
    "    \n",
    "restartClientFunction()    \n",
    "ranModels = clientFunction(runModels,npa)\n",
    "restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0db97-3ceb-4599-8375-579685399dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_results.loc['MSPUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd72b01-7f97-4f7f-82fc-08ff7544bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runModels(npa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44641c-40ea-4d12-bdb5-2f95cb89d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranModels[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1bf74-a5bc-4e4e-bc49-0d15f1f6bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df235e65-1b44-4d54-bb38-1d05f4191457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranModels_ = pd.concat([pd.DataFrame(np.array([item[1] for item in ranModels])),pd.DataFrame(np.array([item[2] for item in ranModels])),pd.DataFrame(np.array([item[3] for item in ranModels])),pd.DataFrame(np.array([item[4] for item in ranModels])),pd.DataFrame(np.array([item[5] for item in ranModels]))],axis=1)\n",
    "\n",
    "ranModels_.index = [item[0] for item in ranModels]\n",
    "\n",
    "ranModels_.columns = ['in-sample-mape','out-sample-mape', 'in_model', 'summary','lags','seasonal_non']\n",
    "\n",
    "ranModels_ = ranModels_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc6fc0-8568-4754-8681-6b99d524f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c114f0a-bd44-4a20-8cc5-06799be05431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(ranModels_['out-sample-mape'].replace([np.inf, -np.inf], np.nan).dropna()=='error')\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0f15a-bfed-41b6-9f61-d3dc5ea6fd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b60bc9-0d1d-4967-bf20-8372dbcfa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ = ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2ad15-550f-4a79-b030-2be97f86374d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e82a4e-4cc6-4e94-933a-845c7e14b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "runningTotal = 0\n",
    "values = []\n",
    "for c in range(0,len(cleaned_)):\n",
    "    values.append(float(cleaned_.iloc[c]))\n",
    "    #print(runningTotal)\n",
    "   \n",
    "'''\n",
    "#print(runningTotal/len(cleaned_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7937-26b4-462b-8340-9cc2a1b09a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(values).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d1848-970c-435c-b11d-a230165fca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91ef2b-4a22-41a9-94a9-031e261aa225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702161dc-506e-4504-a771-3321bc0e8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned_[cleaned_!=\"error\"])\n",
    "#plt.show()\n",
    "#cleaned_ = cleaned_[cleaned_!=\"error\"]\n",
    "filters = cleaned_.quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "#cleaned_[(cleaned_<=filters.iloc[3]) * (cleaned_>=filters.iloc[1])].hist()\n",
    "#subset = cleaned_[(cleaned_<=filters.iloc[2])]\n",
    "cleaned_[(cleaned_<=filters.iloc[2])].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0cb65-7fb9-4540-96ca-a02f5bd5f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ranModels_results.dropna())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a67708-db59-4759-96e2-4a8528b5e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "decent_models = cleaned_[cleaned_<=filters.iloc[2]].dropna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c03b0-dad5-404f-9be7-c0b9fde65e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_results.loc[decent_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae111b61-ede2-4d78-8ae5-4b110bbfbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in decent_models:\n",
    "    #print(c)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92af28a-54e8-4242-a414-695bd8aead34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7242b51a-f6f5-4f45-bd9e-c2c52a9e2e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out-sample-mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASPUS</th>\n",
       "      <td>362937.656418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAA10Y</th>\n",
       "      <td>118.241946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACDINA066MNFRBNY</th>\n",
       "      <td>633.996626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACTSAMFRBDAL</th>\n",
       "      <td>885.648916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAMLC0A0CM</th>\n",
       "      <td>300.493620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XDOC</th>\n",
       "      <td>294.141068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLB</th>\n",
       "      <td>138.815136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLC</th>\n",
       "      <td>242.183811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLI</th>\n",
       "      <td>259.028880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLP</th>\n",
       "      <td>426.583128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   out-sample-mape\n",
       "ASPUS                362937.656418\n",
       "BAA10Y                  118.241946\n",
       "BACDINA066MNFRBNY       633.996626\n",
       "BACTSAMFRBDAL           885.648916\n",
       "BAMLC0A0CM              300.493620\n",
       "...                            ...\n",
       "XDOC                    294.141068\n",
       "XLB                     138.815136\n",
       "XLC                     242.183811\n",
       "XLI                     259.028880\n",
       "XLP                     426.583128\n",
       "\n",
       "[271 rows x 1 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49c296-b096-40b6-81fc-01502050c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "07c858bf-977f-4060-b4e9-6b3cf58d0f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSUSHPINSA\n",
      "in_sample R2:  0.8954251047440153\n",
      "in sample mape: 57.41329396311446\n",
      "out sample mape: 83.40834289841554\n",
      "lags: [['CSUSHPINSA', 0], ['CSUSHPINSA', 1], ['DFII10', 3], ['T5YIFR', 2]]\n",
      "seasonal: [['CSUSHPINSA', 1, 1], ['CSUSHPINSA', 1, 1], ['DFII10', 0, 1], ['T5YIFR', 0, 1]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.895\n",
      "Model:                            OLS   Adj. R-squared:                  0.880\n",
      "Method:                 Least Squares   F-statistic:                     57.08\n",
      "Date:                Fri, 14 Jan 2022   Prob (F-statistic):           5.51e-10\n",
      "Time:                        00:49:45   Log-Likelihood:                -21.427\n",
      "No. Observations:                  24   AIC:                             50.85\n",
      "Df Residuals:                      20   BIC:                             55.57\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0328      0.143      0.230      0.820      -0.265       0.330\n",
      "CSUSHPINSA     0.6524      0.075      8.663      0.000       0.495       0.810\n",
      "DFII10        -3.7334      0.497     -7.509      0.000      -4.771      -2.696\n",
      "T5YIFR        -2.6638      0.709     -3.757      0.001      -4.143      -1.185\n",
      "==============================================================================\n",
      "Omnibus:                        1.996   Durbin-Watson:                   2.341\n",
      "Prob(Omnibus):                  0.369   Jarque-Bera (JB):                0.728\n",
      "Skew:                           0.287   Prob(JB):                        0.695\n",
      "Kurtosis:                       3.632   Cond. No.                         10.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "CUSR0000SEHA\n",
      "in_sample R2:  0.8999216199491106\n",
      "in sample mape: 11.19649322757358\n",
      "out sample mape: 33.80237544415402\n",
      "lags: [['CUSR0000SEHA', 0], ['BOGZ1FA105015103Q', 2], ['CUSR0000SEHA', 1], ['ETOTALUSQ176N', 1], ['JSPRW', 1]]\n",
      "seasonal: [['CUSR0000SEHA', 0, 2], ['BOGZ1FA105015103Q', 0, 1], ['CUSR0000SEHA', 0, 2], ['ETOTALUSQ176N', 0, 1], ['JSPRW', 0, 1]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.900\n",
      "Model:                            OLS   Adj. R-squared:                  0.880\n",
      "Method:                 Least Squares   F-statistic:                     44.96\n",
      "Date:                Fri, 14 Jan 2022   Prob (F-statistic):           1.01e-09\n",
      "Time:                        00:49:45   Log-Likelihood:                 7.0572\n",
      "No. Observations:                  25   AIC:                            -4.114\n",
      "Df Residuals:                      20   BIC:                             1.980\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.1728      0.168      1.028      0.316      -0.178       0.523\n",
      "BOGZ1FA105015103Q -3.595e-07   1.27e-07     -2.823      0.011   -6.25e-07   -9.38e-08\n",
      "CUSR0000SEHA          0.3883      0.134      2.907      0.009       0.110       0.667\n",
      "ETOTALUSQ176N         0.0062      0.002      3.472      0.002       0.002       0.010\n",
      "JSPRW                 0.0680      0.046      1.479      0.155      -0.028       0.164\n",
      "==============================================================================\n",
      "Omnibus:                        0.618   Durbin-Watson:                   2.574\n",
      "Prob(Omnibus):                  0.734   Jarque-Bera (JB):                0.704\n",
      "Skew:                           0.273   Prob(JB):                        0.703\n",
      "Kurtosis:                       2.387   Cond. No.                     1.36e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.36e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "NROU\n",
      "in_sample R2:  0.9615779838827144\n",
      "in sample mape: 23.910046587781075\n",
      "out sample mape: 24.340716886249524\n",
      "lags: [['NROU', 0], ['CASTHPI', 4], ['NROU', 1], ['TDSP', 4]]\n",
      "seasonal: [['NROU', 0, 1], ['CASTHPI', 0, 2], ['NROU', 0, 1], ['TDSP', 0, 2]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.962\n",
      "Model:                            OLS   Adj. R-squared:                  0.956\n",
      "Method:                 Least Squares   F-statistic:                     175.2\n",
      "Date:                Fri, 14 Jan 2022   Prob (F-statistic):           5.11e-15\n",
      "Time:                        00:49:46   Log-Likelihood:                 171.86\n",
      "No. Observations:                  25   AIC:                            -335.7\n",
      "Df Residuals:                      21   BIC:                            -330.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0019      0.001     -3.335      0.003      -0.003      -0.001\n",
      "CASTHPI     3.256e-05   1.06e-05      3.060      0.006    1.04e-05    5.47e-05\n",
      "NROU           0.7805      0.064     12.191      0.000       0.647       0.914\n",
      "TDSP           0.0007      0.000      1.585      0.128      -0.000       0.002\n",
      "==============================================================================\n",
      "Omnibus:                        0.126   Durbin-Watson:                   0.781\n",
      "Prob(Omnibus):                  0.939   Jarque-Bera (JB):                0.025\n",
      "Skew:                          -0.021   Prob(JB):                        0.988\n",
      "Kurtosis:                       2.851   Cond. No.                     1.13e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "USPHCI\n",
      "in_sample R2:  0.7051214781126577\n",
      "in sample mape: 6.890883718948934\n",
      "out sample mape: 95.53667520126558\n",
      "lags: [['USPHCI', 0], ['IC4WSA', 2], ['USPHCI', 1]]\n",
      "seasonal: [['USPHCI', 0, 2], ['IC4WSA', 0, 1], ['USPHCI', 0, 2]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.705\n",
      "Model:                            OLS   Adj. R-squared:                  0.678\n",
      "Method:                 Least Squares   F-statistic:                     26.30\n",
      "Date:                Fri, 14 Jan 2022   Prob (F-statistic):           1.47e-06\n",
      "Time:                        00:49:43   Log-Likelihood:                 32.440\n",
      "No. Observations:                  25   AIC:                            -58.88\n",
      "Df Residuals:                      22   BIC:                            -55.22\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.3080      0.088      3.516      0.002       0.126       0.490\n",
      "IC4WSA      5.005e-06   1.48e-06      3.393      0.003    1.95e-06    8.06e-06\n",
      "USPHCI         0.6984      0.104      6.717      0.000       0.483       0.914\n",
      "==============================================================================\n",
      "Omnibus:                        6.635   Durbin-Watson:                   2.461\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                4.620\n",
      "Skew:                           0.968   Prob(JB):                       0.0992\n",
      "Kurtosis:                       3.829   Cond. No.                     1.23e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.23e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "CLR\n",
      "in_sample R2:  0.6213379345534038\n",
      "in sample mape: 57.158368378187554\n",
      "out sample mape: 96.91746106568789\n",
      "lags: [['CLR', 0], ['HDTGPDUSQ163N', 1], ['CRM', 1], ['FORG', 1]]\n",
      "seasonal: [['CLR', 0, 1], ['HDTGPDUSQ163N', 0, 1], ['CRM', 0, 1], ['FORG', 0, 1]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.621\n",
      "Model:                            OLS   Adj. R-squared:                  0.565\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Fri, 14 Jan 2022   Prob (F-statistic):           0.000182\n",
      "Time:                        00:49:43   Log-Likelihood:                -25.226\n",
      "No. Observations:                  24   AIC:                             58.45\n",
      "Df Residuals:                      20   BIC:                             63.16\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.3200      0.263      1.217      0.238      -0.229       0.869\n",
      "HDTGPDUSQ163N    -1.2222      0.302     -4.047      0.001      -1.852      -0.592\n",
      "CRM               0.6209      0.168      3.701      0.001       0.271       0.971\n",
      "FORG             -0.0993      0.101     -0.980      0.339      -0.311       0.112\n",
      "==============================================================================\n",
      "Omnibus:                        2.761   Durbin-Watson:                   1.965\n",
      "Prob(Omnibus):                  0.251   Jarque-Bera (JB):                1.953\n",
      "Skew:                           0.518   Prob(JB):                        0.377\n",
      "Kurtosis:                       2.061   Cond. No.                         5.40\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "for m in range(0,len(ranModels_.loc[decent_models])):\n",
    "    if(ranModels_.loc[decent_models].iloc[m][2].rsquared>.6):\n",
    "        print(decent_models[m])\n",
    "        print(\"in_sample R2: \", ranModels_.loc[decent_models].iloc[m][2].rsquared)\n",
    "        print(\"in sample mape:\",ranModels_.loc[decent_models].iloc[m][0])\n",
    "        print(\"out sample mape:\",ranModels_.loc[decent_models].iloc[m][1])\n",
    "        print(\"lags:\",ranModels_.loc[decent_models].iloc[m][4])\n",
    "        print(\"seasonal:\",ranModels_.loc[decent_models].iloc[m][5])\n",
    "        print(ranModels_.loc[decent_models].iloc[m][3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d0f36-2519-448d-8f17-0662fb890d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28034305-002f-498a-bff6-bb51a9ca0354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac0e15-ed83-4066-a895-1c41dcd207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now sorted by model return pos\n",
    "'''\n",
    "batchSet = np.array(CCFs)[pos]\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "client.restart()\n",
    "\n",
    "future = client.map(runModels, batchSet,batch_size=64)\n",
    "\n",
    "models_ran = client.gather(future)\n",
    "client.restart()\n",
    "client.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc598c3-4245-4c17-b901-c48bb61f1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2db4d5-b4de-4527-8a5a-6b9e59d2122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = temp_train[winners_]\n",
    "\n",
    "y_train = temp_train['target']\n",
    "\n",
    "kfold = KFold(n_splits=numCV, shuffle=True)\n",
    "\n",
    "#used for pcorr kfolds as well as best subsets\n",
    "train_ = []\n",
    "test_ = []\n",
    "\n",
    "kfold.get_n_splits(X_train.index)\n",
    "\n",
    "for train_indices, test_indices in kfold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n",
    "\n",
    "threshold = .05\n",
    "\n",
    "set_ = list(winners_)\n",
    "\n",
    "max_pvalue = 1\n",
    "\n",
    "subset = temp_train[np.concatenate([['target'],winners_])]\n",
    "\n",
    "n=len(subset)\n",
    "\n",
    "while(max_pvalue>=threshold):\n",
    "\n",
    "    dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "    p_values = pd.DataFrame(2*dist.cdf(-abs(subset.pcorr()['target']))).T\n",
    "    p_values.columns = list(subset.columns)\n",
    "\n",
    "    max_pname = p_values.idxmax(axis=1)[0]\n",
    "    max_pvalue = p_values[max_pname].values[0]\n",
    "\n",
    "    #print(max_pvalue, max_pname)\n",
    "\n",
    "    #to prevent errors, always return 1 value\n",
    "    if len(set_)==1:\n",
    "        break\n",
    "\n",
    "    if (max_pvalue > threshold):\n",
    "\n",
    "        set_.remove(max_pname)\n",
    "        temp = [target]\n",
    "        temp.extend(set_)\n",
    "        subset = subset[temp]\n",
    "\n",
    "        max_pname=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31693bd1-5256-45ee-8d2b-8175abe30528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015629e-d203-4586-b48f-35065094fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "small_set = random.sample(list(np.sort(cleaned.columns)),1)\n",
    "\n",
    "runs = []\n",
    "for chosen in small_set:\n",
    "    runs.append(run_analysis(chosen))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698e28f-3010-4e64-9edf-5f359aab2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen)\n",
    "\n",
    "#%matplotlib inline\n",
    "plt.plot(cleaned[chosen])\n",
    "plt.savefig(\"target.jpg\")\n",
    "plt.show()\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "print('chosen', chosen, 'training vs holdout f test for equal variance', training_vs_holdout_f_test[1])\n",
    "\n",
    "#CV Plot\n",
    "fig = plot_sfs(fitted.get_metric_dict(), kind='std_err')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.savefig(str(target)+'.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "#print(metric_table)\n",
    "plt.plot(metric_table['avg_score'])\n",
    "plt.savefig(str(target)+'metric.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "for w in range(0,len(winners_)):\n",
    "    print(winners_[w])\n",
    "    value = np.where(raw_int.columns==winners_[w])[0][0]\n",
    "    print(inverses[w])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==winners_[w])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "\n",
    "\n",
    "print(seasonal)\n",
    "print(nonseasonal)\n",
    "\n",
    "print(chosen,'Population', 'Equal mean:', equal_mean, ', ', 'Population', 'Equal variance:', equal_var)\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "value = np.where(raw_int.columns==chosen)[0][0]\n",
    "\n",
    "#print(\n",
    "print('sndif:', sndif[value])\n",
    "print('ndif:', ndif[value])\n",
    "\n",
    "for w in set_:\n",
    "    plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "    plt.show()        \n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n",
    "\n",
    "#for w in winners_:\n",
    "sn.set_theme(style=\"ticks\")\n",
    "\n",
    "t = temp_train[np.concatenate([['target'],winners_])]\n",
    "t_ = t[['target']]\n",
    "t_.columns = ['target2']\n",
    "#t_.rename('target2')\n",
    "t = pd.concat([t,t_],axis=1)\n",
    "sn.pairplot(t, hue=\"target\")\n",
    "#plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "for s in range(0,len(set_)):\n",
    "    print(np.where(ccf_scores.columns==set_[s])[0][0])\n",
    "\n",
    "print(MAPE(temp_test['target'],test_forecast))\n",
    "\n",
    "index_ = []\n",
    "\n",
    "for w in set_:\n",
    "    print(w)\n",
    "    value = np.where(raw_int.columns==w)[0][0]\n",
    "    index_.append(value)\n",
    "    inverses.append([w,sndif[value],ndif[value]])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==set_[s])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab30499-2191-4f82-b1ee-a2087973c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d08d6-1f0c-4447-be2d-a3a6b91a1fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e6ab6-e639-4dce-8db4-e29a2d729119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4440f99-f158-43d1-9108-6967fc0122aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77cb1-9235-4db8-ab3e-826f65c44330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0058905-36bc-476c-b52a-b8fde036eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ccf_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543fec-bd07-4bbf-b3d0-b1431bcba01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577961c-4929-4071-8f22-97381fead1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224de44f-3fc4-4630-85ac-622a7d8d3c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35a30-937e-4751-836a-8cf447037e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask = dd.from_pandas(data_final,npartitions=128)\n",
    "#data_final_dask_w_y = dd.concat([cleaned[[y_name]],data_final_dask.compute()],axis=1)\n",
    "#names_ = ['target']\n",
    "#names_.extend(cleaned.columns)\n",
    "#data_final_dask_w_y.columns = names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2b44-72f9-46b4-b3fc-a10c46fd0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask.apply(np.cumsum,axis=1).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce954cbf-4eca-4d46-a2af-afa25e3e88f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13186e-5615-44b8-8593-067501c7fcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2c216-e4cc-4ce5-aead-bcb283cd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c54e-9bd1-4012-b11a-6a28f1cc8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int[chosen])\n",
    "#plt.plot(cleaned[chosen])\n",
    "#plt.plot(data_final_dask_w_y[chosen].compute())\n",
    "#plt.plot(data_final_dask_w_y[['target']].compute().loc[training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2259a1-3d45-43b5-9f1a-4715ed7adf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sort(data_final_dask_w_y.compute().isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a92423-63d4-4d38-85ed-dc9e910eef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17484b9-be53-4ab5-ae8c-1b43b45e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "#pd.concat([target,zca1],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755a17-dfa2-479d-a3f9-d91134239c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fe348-072f-4814-a7c3-af7f24cf7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "newindex = []\n",
    "\n",
    "for i in range(0,len(temp_train.index)):\n",
    "    newindex.append(temp_train.index[i])\n",
    "\n",
    "for i in range(0,nonseasonal):\n",
    "    newindex.append(last_day_of_month(temp_train.index[-1] + pd.DateOffset(90*i)))\n",
    "    \n",
    "len(newindex)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa1c1d-2570-4358-9aae-d501ba283957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51702ec-ba0b-48f1-bdc5-6f22cae90e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "future = client.map(regress, X)\n",
    "\n",
    "results = []\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "    \n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df_.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0d63e-85ca-449b-8390-aeeecb71313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaler = StandardScaler()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "#scaler.fit(np.array(data_final_dask_w_y[['target']].compute().loc[training]).reshape(-1, 1))\n",
    "\n",
    "New_Names = list(data_final_dask_w_y.columns.difference(['target']))\n",
    "\n",
    "outer_dataset = data_final_dask_w_y.compute().loc[training].dropna()\n",
    "target = outer_dataset[['target']]\n",
    "\n",
    "subset = pd.concat([target,outer_dataset[New_Names]],axis=1)\n",
    "\n",
    "num_folds = 2\n",
    "#kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "#train, test = kfold.get_n_splits(outer_dataset.index)\n",
    "\n",
    "p_threshold = .05\n",
    "\n",
    "iteration = 0\n",
    "max_pvalue = 1\n",
    "\n",
    "while(max_pvalue>=.05):\n",
    "#\n",
    "    print(chosen)\n",
    "    \n",
    "    print(New_Names)\n",
    "    \n",
    "    n_p_values = pd.DataFrame()\n",
    "\n",
    "    p_values = []\n",
    "    \n",
    "    #parallelize here (x16)\n",
    "    for n in New_Names:\n",
    "        #print(n)\n",
    "        New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "        p_values.append(pvalues(n))\n",
    "        \n",
    "    p_values_df = pd.DataFrame(p_values,index=New_Names)\n",
    "    print(p_values_df)\n",
    "\n",
    "    max_pname = New_Names[np.argmax(p_values_df)]\n",
    "    max_pvalue = p_values[np.argmax(p_values_df)]\n",
    "\n",
    "    #n_p_values = pd.concat([n_p_values,p_values],axis=0)\n",
    "    #print(n_p_values)\n",
    "\n",
    "    if (max_pvalue > .05):\n",
    "        print([max_pname, max_pvalue])\n",
    "        #New_Names.remove(max_pname)\n",
    "        #New_Names_testing = list(np.array(New_Names_testing)[(np.array(New_Names_testing)!=max_pname)])\n",
    "        New_Names = list(np.array(New_Names)[(np.array(New_Names)!=max_pname)])\n",
    "        temp = ['target']\n",
    "        temp.extend(New_Names)\n",
    "        subset = subset[temp]\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40460a2a-3b85-4e98-a95e-792e089b57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c159e1b-117f-48fc-87f8-b402c6310ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_temp = data_final_dask_w_y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f421c1-f54c-4de0-a658-f83efe327bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset[New_Names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1eec-b1c3-4ec2-9c10-4cdd03192cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523b67a-6bd8-46a1-91e7-345d9fc2f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "includes = []\n",
    "for c in subset.columns:\n",
    "    index = np.argwhere(data_final_dask_w_y.columns==c)[0][0]\n",
    "    includes.append(index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12096a-43ea-4eff-aee9-1c47bb6230cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53efc9-e332-4828-b7b3-a8f3cf70118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = train(data_final_dask_w_y[subset.columns].compute().loc[training].dropna())\n",
    "#subset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f337a-3486-4c7e-b469-74ce5d877360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = regress(data_final_dask_w_y[subset.columns].compute().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abd359-b2e1-4af7-9a7d-8a3d17434be0",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
