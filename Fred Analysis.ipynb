{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842ae64-4502-42d2-aeab-22d1cd96e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install clustergram pandas_profiling scipy sklearn statsmodels IPython dtale matplotlib rpy2 seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49edd-ccdb-4a5a-9ede-a9b3c081ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in ~/.bashrc\n",
    "#LD_PRELOAD=\"/mnt/distvol/R/4.1.2/lib64/R/lib/LibR.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71528bb4-c906-457f-a87a-670a29bd8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skp\n",
    "import pingouin as pg\n",
    "from OLS_LR_DiagnosticPlots.ModelDiagnostics import Plot\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import scipy\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import datasets\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from IPython.display import display, clear_output\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96046e-bb6b-420f-b6b1-9524e60fe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fracdiff import fdiff\n",
    "#import urbangrammar-graphics as ugg\n",
    "%matplotlib inline\n",
    "import os\n",
    "from clustergram import Clustergram\n",
    "from concurrent.futures import ALL_COMPLETED\n",
    "from concurrent.futures import wait\n",
    "from dask.distributed import as_completed\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import Semaphore\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from numpy import absolute\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from pandas_profiling import ProfileReport\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.utils import diff_inv\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.rinterface_lib import openrlib\n",
    "from scipy import stats\n",
    "from scipy.cluster.vq import vq\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import *\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "from sklearn.utils import as_float_array\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA as ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import IPython\n",
    "import concurrent.futures\n",
    "import dask.dataframe as dd\n",
    "import datetime\n",
    "import dtale\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import pmdarima\n",
    "import pycorrelate\n",
    "import random\n",
    "import re\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.situation\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import shap\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "import sys\n",
    "import time\n",
    "if not sys.warnoptions:\n",
    "\timport warnings\n",
    "\twarnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a8c73-5c94-4d9a-bf1b-9ffbe6836975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = get_config()\n",
    "libpath = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = (\n",
    "    rpy2.situation.r_ld_library_path_from_subprocess(openrlib.R_HOME) +\n",
    "    libpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45c105-205f-4f2b-9526-b8373682df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def whiten(X, method='zca'):\n",
    "\t\t\"\"\"\n",
    "\t\tWhitens the input matrix X using specified whitening method.\n",
    "\t\tInputs:\n",
    "\t\t\tX:      Input data matrix with data examples along the first dimension\n",
    "\t\t\tmethod: Whitening method. Must be one of 'zca', 'zca_cor', 'pca',\n",
    "\t\t\t\t\t'pca_cor', or 'cholesky'.\n",
    "\t\t\"\"\"\n",
    "\t\tfluff = 1e-9\n",
    "\t\tX = X.reshape((-1, np.prod(X.shape[1:])))\n",
    "\t\tX_centered = X - np.mean(X, axis=0)\n",
    "\t\tSigma = np.dot(X_centered.T, X_centered) / X_centered.shape[0]\n",
    "\t\tW = None\n",
    "\t\tif method in ['zca', 'pca', 'cholesky']:\n",
    "\t\t\tU, Lambda, _ = np.linalg.svd(Sigma)\n",
    "\t\t\tif method == 'zca':\n",
    "\t\t\t\tW = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(Lambda + fluff)), U.T))\n",
    "\t\t\telif method =='pca':\n",
    "\t\t\t\tW = np.dot(np.diag(1.0 / np.sqrt(Lambda + fluff)), U.T)\n",
    "\t\t\telif method == 'cholesky':\n",
    "\t\t\t\tW = np.linalg.cholesky(np.dot(U, np.dot(np.diag(1.0 / (Lambda + fluff)), U.T))).T\n",
    "\t\telif method in ['zca_cor', 'pca_cor']:\n",
    "\t\t\tV_sqrt = np.diag(np.std(X, axis=0))\n",
    "\t\t\tP = np.dot(np.dot(np.linalg.inv(V_sqrt), Sigma), np.linalg.inv(V_sqrt))\n",
    "\t\t\tG, Theta, _ = np.linalg.svd(P)\n",
    "\t\t\tif method == 'zca_cor':\n",
    "\t\t\t\tW = np.dot(np.dot(G, np.dot(np.diag(1.0 / np.sqrt(Theta + fluff)), G.T)), np.linalg.inv(V_sqrt))\n",
    "\t\t\telif method == 'pca_cor':\n",
    "\t\t\t\tW = np.dot(np.dot(np.diag(1.0/np.sqrt(Theta + fluff)), G.T), np.linalg.inv(V_sqrt))\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Whitening method not found.')\n",
    "\t\treturn np.dot(X_centered, W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465a19f-5039-4627-8b7b-23d0b18f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001  \n",
    "    if p < alpha: \n",
    "        # null hypothesis: x comes from a normal distribution\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def returnYeo (x,training=False):\n",
    "    if(bool(training)):\n",
    "        xt, _ = stats.yeojohnson(x.loc[training])\n",
    "        xt = pd.DataFrame(xt)\n",
    "    else:\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        xt = pd.DataFrame(xt)        \n",
    "    return([xt,_])\n",
    "\n",
    "def regress(dd_df,numCV=2):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    print(\"y needs to be named 'target', regress only uses the variable names, it doesn't use index's.  You apply that using .fit on this functions return\")\n",
    "    #dd_df = data_final\n",
    "    variables=dd_df.columns\n",
    "    target = variables[0]\n",
    "    te = pd.DataFrame(dd_df['target']) \n",
    "    te.index = ([*dd_df.index])\n",
    "    #te.columns = ['target']\n",
    "    col_names = variables[~variables.isin(['target'])].ravel()\n",
    "\n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(col_names)*.05), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=1,\n",
    "              cv=numCV)\n",
    "\n",
    "    return (s_f_s)\n",
    "\n",
    "def last_day_of_month(date):\n",
    "    return date.replace(day=1) + relativedelta(months=1) - relativedelta(days=1)\n",
    "\n",
    "def findknee(xdata):\n",
    "    rate_of_change=(xdata[0]-xdata[-1])/(len(xdata)-1)\n",
    "    #print(rate_of_change)\n",
    "    delta = xdata-xdata[-1]\n",
    "    deltas = []\n",
    "    deltas.append(delta[0])\n",
    "    for d in range(1,len(xdata)):\n",
    "        deltas.append(deltas[d-1]-rate_of_change)\n",
    "    #print(deltas)\n",
    "    for d in range(0,len(xdata)):\n",
    "        deltas[d]=delta[d]-deltas[d]\n",
    "    return(np.abs(deltas))\n",
    "    \n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def formula_from_cols(df, y):\n",
    "    return y + ' ~ ' + ' + '.join([col for col in df.columns if not col==y])\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    if (len(data.columns)==1):\n",
    "        inner_scale, l = returnYeo(data)\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)        \n",
    "    else:\n",
    "        for i in range(0,len(data.columns)):\n",
    "            inner_scale, l = returnYeo(data.iloc[:,i])\n",
    "            inner_scale.set_index(data.index)\n",
    "\n",
    "            transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "            transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "\n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, regularization=1e-5, copy=False):\n",
    "      self.regularization = regularization\n",
    "      self.copy = copy\n",
    "  def fit(self, X, y=None):\n",
    "      X = as_float_array(X, copy=self.copy)\n",
    "      self.mean_ = np.mean(X, axis=0)\n",
    "      X = X - self.mean_\n",
    "      sigma = np.dot(X.T, X) / (X.shape[0] - 1)\n",
    "      U, S, V = np.linalg.svd(sigma)\n",
    "      tmp = np.dot(U, np.diag(1 / np.sqrt(S + self.regularization)))\n",
    "      self.components_ = np.dot(tmp, U.T)\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "      X_transformed = X - self.mean_\n",
    "      X_transformed = np.dot(X_transformed, self.components_.T)\n",
    "      return X_transformed\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "    \"\"\"\n",
    "    Cross correlation with a maximum number of lags.\n",
    "\n",
    "    `x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "    The return vaue has length 2*maxlag + 1.\n",
    "    \"\"\"\n",
    "    py = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "    T = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "                   strides=(-py.strides[0], py.strides[0]))\n",
    "    px = np.pad(x, maxlag, mode='constant')\n",
    "    if mode == 'dot':       # get lagged dot product\n",
    "        return T.dot(px)\n",
    "    elif mode == 'corr':    # gets Pearson correlation\n",
    "        return (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "               (np.std(T, axis=1) * np.std(px)) \n",
    "    \n",
    "def train(partition):\n",
    "    est = LinearRegression()\n",
    "    est.fit(partition[New_Names].values, partition['target'])\n",
    "    return est\n",
    "\n",
    "    '''\n",
    "    \n",
    "def nv_diff_sets(v_of_i,dataset,f_casts):\n",
    "\n",
    "  s_=sndif_[which(colnames(raw)==var_of_int)]\n",
    "  d_=ndif_[which(colnames(raw)==var_of_int)]\n",
    "  \n",
    "  startRow = c()\n",
    "  for (r in rownames(dataset[1:d_,,drop=FALSE])):\n",
    "    startRow = c(startRow,which(rownames(raw)==r))\n",
    "  \n",
    "  data_ = c(na.omit(c(dataset[,var_of_int], f_casts)))\n",
    "  \n",
    "  if(s_==0):\n",
    "    inv_d = diffinv(data_,differences=d_,xi=raw[startRow,var_of_int])\n",
    "  else:  \n",
    "    inv_d = diffinv(diffinv(data_,differences = d_, xi=raw[startRow,var_of_int]), differences = s_,xi=raw[startRow:(startRow+season-1),var_of_int])\n",
    "    \n",
    "  return(inv_d)\n",
    "'''\n",
    "#define F-test function\n",
    "def f_test(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    f = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic \n",
    "    dfn = x.size-1 #define degrees of freedom numerator \n",
    "    dfd = y.size-1 #define degrees of freedom denominator \n",
    "    p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic \n",
    "    return f, p\n",
    "\n",
    "def lagpad(x, k):\n",
    "    length=np.full(abs(k), np.NaN)\n",
    "    #print(length)\n",
    "    #k=k-1\n",
    "    if (k>0):\n",
    "        result = np.concatenate([length,x[0:(len(x)-k)]])\n",
    "    elif (k<0):\n",
    "        result= np.concatenate([(x[abs(k):(len(x))]),length])\n",
    "    else:\n",
    "        result= x\n",
    "    return(result)\n",
    "\n",
    "def lag(data):\n",
    "    return lagpad(data,1)\n",
    "\n",
    "def sndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[2]\n",
    "    #print(index)\n",
    "    data = raw_int[name].loc[index]\n",
    "    #print(data)\n",
    "    return([name,pmdarima.arima.nsdiffs(data.dropna(),m=npa_[1])])\n",
    "\n",
    "def ndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[1]\n",
    "    data = deseasoned[name].loc[index]\n",
    "\n",
    "    score = pmdarima.arima.ndiffs(data.dropna())\n",
    "    \n",
    "    if(score==0):\n",
    "        score = 1\n",
    "    return([name,score])\n",
    "\n",
    "def collect():\n",
    "    gc.collect()\n",
    "\n",
    "def clientFunction(function_name,vars_):\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    future_ = client.map(function_name,vars_,batch_size=64)\n",
    "    \n",
    "    results = []\n",
    "    #my intent was to capture future objects vs results and this gave me results\n",
    "    for f_ in as_completed(future_):\n",
    "        if(f_.status==\"error\"):\n",
    "            results.append(\"error\")\n",
    "        else:\n",
    "            results.append(f_.result()) \n",
    "\n",
    "    client.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "def returnElement(v):\n",
    "    return(v[0])\n",
    "\n",
    "def returnResults(v):\n",
    "    return(v[1])\n",
    "\n",
    "def restartClientFunction():\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    client.restart()\n",
    "    client.close()\n",
    "\n",
    "def ts_cv_split (dataset):\n",
    "    #rmse = []\n",
    "\n",
    "    both_ = []\n",
    "    #train_ = []\n",
    "    #test_ = []\n",
    "    for train_index, test_index in tscv.split(outer_dataset.index):\n",
    "        #train_.append(train_index)\n",
    "        #test_.append(test_index)\n",
    "        both_.append([train_index,test_index])    \n",
    "    return(both_)\n",
    "\n",
    "def return_ts_cv_data (indexes):\n",
    "    dataset=outer_dataset\n",
    "    #print(indexes[0])\n",
    "    return([dataset.iloc[indexes[0]],dataset.iloc[indexes[1]]])\n",
    "\n",
    "def cv_pcor_check (npa_):\n",
    "    \n",
    "    #data = npa_\n",
    "    n = npa_[2]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "    #print(npa_[0])\n",
    "    \n",
    "    #dataset= outer_dataset\n",
    "    #train_index = npa_[0]\n",
    "    #print(train_index)\n",
    "    #test_index = npa_[1]\n",
    "    \n",
    "    #I don't need it to do training/test splits, but I had advanced ideas that would apply linear models to a test partition and go with the best error reduction... \n",
    "    # but partial correlations are just that except they don't take into consideration training/test partitions\n",
    "\n",
    "    #target.iloc[training].iloc[train_index]\n",
    "    subset_train = npa_[0]#dataset.iloc[train_index]\n",
    "    train_index = subset_train.index\n",
    "    subset_train = subset_train.dropna()\n",
    "    subset_test = npa_[1]#dataset.iloc[test_index]\n",
    "    #return(subset_test)\n",
    "    test_index = subset_test.index\n",
    "    subset_test = subset_test.dropna()\n",
    "    \n",
    "    y_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train['target'])\n",
    "    y_fore_no_x = y_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    y_resid_no_x = y_fore_no_x.ravel()-subset_test['target']\n",
    "    \n",
    "    x_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train[n])\n",
    "    x_fore_no_x = x_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    x_resid_no_x = x_fore_no_x.ravel()-subset_test[n]\n",
    "    \n",
    "    cor_resid = pd.concat([pd.DataFrame(y_resid_no_x),pd.DataFrame(x_resid_no_x)],axis=1).corr()\n",
    "    #model_name = ols(formula_from_cols(subset, 'target'),data=data_final_dask_w_y[subset.columns].compute().iloc[train_index]).fit()\n",
    "    #print(model_name.summary())\n",
    "\n",
    "    #skip y and states\n",
    "    #set_ = subset.loc[:, ~subset.columns.isin([target])].columns.tolist()\n",
    "    \n",
    "    c_value = np.array(cor_resid).ravel()[1]\n",
    "    \n",
    "    return(c_value)\n",
    "\n",
    "#correlation p values\n",
    "def pvalues(n):\n",
    "    #n = New_Names[0]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "\n",
    "    p_values = pd.DataFrame()\n",
    "    #inner_c_values = []\n",
    "\n",
    "    #outer_dataset is derived from trainings\n",
    "    indexes = ts_cv_split(outer_dataset)\n",
    "    \n",
    "    data = clientFunction(return_ts_cv_data,indexes)\n",
    "    #print(data)\n",
    "    #print(data)\n",
    "    new_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        #print(d[0])\n",
    "        #print(d[1])\n",
    "        #print(n)\n",
    "        new_data.append([d[0],d[1],n])\n",
    "    #inner_c_values = []\n",
    "    #print(new_data[0][0])\n",
    "    #print(cv_pcor_check(new_data[0]))\n",
    "    #here test against holdout data is done\n",
    "    inner_c_values = clientFunction(cv_pcor_check,new_data)\n",
    "    print(inner_c_values)\n",
    "    #loops\n",
    "    \n",
    "    #for d in data:\n",
    "        #inner_c_values.append(cv_pcor_check(d))\n",
    "\n",
    "    n_ = len(indexes[1][0]) \n",
    "\n",
    "    dist = scipy.stats.beta(n_/2 - 1, n_/2 - 1, loc=-1, scale=2)\n",
    "    p_value = 2*dist.cdf(-abs(np.mean(inner_c_values)))\n",
    "    temp = pd.DataFrame([chosen,n,p_value]).T\n",
    "    temp.columns = ['target','test','p']\n",
    "\n",
    "    if(np.isnan(p_value)):\n",
    "        #print(n)\n",
    "        #print(inner_c_values)\n",
    "        p_value = 0\n",
    "    #p_values = pd.concat([p_values,temp],axis=0)\n",
    "    return(p_value)\n",
    "\n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "\n",
    "def undiff(data, seasonal, nonseasonal, xi):\n",
    "    \n",
    "    print(\"you have to know what xi for which use case you are going to use\")\n",
    "    \n",
    "    #nonseasonal\n",
    "    if(nonseasonal!=0 and seasonal==0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,1,nonseasonal)\n",
    "        return(temp_[-len(data):])\n",
    "        \n",
    "    #seasonal\n",
    "    if(seasonal!=0 and nonseasonal == 0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,season,1)\n",
    "        return(temp_[-len(data):])\n",
    "    \n",
    "    #both\n",
    "    #(for now force seasonal to 1)\n",
    "    if(seasonal==1 and nonseasonal == 1):\n",
    "        \n",
    "        '''\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        #print(temp)\n",
    "        temp_ = temp\n",
    "        \n",
    "        print(type(xi))\n",
    "        initial_non_seasonal_delta = xi.iloc[season+nonseasonal]-xi.iloc[season]\n",
    "        print(initial_non_seasonal_delta)\n",
    "        \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        #print(initial_seasonal_delta)\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(temp_)])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "        '''\n",
    "                #temp = data\n",
    "\n",
    "        temp_ = np.concatenate([np.array(xi),np.array(data)])\n",
    "        '''\n",
    "         for s in range(seasonal,0):\n",
    "\n",
    "            print(s)\n",
    "            initial_seasonal_delta = xi.iloc[season*s]-xi.iloc[0]\n",
    "            '''\n",
    "            \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(data.dropna())])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "\n",
    "    #non seasonal\n",
    "    #undiff(temp_test['target'].dropna(), 0, nonseasonal,[raw_int[chosen].loc[temp_train['target'].index[-1]]])\n",
    "    #test\n",
    "    #undiff(temp_test[chosen],seasonal,nonseasonal,raw_int[chosen].loc[temp_train['target'].index[-1:]])\n",
    "    #train\n",
    "    #train_prior_date = raw_int[chosen].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal]\n",
    "    #train_xi=[raw_int[chosen].loc[train_prior_date]]\n",
    "    #undiff(temp_train['target'], seasonal, nonseasonal,xi)\n",
    "\n",
    "    #seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).dropna(),1,0,raw_int[chosen][0:season])\n",
    "\n",
    "    #non seasonal and seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).diff().dropna(),seasonal,nonseasonal,raw_int[chosen][0:season+nonseasonal])\n",
    "\n",
    "def difference(data, seasonal, nonseasonal):\n",
    "\n",
    "    if seasonal > 0:\n",
    "        return(data.diff(periods=season).diff(nonseasonal))\n",
    "    elif season > 0:\n",
    "        return(data.diff(nonseasonal))\n",
    "    else:\n",
    "        return(data)\n",
    "    \n",
    "'''\n",
    "def do_task_returnCCFs(x, sem):\n",
    "    with sem:\n",
    "        time.sleep(1)\n",
    "        return returnCCFs(x)\n",
    "'''\n",
    "    \n",
    "def fit_sfs_models(npa_):\n",
    "    \n",
    "    #[CCF_names[c],CCF_data[c],CCF_scores[c],CCF_best_lags[c]]\n",
    "\n",
    "    name = npa_[0]\n",
    "    #print(name)\n",
    "    data_final = npa_[1]\n",
    "    train = npa_[2]\n",
    "    test = npa_[3]\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    s_f_s = regress(temp_train)\n",
    "\n",
    "    target = temp_train.columns[0]\n",
    "    #.fit is X, y format\n",
    "    if not sys.warnoptions:\n",
    "        import warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        fitted = s_f_s.fit(temp_train.loc[:, ~temp_train.columns.isin(['target'])], pd.DataFrame(temp_train['target']))\n",
    "        \n",
    "    return([name,fitted])\n",
    "\n",
    "#loads training, testing indexs from host\n",
    "def getDataMetrics(npa_):\n",
    "\n",
    "    name = npa_[0]\n",
    "    #print(name)\n",
    "    data_final = pd.DataFrame(npa_[1])\n",
    "    train = npa_[2]\n",
    "    test = npa_[3]\n",
    "    \n",
    "    #if(str(CCF_package[0][0][2][0])=='nan'):\n",
    "        #return([name,['error','error']])\n",
    "    #else:\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    #if p < .05, we reject the null hypothesis that the two populations have equal variance.\n",
    "    training_vs_holdout_f_test = f_test(temp_train,temp_test)\n",
    "\n",
    "    t_test = []\n",
    "    equal_var = False\n",
    "\n",
    "    if(training_vs_holdout_f_test[1]>.05):\n",
    "        equal_var = True\n",
    "        t_test.append(stats.ttest_ind(temp_train,temp_test,equal_var=True))\n",
    "    else:\n",
    "        t_test.append(stats.ttest_ind(temp_train,temp_test,equal_var=False))\n",
    "\n",
    "    equal_mean = False\n",
    "    #test if equal mean\n",
    "    if(t_test[0][1]>.05):\n",
    "        equal_mean = True\n",
    "        \n",
    "    train_norm = False\n",
    "    test_norm = False\n",
    "    if(testNormal(temp_train)):\n",
    "        train_norm=True\n",
    "        \n",
    "    if(testNormal(temp_test)):\n",
    "        test_norm = True\n",
    "\n",
    "    return([name,[equal_var,equal_mean,[train_norm,test_norm]]])\n",
    "\n",
    "def deriveWinners(npa_):\n",
    "    name = npa_[0]\n",
    "\n",
    "    data_final = npa_[1]\n",
    "\n",
    "    ccf_scores = npa_[2]\n",
    "\n",
    "    best_lags = npa_[3]\n",
    "\n",
    "    models_results_ = npa_[4]\n",
    "    \n",
    "    train = npa_[5]\n",
    "    test = npa_[6]\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "\n",
    "    #model_pos = np.where(models_results_.index==name)[0][0]\n",
    "    #model_pos = np.where(np.array(models_results)==name)[0][0]\n",
    "    \n",
    "    if(str(models_results_)=='nan'):\n",
    "            return([name,'error'])    \n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    #return(name)\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    fitted = models_results_[0]\n",
    "\n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "\n",
    "    winners = metric_table[metric_table['avg_score']<(np.std(metric_table['avg_score'])+np.min(metric_table['avg_score']))].tail(1)['feature_names'].index\n",
    "    winners_ = np.asarray(fitted.get_metric_dict()[winners[0]]['feature_names'])\n",
    "\n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_ = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "\n",
    "    return([name,winners_])\n",
    "\n",
    "def log_(x):\n",
    "    x_log = np.log(abs(x))*np.sign(x)\n",
    "    x_log[x.round(2)==0]=0\n",
    "    return(x_log)\n",
    "\n",
    "def unlog(x):\n",
    "    raised = 10 ** x.dropna().round(2)\n",
    "    raised[x.dropna().round(2)==0] = 0\n",
    "    return(raised)\n",
    "\n",
    "def ret_ccf(npa_):\n",
    "    #y_name = npa_[0]\n",
    "    y_name = npa_.columns[0]\n",
    "    x_name = npa_.columns[1]\n",
    "    #x_name = npa_[1]\n",
    "    #index = npa_[2]\n",
    "    index = npa_.index\n",
    "    \n",
    "    #data = cleaned.loc[index].dropna()\n",
    "    data = npa_.loc[index].dropna()\n",
    "    \n",
    "    y = np.array(data.iloc[:,data.columns==y_name]).ravel()\n",
    "    \n",
    "    x = np.array(data.iloc[:,data.columns==x_name]).ravel()\n",
    "    #print(x)\n",
    "    #ccf = statsmodels.tsa.stattools.ccf(x,y)\n",
    "    ccf = crosscorrelation(x,y, ccf_max_lag, mode='corr')\n",
    "    #print(ccf)\n",
    "    return([y_name,x_name,ccf])\n",
    "\n",
    "#uses cleaned (i.e. diffed) as data source \n",
    "def returnCCFs(npa_):\n",
    "    name = npa_[0]\n",
    "    input_data = npa_[1]\n",
    "    #print(input_data)\n",
    "    #chosen = 'LXXRCSA'\n",
    "\n",
    "    ccf_ = []\n",
    "\n",
    "    npa = []\n",
    "\n",
    "    #chosen = cleaned.columns[random.randint(0,len(cleaned.columns)-1)]\n",
    "    #chosen = 'MSPUS'\n",
    "    #chosen = 'LXXRCSA'\n",
    "    \n",
    "    #y_name = input_data.columns[input_data.columns==chosen].values[0]\n",
    "\n",
    "    #x_names = input_data.columns[input_data.columns!=chosen]\n",
    "    \n",
    "    y_name = input_data.columns[input_data.columns==name].values[0]\n",
    "    #x_names = cleaned.columns[(cleaned.columns!=cleaned.columns[0])]\n",
    "    x_names = input_data.columns\n",
    "    #print(x_names)\n",
    "\n",
    "    for s in range(0,len(x_names)):\n",
    "        #y_name = y_name_\n",
    "        x_name = x_names[s]\n",
    "        #print(x_name)\n",
    "        #npa.append([y_name,x_name,training])\n",
    "        #print([y_name,x_name])\n",
    "        npa.append(input_data[[y_name,x_name]])\n",
    "\n",
    "    ccf_ = list(map(ret_ccf,npa))\n",
    "    #clientFunction(ret_ccf,npa)\n",
    "    \n",
    "    #y = np.array(input_data.iloc[:,input_data.columns==y_name]).ravel()\n",
    "    #x = y\n",
    "    #last one is for comparing with itself to ensure 0 lag ccf is 1\n",
    "    #ccf_.append([y_name,y_name,crosscorrelation(x,y, ccf_max_lag, mode='corr')])\n",
    "    #ccf_.append([np.array([y_name,y_name]).reshape(2,1),crosscorrelation(x,y, 4, mode='corr')])#\n",
    "\n",
    "    range_ = [*range(-ccf_max_lag,ccf_max_lag+1)].copy()\n",
    "\n",
    "    ccf_scores = pd.DataFrame()\n",
    "\n",
    "    for c in ccf_:\n",
    "        y = c[0]\n",
    "        x = c[1]\n",
    "        ar_ = pd.DataFrame(c[2])\n",
    "        ar_.index = range_\n",
    "        ar_.columns = [x]\n",
    "        #print(y,x,[ccf_scores,ar_])\n",
    "        ccf_scores = pd.concat([ccf_scores,ar_],axis=1)\n",
    "\n",
    "    #derive optimally lagged dataset\n",
    "\n",
    "    data_final = pd.DataFrame()\n",
    "\n",
    "    best_lags = []\n",
    "    #don't want the last one because it's a repeat of chosen?  causes an error?\n",
    "    #for c in ccf_scores.columns[:-1]:\n",
    "    #run through ccf_scores (which are based on training) and apply to whole dataset\n",
    "    for c in ccf_scores.columns:\n",
    "        #print(c)\n",
    "        temp = ccf_scores[ccf_scores.index>0][c]\n",
    "        bl = ccf_scores.index[ccf_scores.index>0][np.argmax(abs(temp))]\n",
    "        best_lags.append(abs(bl))\n",
    "        data = pd.DataFrame(lagpad(cleaned[c],bl))\n",
    "        data.index = cleaned.index\n",
    "        data.columns = [c]\n",
    "        data_final = pd.concat([data_final,data],axis=1)\n",
    "\n",
    "    #doesn't need to be shift, because all other values are offset by at least 1 lag\n",
    "    temp = pd.DataFrame(cleaned[name])\n",
    "    temp.columns = ['target']\n",
    "    data_final = pd.concat([temp,data_final],axis=1)\n",
    "\n",
    "    return([name, data_final,ccf_scores, best_lags])\n",
    "    #return([name, ccf_,data_final,ccf_scores, best_lags])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9cba9-d56b-427b-9bb4-dd5cf0b67205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ef083-5f57-410b-8c5a-0b476293b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned['CSUSHPINSA'][training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6b876-1953-4937-bc06-3c05123d53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(lagpad(cleaned['T5YIFR'][training],2)).set_index(cleaned['T5YIFR'][training].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3a271-22ea-4418-aeb1-f7a61baa52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(raw_int.columns=='CSUSHPINSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8f442-3084-4c8d-b4e8-09ff479bf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62e042-4e51-48a6-86e1-3e054f6a8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emp = returnCCFs([raw_int.columns[np.where(raw_int.columns=='CSUSHPINSA')][0],cleaned.loc[training]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd5850-59d0-4226-8e9c-57a3e1071c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c692af-7715-4c1e-8bac-14c45a6b7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp[2]['CSUSHPINSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe68fc3-2e5d-4f8b-b715-a9f1755c7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(temp[1].columns)\n",
    "#['CSUSHPINSA'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18d71-3543-40ec-a30c-a23da921c220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b8239-aff7-41e3-a3d8-e4af4ac3d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fcbc9-b5dc-420b-a29e-2d36aebbb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e958a51-c9e2-4aa4-a56a-fa7b21fef44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCV = 2\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "\n",
    "ccf_max_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a75df-bb32-49a6-9fb6-1275c50118bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8522fc-a4da-4a03-a113-ab647a07910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"all_data.csv\",index_col=0)\n",
    "raw.index = pd.to_datetime(raw.index)\n",
    "\n",
    "#fillna(method='bfill')\n",
    "raw_int = raw.interpolate(method='time').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f46ab1-885b-445b-aad6-d4216c46acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381b0b6-e08c-4b8e-ab95-f18116a375e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_test_split(raw_int.index, test_size=.33, random_state=0, shuffle=False)\n",
    "\n",
    "test_sets = []\n",
    "\n",
    "for i in indexes:\n",
    "    test_sets.append(raw_int.index.difference(i))\n",
    "    \n",
    "training = indexes[0]\n",
    "testing = indexes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31cb10-77cb-49e6-95fe-daf9070147a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539ddc5-f4d2-405a-b6b5-463192afa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta = (raw_int-raw_int.shift()).dropna()\n",
    "#raw_delta = (raw_int - raw_int.apply(lag,0)).dropna()\n",
    "#raw_delta.head()\n",
    "\n",
    "#raw_delta.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd80bd-da12-4330-bb5d-fa81b6a9eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3655-065a-4b5f-bf22-1f20181c718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0,len(raw_int.columns)):\n",
    "        \n",
    "#np.max(sndif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a754c9b-7e97-41d4-85be-74b8ea10e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95b5fa-44cc-4ea7-adb1-7f21bd8b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.diff().dropna().apply(pmdarima.arima.nsdiffs(m=4))\n",
    "\n",
    "sndif = []\n",
    "\n",
    "season = 4\n",
    "maxn = season\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],maxn,training])\n",
    "    \n",
    "sndif = clientFunction(sndif_,npa)\n",
    "\n",
    "results_sndif = pd.DataFrame(pd.DataFrame([item[1] for item in sndif])).set_index(item[0] for item in sndif)\n",
    "\n",
    "sndif_results = results_sndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ababf-02b0-4970-8b22-749ccc9fc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sndif_results[sndif_results>1].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5a829-815c-4f59-a37c-30ba2f6f094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sndif_results.loc[sndif_results[sndif_results>1].dropna().index]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72172de8-1877-4150-a2a5-d2c4176d5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sndif_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6555d44-61b8-4a1d-8243-7d90c20a91ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224b0db-c35f-4fd3-b689-f8c48f95ff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f04907-0899-47f3-b0ba-2b49ccd31f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76094108-7c4b-42a8-8165-2e392c6dc8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed4047-3025-4b11-87d3-4de4587550ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510867fd-2eaf-4ca6-b9e5-886d31f91af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fbb73-2973-4ca1-9d6f-e1dee5d9487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't preserve na's...\n",
    "#len(pmdarima.utils.diff(temp,1,1).ravel())\n",
    "\n",
    "deseasoned = pd.DataFrame()\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = sndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    if(compare*season == 0):\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "    else:\n",
    "        #print(compare)\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "        if(compare>0):\n",
    "            for d in range(0,compare):\n",
    "                temp = pd.DataFrame(temp.values.ravel()-lagpad(temp.values.ravel(),1*season)).set_index(temp.index)\n",
    "                temp.columns = raw_int.iloc[:,[i]].columns\n",
    "    deseasoned = pd.concat([deseasoned,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070ea74-f10c-44be-8afa-bcadf80835f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([pd.DataFrame(raw_int[names].columns),pd.DataFrame(raw_int.columns)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c31988-eb80-4626-acf7-b058904f7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f34f6d-9da4-460f-9f4b-ad79333d480b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f972-961c-4202-aae0-d6d9b3445422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_(npa[0])\n",
    "#sndif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee439e23-992e-4dce-8cad-524c2f95eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif = []\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],training])\n",
    "    \n",
    "ndif = clientFunction(ndif_,npa)    \n",
    "\n",
    "results_ndif = pd.DataFrame(pd.DataFrame([item[1] for item in ndif])).set_index(item[0] for item in ndif)\n",
    "\n",
    "ndif_results = results_ndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556689a-0f4e-4111-a5fa-30da2d1985da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaa60d-8804-4476-af02-bc5813637247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2455f-2517-4844-a92d-f0870c4ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876d330-9fc9-484b-8be9-562cebe91ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bbabb-94ff-47b2-8ee3-56fe70ff46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = ndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    temp_ = deseasoned[[raw_int.columns[i]]]\n",
    "    colnames = temp_.columns\n",
    "    if compare>0:\n",
    "        #print(ndif[i])\n",
    "        for d in range(0,compare):\n",
    "            #print(d)\n",
    "            #\n",
    "            #print(temp_.columns)\n",
    "            #temp_ = pd.DataFrame(temp_.values.ravel()-lagpad(temp_.values.ravel(),1)).set_index(temp_.index)\n",
    "            #temp_.columns = colnames\n",
    "            #if(d==1):\n",
    "                #print(raw_int.columns[i])\n",
    "            temp_ = temp_.diff()\n",
    "    temp_.columns = deseasoned[[raw_int.columns[i]]].columns\n",
    "    deseasoned_differenced = pd.concat([deseasoned_differenced,temp_],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0674d6d-026c-4d0f-bfb5-6d076165a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6874c8-c189-422d-8743-6d398590d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309a8f4-665b-473b-b35f-ceb1cbcb7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.interpolate(method='time').isna().sum().sum()\n",
    "#.fillna(method='bfill')\n",
    "#raw_int = raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7c307-5b10-4e14-936c-3665c4579e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfebf96-1bd9-41ed-855d-7ada55f8682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40eced-b085-4283-a47d-ca42e2967734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445377f0-481e-4147-8396-662f98b29fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "cleaned = deseasoned_differenced.interpolate(method='time')#.dropna()\n",
    "\n",
    "#cleaned_log = log_(cleaned)#np.log(abs(cleaned))*np.sign(cleaned)\n",
    "#cleaned_log[cleaned.round(2)==0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50144f7-dad5-4eec-ad90-120093d16b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dff07-2cf2-456d-9684-ae29c9628487",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['ASPUS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa62b7e-72be-431f-bc75-b945481216cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(deseasoned_differenced.interpolate(method='time'),2)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc1b23-ea20-462b-a7eb-187202d5254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c28a1-d38f-4a76-a0e4-6867ccd7fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_log.to_csv(\"cleaned.csv\",index=True, index_label='Date')\n",
    "cleaned.to_csv(\"cleaned.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20c01-c2c8-40d6-9fbe-1e0f65b15b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned = cleaned_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b78028-85ae-436f-808c-1cddf0378cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f822cb-9735-4ddc-b9e9-59cb4cfd1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(skew).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844722f-c44b-4c74-9fa6-30e62bbce479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(kurtosis).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80396d-33c8-41b7-988c-23784d06bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(adfuller).iloc[1,].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec687a0-fe63-4c31-9c00-fd7fe14afe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc83c74-4729-4b1f-9fd4-6f1ec4f1ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415e0c7-f5dc-4f8d-a5d9-a2b5d7aa9078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8ab6-1c71-465c-8e78-cead6902b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_list = []\n",
    "\n",
    "for c in cleaned.columns:\n",
    "\n",
    "    normal_list.append(testNormal(cleaned[[c]].loc[training].dropna()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94dc80-0ed0-484e-b90b-60b80cf6832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76476328-04a1-42f1-a12b-1e9c748e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = pd.DataFrame()\n",
    "lambdas = []\n",
    "for c in range(0,len(cleaned.columns)):\n",
    "    if(normal_list[c]==1):\n",
    "\n",
    "        newData = pd.concat([newData,cleaned[cleaned.columns[c]]],axis=1)\n",
    "        lambdas.append(0)\n",
    "    else:\n",
    "        train_, l = transform_boxcox(cleaned[[cleaned.columns[c]]].loc[training].dropna())\n",
    "        train_.index = cleaned[[cleaned.columns[c]]].loc[training].dropna().index\n",
    "        test_ = transform_boxcox_l(cleaned[[cleaned.columns[c]]].loc[testing],l)   \n",
    "        \n",
    "        newData = pd.concat([newData,pd.concat([train_,test_])],axis=1)\n",
    "        lambdas.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ababa-7c07-4961-a4ff-57b4455ad8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#plt.plot(newData.dropna().iloc[:,102])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f551c10-3c73-4146-9dad-06d284671e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf510b6-1a26-4b71-a0fe-5930fc33a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv(\"newData.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85aaac8-a8e5-4eaf-987b-8d314cff6536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86f1b6-2583-4dfd-98a8-16e07cd6806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#%matplotlib inline\n",
    "#testNormal(cleaned.iloc[:,num]).dropna().plot.hist()\n",
    "#plt.show()\n",
    "#cleaned.iloc[:,num].dropna().plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c6968-d2c6-4ee8-9fb9-8e0521118c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a320-0a65-4655-a883-7979a533bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb0918-211c-4e91-96d2-ed65662ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are stationary?\n",
    "%matplotlib inline\n",
    "pd.DataFrame(cleaned.dropna().apply(adfuller).iloc[1,]).iloc[:,0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44357db8-49cd-4001-b834-7708f0b0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in cleaned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64a2b4-4999-44c7-a16a-022499effcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6f0e4-00b9-4d1f-a0d5-c96148ba8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.cumsum(x_names=='BOGZ1FL105015105Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10040ac7-710f-4822-ac65-dd624ea1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(cleaned.iloc[:,raw.columns=='BACDINA066MNFRBNY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f5bde-8c64-44d0-97c6-955504a29dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in cleaned.columns:\n",
    "    #print(y_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb03f9-0620-4717-aa8b-d42d540bac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cc7dd-2b41-45c8-8968-0570b4db0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndif_results.loc['NROU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17870b03-f234-4f36-adb6-c072d3ff5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_results.loc['NROU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3842ba-3b4a-4abb-ac5d-2a210de4d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int['NROU'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117df49-d347-468a-a616-8639af7cd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbab82-1828-4023-b9d3-d969a007ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af3d68-47a0-49b7-9d13-22e7af5708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "\n",
    "for c in raw_int.columns:\n",
    "    npa.append([c,cleaned.loc[training]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed004af-9d43-4dd1-87d9-3b80b81b076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "#in order\n",
    "future = client.map(returnCCFs, npa)\n",
    "\n",
    "CCFs_ = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "'''\n",
    "#for chosen in small_set:\n",
    "#    run_analysis(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5392e41-a93f-4e4b-b5d1-b64863cfc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#([name,data_final,ccf_scores, best_lags])\n",
    "#[item[4] for item in CCFs_][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96fdad-1d9b-414f-9792-c49cd4ee6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CCFs_data = pd.DataFrame([item[1] for item in CCFs_]).set_index([[item[0][0][0] for item in CCFs]])\n",
    "CCF_names = [item[0] for item in CCFs_]\n",
    "CCF_data = [item[1] for item in CCFs_]\n",
    "CCF_scores = [item[2] for item in CCFs_]\n",
    "CCF_best_lags = [item[3] for item in CCFs_]\n",
    "\n",
    "#CCFs.columns = ['equal_var','equal_mean']\n",
    "#.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a902ec-2260-4b3f-9b31-befba7512d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "26df420e-b8c4-49b8-ac01-2b6e2337ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_pos(y):\n",
    "    pos = np.where(np.array(CCF_names)==y)[0][0]\n",
    "    data = CCF_data[pos].dropna()\n",
    "    \n",
    "    names = data.columns\n",
    "   \n",
    "    #y = 'target'\n",
    "    #print(y)\n",
    "    x = np.array(names)[np.array(names)!='target']\n",
    "    data = data.loc[:, (data != data.iloc[0]).any()] \n",
    "    #print(data[['target',y]])\n",
    "    shap.initjs()\n",
    "    #return(pos)\n",
    "    \n",
    "    loop=True\n",
    "    \n",
    "    removes = []\n",
    "    #if(autoremove):\n",
    "    while(loop==True):\n",
    "\n",
    "        x_names = data.columns[~data.columns.isin([item for item in ['target',*removes]])]\n",
    "\n",
    "        #x_scores = data[[y,*x_names]].pcorr()[[y]]\n",
    "\n",
    "        x_scores = pd.concat([data['target'],pd.DataFrame((np.array(data[x_names])),columns=x_names).set_index(data.index)],axis=1).pcorr()[['target']]\n",
    "\n",
    "        #print(x_scores.loc[~x_scores.index.isin([y])])\n",
    "\n",
    "        #print(x_names)\n",
    "\n",
    "        index_set = data.index\n",
    "\n",
    "        test_results = x_scores\n",
    "\n",
    "        n = len(index_set)\n",
    "        df_ = n - 2\n",
    "\n",
    "        t=abs(test_results)*np.sqrt(df_)/np.sqrt(1-abs(test_results)**2)\n",
    "\n",
    "        test_results_least = t.iloc[[np.argmin(abs(t))]].index[0]\n",
    "\n",
    "        t_score_least = t.iloc[[np.argmin(abs(t))]]\n",
    "\n",
    "        crit_t = scipy.stats.t.ppf(1 - .05 / 2, df_)\n",
    "\n",
    "        if(np.isnan(t_score_least.values[0][0])):\n",
    "            remove = test_results_least\n",
    "            removes.append(remove)\n",
    "\n",
    "        if((t.loc[test_results_least]<crit_t)[0]):\n",
    "            remove = test_results_least\n",
    "            #print(remove,t_score_least.values[0][0])\n",
    "            removes.append(remove)\n",
    "\n",
    "        if((t.loc[test_results_least]>crit_t)[0]):\n",
    "            loop=False\n",
    "\n",
    "        if(len(x_names)==1):\n",
    "            loop=False\n",
    "    #else:\n",
    "        #x_names = data.columns[~data.columns.isin([item for item in [y,*removes]])]\n",
    "\n",
    "    #return(x_names)\n",
    "     \n",
    "    #regress(data)\n",
    "    data = data[['target',*x_names]]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    numCV = 10\n",
    "    \n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(data.columns)*.125), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=-1,\n",
    "              cv=numCV)\n",
    "\n",
    "    #data_w_inter_train= data_w_inter.loc[train]\n",
    "    #data_w_inter_test= data_w_inter.loc[test]\n",
    "    \n",
    "    fitted = s_f_s.fit(data.loc[:, ~data.columns.isin(['target'])], pd.DataFrame(data['target']))\n",
    "    \n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "    \n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_p = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "    \n",
    "    #print(winners_p)\n",
    "    \n",
    "    X = data[winners_p]\n",
    "   \n",
    "    X_ = pd.DataFrame((np.array(X)),columns=X.columns).set_index(X.index)\n",
    "    X_.index = X.index\n",
    "    X_.columns = X.columns\n",
    "    X = X_\n",
    "    #print(X)\n",
    "    #Y = scale(data.iloc[:,0], scale=True)\n",
    "    Y = pd.DataFrame(skp.scale(data['target'], with_mean=True, with_std=True))\n",
    "    Y.columns = ['target']\n",
    "    Y.index = data['target'].index\n",
    "    Y.sort_values(kind=\"quicksort\", by='target', ascending=True, inplace=True)\n",
    "    X = X.loc[Y.index]\n",
    "    \n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    \n",
    "    model.fit(X, Y)\n",
    "    model_ = sm.OLS(Y,X)\n",
    "    results = model_.fit()\n",
    "    #shap\n",
    "    background = np.array(X)\n",
    "    e = shap.LinearExplainer(model, X)\n",
    "    \n",
    "    shap_values = e.shap_values(np.array(X))\n",
    "    shap.summary_plot(shap_values, -np.array(X))\n",
    "    explainer = shap.Explainer(model, X)\n",
    "    shap.plots.heatmap(explainer(X))\n",
    " \n",
    "    predict = results.predict(X.loc[Y.index])\n",
    "    plt.plot(np.array(Y))\n",
    "    plt.plot(np.array(predict))\n",
    "    plt.show()\n",
    "    \n",
    "    corrMatrix = pd.concat([Y,X],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=True,key=abs)\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    corrMatrix = pd.concat([Y,X],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=True,key=abs)\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "    (predict-Y['target']).hist()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"mape:\",MAPE(Y['target'],predict))\n",
    "    \n",
    "    linear_plot = Plot.LinearRegressionResidualPlot(X.values, Y.values)\n",
    "    lm = linear_plot.fit()\n",
    "    summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "    #print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "    print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "    \n",
    "    temp = pd.concat([Y,X],axis=1)\n",
    "    #temp.index = data.loc[X.index]\n",
    "    #sns.pairplot(temp)\n",
    "    #return([results.summary(),temp])\n",
    "    return([results.summary()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e9b77b11-4cba-4953-98ff-81b662403c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e685e65b448fa9ea50a047d8187a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Select(description='y', options=('ASPUS', 'AWHAETP', 'BAA10Y', 'BACDINA066MNFRBNY', 'BAC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def derive_data(y):\n",
    "    return(return_model_vars(CCF_data[np.where(np.array(CCF_names)==y)[0][0]],y))\n",
    "\n",
    "y=widgets.Select(options=CCF_names,disabled=False)\n",
    "\n",
    "a=interact(derive_pos,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a8132-77c3-47bf-9248-589d7a839568",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def derive_pos(y):\n",
    "    return(np.where(np.array(CCF_names)==y)[0][0])\n",
    "\n",
    "y=widgets.Select(options=CCF_names,disabled=False)\n",
    "\n",
    "a=interact(derive_pos,y=y)\n",
    "\n",
    "\n",
    "def derive_names(y):\n",
    "    #CCF_data[CCF_data[np.where(np.array(CCF_names)==y)[0][0]]]\n",
    "    #data = CCF_data[np.where(np.array(CCF_names)==y)]\n",
    "    return(np.array([y,*np.array(CCF_names)[np.array(CCF_names)!=y]]))\n",
    "    #df = (sm.add_constant(df_)[[*df_.columns,'const']])\n",
    "\n",
    "y=widgets.Select(options=CCF_names,disabled=False)\n",
    "\n",
    "a=interact(derive_names,y=y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb830e-ccfd-4206-abf2-5d35bae8abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDataMetrics(CCFs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492690d6-cda1-4207-93cc-ae2c92032abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12160ac-7d89-477a-9d35-6360fcae1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(CCFs[113][0][0][2][0])=='nan'\n",
    "\n",
    "#I don't want to derive metrics on training data\n",
    "\n",
    "#pcor_test, pcor_zca\n",
    "indexes_ = train_test_split(cleaned.loc[training].dropna().index, test_size=.5, random_state=0, shuffle=False)\n",
    "\n",
    "npa = []\n",
    "\n",
    "for n in cleaned.columns:\n",
    "    name = n\n",
    "    data = cleaned[n]\n",
    "    train = indexes_[0]\n",
    "    test = indexes_[1]\n",
    "    npa.append([name,data,train,test])\n",
    "\n",
    "metrics = clientFunction(getDataMetrics,npa)\n",
    "\n",
    "'''\n",
    "metrics = []\n",
    "\n",
    "for a in range(0,len(CCFs)):\n",
    "    if(str(CCFs[a][0][0][2][0])=='nan'):\n",
    "        print(a)\n",
    "        print(raw_int.columns[a])\n",
    "        metrics.append('nan')\n",
    "    else:\n",
    "        metrics.append(getDataMetrics(np.array(CCFs)[a]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d365a-810b-410b-a2fc-3ba1dbeb50e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f87df-4385-4067-be9b-a4fa5cbbf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_metrics = pd.DataFrame([item[1] for item in metrics]).set_index([[item[0] for item in metrics]]).loc[raw_int.columns]\n",
    "data_metrics.columns = ['equal_var','equal_mean','normal_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1561-60ed-47cc-b13d-64fbded0713f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd6018-f934-4cfb-a4f5-3e44c2e972ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = np.where(cleaned.columns==chosen)\n",
    "#list(CCFs[pos[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1f770-1fe4-4482-a467-f125e366036f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a09c9d-7b90-4970-80e8-63ea3b53afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161d336-6dcd-465f-86e5-d26a29a38cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_sfs_models(CCFs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4668ce3-caf9-4a13-9795-8088f967b9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708134a-fba0-4520-a906-551b18de0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pd.concat([pd.DataFrame(cleaned['ASPUS']),pd.DataFrame(lagpad(cleaned['AWHAETP'],-1)).set_index(cleaned['AWHAETP'].index)],axis=1)\n",
    "'''\n",
    "len(training)\n",
    "len(temp.index)\n",
    "\n",
    "temp = pd.concat([pd.DataFrame(cleaned['ASPUS']),pd.DataFrame(lagpad(cleaned['AWHAETP'],0)).set_index(np.array(cleaned['AWHAETP'].index))],axis=1).dropna()\n",
    "temp = temp[(temp.iloc[:,1].index>=training[0])*(temp.iloc[:,1].index<=training[-1])]\n",
    "x = temp.iloc[:,1]\n",
    "y = temp.iloc[:,0]\n",
    "print(crosscorrelation(np.array(x),np.array(y), ccf_max_lag, mode='corr'))\n",
    "print(temp.corr())\n",
    "display(temp)\n",
    "'''\n",
    "\n",
    "#temp.loc[training].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045774ea-e4a4-4619-ae4c-535c5cc34769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbe647-6922-4274-9781-b76659ea0d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c0246-c14e-41f0-88da-b41f69aa1103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46de38a-b229-4526-8cd2-00d366f6aa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570539b-3694-4432-8e15-9a0b4d31ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcorr_test(npa_):\n",
    "    yname = npa_[0]\n",
    "    #print(yname)\n",
    "    xname = npa_[1]\n",
    "    data_final = npa_[2]\n",
    "    \n",
    "    index_ = npa_[3]\n",
    "    \n",
    "    x_names = data_final.columns[~data_final.columns.isin([yname])]\n",
    "\n",
    "    x_no_x_names = x_names[~x_names.isin([xname])]\n",
    "\n",
    "    train = index_[0]\n",
    "\n",
    "    test = index_[1]\n",
    "\n",
    "    data_train = data_final.loc[train].dropna()\n",
    "    data_test = data_final.loc[test].dropna()\n",
    "  \n",
    "    model_x = sm.OLS(data_train[[xname]],data_train[x_no_x_names])\n",
    "\n",
    "    model_y = sm.OLS(data_train[[yname]],data_train[x_names])\n",
    "    \n",
    "    model_x_fit = model_x.fit()\n",
    "    model_y_fit = model_y.fit()\n",
    "    \n",
    "    x_resid_test = model_x_fit.predict(data_test[x_no_x_names])-data_test[xname]\n",
    "    y_resid_test = model_y_fit.predict(data_test[x_names])-data_test[yname]\n",
    "\n",
    "    result = pd.concat([pd.DataFrame(x_resid_test),pd.DataFrame(y_resid_test)],axis=1).corr()\n",
    "\n",
    "    return [xname,np.array(result)[0][1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098bd51-1b2f-4f46-9f3a-e7124ff43f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned.pcorr().round(2)[['ASPUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937547df-c93a-47bb-9e36-9fa826d7798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a0b63-892c-40c6-9fa7-dd7257456930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33a3cb-4e99-4e04-9fdb-d88c996d4a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f86b53-4380-4216-b9be-1550f9e72df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2571ff2-1ff3-4610-970c-7fa720ae78b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb986c3-f83e-4d88-a4fd-ddb8cd2c2c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4951c9-12ca-4886-b2f4-6a35f2d8f5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc472b-a793-42e6-964f-f70b01b5292f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358de53d-81db-48cd-9815-5a337f879619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_ = pd.DataFrame(results_).set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9804bdf-4b2d-4e2c-90bc-7e1646c4bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_s = train_test_split(training, test_size=.33, random_state=0, shuffle=False)\n",
    "\n",
    "test_sets_s = []\n",
    "\n",
    "#for i in indexes:\n",
    "    #test_sets.append(raw_int.index.difference(i))\n",
    "    \n",
    "training_ = indexes_s[0]\n",
    "testing_ = indexes_s[1]\n",
    "\n",
    "npa = []\n",
    "for n in range(0,len(CCF_data)):\n",
    "    npa.append(['target',CCF_names[n],CCF_data[n],[training_,testing_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06130dd-e1f4-4d6d-9ae7-66507939df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "npa_1 = []\n",
    "\n",
    "for r in npa[0][2].columns[~npa[0][2].columns.isin(['target'])]:\n",
    "    npa_1.append(['target',r,npa[0][2],[training_,testing_]])\n",
    "    #print(r)\n",
    "\n",
    "results_ = clientFunction(pcorr_test,npa_1)\n",
    "results_ = pd.DataFrame(results_).set_index(item[0] for item in results_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29703df-26ae-4dfb-aefe-1e290ff90d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clientFunction(pcorr_test,npa)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77f85f-d8c4-46aa-97cf-1b939f390016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b58a9-9208-4f9a-8c80-27a2c857a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcorr_zca(npa_):\n",
    "    yname = npa_[0]\n",
    "    #print(yname)\n",
    "    xname = npa_[1]\n",
    "    data_final = npa_[2]\n",
    "    \n",
    "    index_ = npa_[3]    \n",
    "    #yname = 'target'\n",
    "    #name = npa_[0]\n",
    "    #data_final = npa_[2]\n",
    "    \n",
    "    data_final = data_final.loc[:, (data_final != data_final.iloc[0]).any()] \n",
    "  \n",
    "    index_set = data_final.dropna().index\n",
    "\n",
    "    indexes_s = train_test_split(index_set, test_size=.33, random_state=0, shuffle=False)\n",
    "    \n",
    "    test_sets_s = []\n",
    "\n",
    "    #for i in indexes:\n",
    "        #test_sets.append(raw_int.index.difference(i))\n",
    "\n",
    "    training_ = indexes_s[0]\n",
    "    testing_ = indexes_s[1]\n",
    "    \n",
    "    loop=True\n",
    "    \n",
    "    removes = []\n",
    "    \n",
    "    while(loop==True):\n",
    "\n",
    "        x_names = data_final.columns[~data_final.columns.isin([item for item in [yname,*removes]])]\n",
    " \n",
    "        npa_1 = []\n",
    "\n",
    "        for r in npa_[2].columns[~npa_[2].columns.isin(['target'])]:\n",
    "            npa_1.append(['target',r,npa_[2],[training_,testing_]])\n",
    "            #print(r)\n",
    "\n",
    "        results_ = clientFunction(pcorr_test,npa_1)\n",
    "        \n",
    "        x_scores_df = pd.DataFrame(results_).set_index(item[0] for item in results_)\n",
    "        '''\n",
    "        x_scores_df = data_final[[yname,*x_names]].pcorr().round(3)[['target']].replace([np.inf,'inf','error', -np.inf], 1)\n",
    "        '''\n",
    "    \n",
    "        x_scores_df = x_scores_df.loc[~x_scores_df.index.isin(['target'])]\n",
    "        \n",
    "        test_results = x_scores_df\n",
    " \n",
    "        \n",
    "        n = len(index_set)\n",
    "        df = n - 2\n",
    "        \n",
    "        t=abs(test_results)*np.sqrt(df)/np.sqrt(1-abs(test_results)**2)\n",
    "\n",
    "        test_results_least = t.iloc[[np.argmin(abs(t))]].index[0]\n",
    "\n",
    "        t_score_least = t.iloc[[np.argmin(abs(t))]]\n",
    "\n",
    "        crit_t = scipy.stats.t.ppf(1 - .05 / 2, df)\n",
    "        \n",
    "        if(np.isnan(t_score_least.values[0][0])):\n",
    "            remove = test_results_least\n",
    "            removes.append(remove)\n",
    "            \n",
    "        if((t.loc[test_results_least]<crit_t)[0]):\n",
    "        \n",
    "            remove = test_results_least\n",
    "            \n",
    "            removes.append(remove)\n",
    "           \n",
    "        if((t.loc[test_results_least]>crit_t)[0]):\n",
    "            loop=False\n",
    "\n",
    "        if(len(x_names)==1):\n",
    "            loop=False\n",
    "            \n",
    "    return([name, x_names])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e330f-e7ca-4791-b140-2b147949970a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca7620-4df0-4b08-a649-8a52ae483e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc1219-1e09-48bb-ad1a-e8442f7c2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = clientFunction(pcorr_zca,npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e15d98-6184-44a6-b0ab-3dd98b96dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each CCF_names\n",
    "\n",
    "#npa = []\n",
    "#for xname in x_names:\n",
    "    #npa.append([yname,xname,cleaned,[cleaned.index[:np.int(np.round(len(cleaned.index)*.66))],cleaned.index[np.int(np.round(len(cleaned.index)*.66)):]]])\n",
    "    \n",
    "#results = clientFunction(pcorr_test,npa)\n",
    "#results_ = pd.DataFrame(results).set_index(item[0] for item in results).iloc[:,[1]]\n",
    "#results_.columns = ['pcorr']\n",
    "\n",
    "#expensive\n",
    "'''\n",
    "#index_set = data_final.loc[.dropna().index\n",
    "x_names_ = []\n",
    "for data_ in range(0,len(CCF_data)):\n",
    "    data = CCF_data[data_].dropna()\n",
    "    name = CCF_names[data_]\n",
    "    print(name)\n",
    "    yname = 'target'\n",
    "    \n",
    "    x_names = data.columns[~data.columns.isin([item for item in [yname,*removes]])]\n",
    "    \n",
    "    removes = []\n",
    "    \n",
    "    iteration = 0\n",
    "    loop = True\n",
    "    restartClientFunction()\n",
    "    time.sleep(10)\n",
    "    while(loop==True):\n",
    "        iteration = iteration+1\n",
    "        x_names = data.columns[~data.columns.isin([item for item in [yname,*removes]])]\n",
    "\n",
    "        npa = []\n",
    "        for xname in x_names:\n",
    "            npa.append([yname,xname,data,[data.index[:np.int(np.round(len(data.index)*.66))],data.index[np.int(np.round(len(data.index)*.66)):]]])\n",
    "\n",
    "        results = clientFunction(pcorr_test,npa)\n",
    "        results_ = pd.DataFrame(results).set_index(item[0] for item in results).iloc[:,[1]]\n",
    "        results_.columns = ['pcorr']\n",
    "\n",
    "        x_scores_df = abs(results_).sort_values(kind=\"quicksort\", by='pcorr', ascending=True)\n",
    "        '''\n",
    "        #x_scores_df = data_final[[yname,*x_names]].pcorr().round(3)[['target']].replace([np.inf,'inf','error', -np.inf], 1)\n",
    "        '''\n",
    "\n",
    "        #x_scores_df = x_scores_df.loc[~x_scores_df.index.isin(['target'])]\n",
    "\n",
    "        test_results = x_scores_df\n",
    "\n",
    "        n = np.int(np.round(len(data.index)*.66))#len(index_set)\n",
    "        df = n - 2\n",
    "\n",
    "        t=abs(test_results)*np.sqrt(df)/np.sqrt(1-abs(test_results)**2)\n",
    "\n",
    "        test_results_least = t.iloc[[np.argmin(abs(t))]].index[0]\n",
    "\n",
    "        t_score_least = t.iloc[[np.argmin(abs(t))]]\n",
    "\n",
    "        crit_t = scipy.stats.t.ppf(1 - .05 / 2, df)\n",
    "\n",
    "        #print(t_score_least/crit_t)\n",
    "        if(np.isnan(t_score_least.values[0][0])):\n",
    "            remove = test_results_least            \n",
    "            removes.append(remove)\n",
    "\n",
    "        if((t.loc[test_results_least]<crit_t)[0]):\n",
    "\n",
    "            remove = test_results_least\n",
    "\n",
    "            removes.append(remove)\n",
    "\n",
    "        if((t.loc[test_results_least]>crit_t)[0]):\n",
    "            loop=False\n",
    "\n",
    "        if(len(x_names)==1):\n",
    "            loop=False\n",
    "            \n",
    "        #clear ram\n",
    "        if (iteration % 32==0):\n",
    "            restartClientFunction()\n",
    "            time.sleep(10)\n",
    "\n",
    "    x_names_.append([name,x_names])\n",
    "    print(data_, name, iteration, x_names)\n",
    "#return([name, x_names])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11af2b-75ab-4650-9fb7-921dea3f5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(x_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d9235-c6f1-4e82-a57a-d08569cd720d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9535494-9486-4318-9fec-4ee7f32a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "reducedSet = []\n",
    "for r in range(0,(len(npa))):\n",
    "    reducedSet.append(pcorr_zca(npa[r]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4b088-997e-400c-9adc-9f30d269ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7c1c1-6be1-4d03-a318-5a21a024aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "results = []\n",
    "for n in npa:\n",
    "    result = pcorr_zca(n)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28248d3d-fbfe-4981-b385-f5ee1f426fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a7ca5-4d92-48ae-9920-39df104a68ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078c13b-c6b2-4d28-a337-1487e3384bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa = []\n",
    "\n",
    "#queue size\n",
    "for c in range(0, len(CCFs_)):\n",
    "    npa.append([CCF_names[c],CCF_data[c].loc[training]])\n",
    "'''\n",
    "#batch parallel\n",
    "distance = 104\n",
    "\n",
    "reducedSets = []\n",
    "\n",
    "print(len(npa))\n",
    "client = Client('192.168.3.100:8786')\n",
    "client.restart()\n",
    "\n",
    "for r in range(0,(len(npa)),distance):\n",
    "    print(r,r+distance)\n",
    "    \n",
    "    #print(npa[r])\n",
    "    #print((npa[r]+distance))\n",
    "    \n",
    "    batchset = npa[r:min(r+distance,len(npa))]\n",
    "    #CCFs_[npa[r]:min(npa[r]+distance,len(CCFs))]\n",
    "    \n",
    "    #clear ram before starting queue\n",
    "    future = clientFunction(pcorr_zca, batchset)\n",
    "    client.restart()\n",
    "\n",
    "    for m in future:\n",
    "        reducedSets.append(m)\n",
    "\n",
    "client.close()\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf361e-6e1e-4dfd-9ba4-fdc21ac8ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for c in data.columns:\n",
    "    npa.append([array,array1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b977a-5f49-4559-89dc-715e5fdd7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n in npa:\n",
    "    #results_ = pcorr_zca(n)\n",
    "    #results.append(results_)\n",
    "'''\n",
    "client = Client('192.168.3.100:8786',timeout=3)\n",
    "#client.restart()\n",
    "\n",
    "future_ = client.map(pcorr_zca,npa,batch_size=64)\n",
    "results = client.gather(future_)\n",
    "client.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21a5a-5a1f-4ba5-a771-3fccbdbc094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducedSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede0ce1-4c3d-45fa-9b2b-446ce2189d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac5f26-d733-4326-aefd-4b78a4e3732e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b53fb2-81fa-4591-8941-a2d228afca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yname='target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabaa1c-8859-4972-991f-7594e83dc49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a6d00-d117-45ea-a9c1-883fc9c5ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75c782-31c6-4e9e-83e1-3de092774b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce01e6-d896-46d9-86f9-71b4cc1f52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b74bc-b157-46aa-aec6-38e5397ba95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove.remove('PGRW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163ae22-27fe-4393-b0c6-bb1b003fcd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fdb8d-55dc-41b4-abaf-b9e11037c9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7623f8b-17ca-402f-b433-9e8dddc93e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.iloc[[np.argmin(abs(t))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793d699-1e0e-46f9-ac1e-1e2f7d50c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca344d7-d527-4e72-923b-d0b1f6fe1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84c2ea-d3b3-4daf-ad9e-0c1952b14ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8921c-f519-4b5c-be3c-34aef09d83eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd75c46-b7fb-4afa-a275-9c1ce7a34c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e470f72-cfa4-43e8-8aba-f378411c4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abs(test_results).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be6620-ee60-457f-9753-217703cd7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_results_least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096bbd4-23b6-47c4-b584-6a3811de04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned[['ASPUS','MSPUS']].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5b24f-46d3-4713-a377-fe31ac67ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.pearsonr(cleaned['MSPUS'].dropna(),cleaned['ASPUS'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566a925-1b75-470e-9908-58bf4615e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_ = npa1[1][1][['target',*temp[1]]].dropna().pcorr().round(3)['target']\n",
    "n = len(npa1[1][1][['target',*temp[1]]].dropna())\n",
    "df = n - 2\n",
    "\n",
    "t=abs(data_)*np.sqrt(df)/np.sqrt(1-abs(data_)**2)\n",
    "crit_t = scipy.stats.t.ppf(1 - .05 / 2, df)\n",
    "print(crit_t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1db526-f036-4513-aa6e-aa150543665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.max(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec7eee5-4cc8-46f5-ab95-699ea57bfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pcorr_zca(npa1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440a745-3d76-4d9f-a565-3a086e9a8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454832fb-e6d7-4adc-b599-4a80e9ecbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pcorr_zca(npa1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97777753-754a-435e-93c9-b52eca3090b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa1 = []\n",
    "\n",
    "reducedSets = []\n",
    "#queue size\n",
    "for c in range(0, len(CCFs_)):\n",
    "    npa1.append([CCF_names[c],CCF_data[c],train,test])\n",
    "'''\n",
    "for n in npa1:\n",
    "    print(n[0])\n",
    "    reducedSets.append(pcorr_zca(n))\n",
    "    #restartClientFunction()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117eebc2-09ac-4b8e-abae-f5f884d6de12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94187da5-2d23-4bf8-a141-52e5d9df4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "results_pcor = pd.DataFrame(np.array([item[1] for item in results]))\n",
    "results_pcor.index = ([item[0] for item in results])\n",
    "#results_pcor = results_pcor.iloc[CCF_names]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d2aac-aff8-4917-a2f6-af8764442375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872218e7-9f26-4472-8745-d44ccc61af6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca35db-b0fa-4984-ba64-e8bfced2b7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce007a4f-5150-42e9-9d61-0d8f7e0d3cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ed626-3ed3-4376-833c-e08c1e51a329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfa5d6-18e9-4cf9-b03c-a173478f9cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69099516-9fc4-4257-871d-4d155238a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch parallel\n",
    "distance = 148\n",
    "\n",
    "models_ = []\n",
    "print(len(npa1))\n",
    "for r in range(0,(len(CCF_names)),distance):\n",
    "    #name = CCF_names[r]\n",
    "    print(r,r+distance)\n",
    "    \n",
    "    #print(npa[r])\n",
    "    #print((npa[r]+distance))\n",
    "    \n",
    "    batchset = npa1[r:min(r+distance,len(CCFs_))]\n",
    "    #CCFs_[npa[r]:min(npa[r]+distance,len(CCFs))]\n",
    "\n",
    "    client = Client('192.168.3.100:8786')\n",
    "    #clear ram before starting queue\n",
    "    client.restart()\n",
    "\n",
    "    future = clientFunction(fit_sfs_models, batchset)\n",
    "\n",
    "    for m in future:\n",
    "        models_.append(m)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "#nonbatch\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "future = client.map(fit_sfs_models, CCFs, batch_size=64)\n",
    "\n",
    "models_ = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f8173-6f05-438f-9540-c8efa77a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cad131-3bc7-4aea-b391-0119e7de6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(CCF_names)==np.array([item[0] for item in models_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92bf12-e06f-49e5-b0d9-7bdbb83b9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CCF_names\n",
    "b = set([item[0] for item in models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b711739-3a3f-4046-8386-15be480eb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [i for i, item in enumerate(a) if item not in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aeba6b-1cae-48bd-b4fb-37d4df6241be",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_children = np.array(CCF_names)[list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00783ae3-ec8c-40cf-bf7d-0d67c10931b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab9469-a37f-4b4d-b927-9dc56943f1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562545e3-467b-408b-8c67-d69c538c3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from bokeh.sampledata.autompg import autompg_clean as df\n",
    "import hvplot.pandas\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "pn.extension('tabulator')\n",
    "PALETTE = [\"#ff6f69\", \"#ffcc5c\", \"#88d8b0\", ]\n",
    "select = pn.widgets.Select(name='Select', options=['Biology', 'Chemistry', 'Physics'])\n",
    "\n",
    "# Make DataFrame Pipeline Interactive\n",
    "idf = df.interactive()\n",
    "\n",
    "model_quartile = pn.widgets.slider(name='model quartile')\n",
    "\n",
    "# Define Panel widgets\n",
    "cylinders = pn.widgets.IntSlider(name='Cylinders', start=4, end=8, step=2)\n",
    "mfr = pn.widgets.ToggleGroup(\n",
    "    name='MFR',\n",
    "    options=['ford', 'chevrolet', 'honda', 'toyota', 'audi'], \n",
    "    value=['ford', 'chevrolet', 'honda', 'toyota', 'audi'],\n",
    "    button_type='success')\n",
    "yaxis = pn.widgets.RadioButtonGroup(\n",
    "    name='Y axis', \n",
    "    options=['hp', 'weight'],\n",
    "    button_type='success'\n",
    ")\n",
    "\n",
    "# Combine pipeline and widgets\n",
    "ipipeline = (\n",
    "    idf[\n",
    "        (idf.cyl == cylinders) & \n",
    "        (idf.mfr.isin(mfr))\n",
    "    ]\n",
    "    .groupby(['origin', 'mpg'])[yaxis].mean()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .sort_values(by='mpg')  \n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "ihvplot = ipipeline.hvplot(x='mpg', y=yaxis, by='origin', color=PALETTE, line_width=6)\n",
    "ihvplot\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91390852-70f4-4aa6-bce3-a1c46949045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb6d78-cf31-4a12-b28e-f3c8058ec0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312c98c-6b7d-46b9-aba1-d96839a57987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78009921-5472-4085-8e91-8b3e40263aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_models_ = pd.DataFrame([item[1] for item in models_])#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_models_.index = [item[0] for item in models_]\n",
    "\n",
    "models_results = results_models_\n",
    "\n",
    "#models_results.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b658233-dff9-4449-8e9e-ab178dcdbf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bd868-c8a1-4474-abc9-21a8bb279f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2b098-3bd4-496f-a9f4-52a34c4f27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0,len(models_results.index[models_results.index=='e'])):\n",
    "    #print(e)\n",
    "    print(models_results.index[models_results.index=='e'][e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df88414-e90c-44c8-baf9-3cd01687d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to get 'e's in models_results to become problem_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0065-c6f1-4011-9cef-570729ca106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b4431-0885-483f-8dcd-c3b9d8385bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62f9d3-79ac-470d-8150-eceac3506248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7acd51-a0b1-48b1-b102-f5baffecff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#str(models_results.loc[models_results.index[113]].values)=='[nan]'\n",
    "'''\n",
    "start = 0\n",
    "for m in models_results.index:\n",
    "    start = start + 1\n",
    "    print(start)\n",
    "    #if(np.isnan(models_results.loc[m])):\n",
    "    #if(models_results.loc[m]):\n",
    "    print(models_results.loc[m])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71414428-917d-4757-ad2d-e4ab5b4092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_order = []\n",
    "for m in models_results:\n",
    "    if(m[1]=='error'):\n",
    "        print('do nothing')\n",
    "        #model_order.append('error')\n",
    "    else:\n",
    "        model_order.append(m[1])\n",
    "     \n",
    "#valid positions due to error (investigating showed large # of 0's in independent term).    \n",
    "pos = []\n",
    "for m in model_order:\n",
    "    if (m=='error'):\n",
    "        print('do nothing')\n",
    "    else:\n",
    "        pos.append(*np.where(np.array(cleaned.columns)==m)[0])\n",
    "        \n",
    "mask = np.ones(len(cleaned.columns), dtype=bool)\n",
    "mask[pos] = False\n",
    "\n",
    "failedresults = []\n",
    "for m in cleaned.columns[mask]:\n",
    "    failedresults.append(m)\n",
    "                \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15236e68-1b56-4aa9-a7bf-e46daf65b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(models_results=='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa089ada-47d6-46fe-a6a7-c7bd635beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isnan(np.array(models_results)[113][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f8bca-b18f-4aa1-b33a-54f570d5d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models with errors\n",
    "\n",
    "problem_children = []\n",
    "\n",
    "for m in range(0,len(models_results.index)):\n",
    "    if(str(models_results.loc[models_results.index[m]].values)=='[nan]'):\n",
    "        problem_children.append(models_results.index[m])\n",
    "        \n",
    "        #print problematic models\n",
    "#plt.plot(raw_int.loc[:,['USREC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6e31-e8dc-4635-aadb-7e0e6f5f37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problem_children)\n",
    "#for p in problem_children:\n",
    "#    print(np.where(models_results.index==p)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dddf8-be4c-4887-ba77-1252292b7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "npa = []\n",
    "\n",
    "#queue size\n",
    "for c in range(0, len(CCFs_)):\n",
    "    print(c)\n",
    "    #print()\n",
    "    \n",
    "    if CCF_names[c] in problem_children:\n",
    "        npa.append(np.array([CCF_names[c],'error']))\n",
    "    else:\n",
    "        #print(names)\n",
    "        #CCF_data[c][names].loc[training]\n",
    "        npa.append(np.array([CCF_names[c],CCF_data[c][results_pcor.iloc[c][0]]]))\n",
    "        '''\n",
    "        '''\n",
    "        name = npa_[0]\n",
    "        #print(name)\n",
    "        data_final = npa_[1]\n",
    "        train = npa_[2]\n",
    "        test = npa_[3]\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a16f94-59f8-48a1-8837-e13ee3df164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoveredModels = []\n",
    "\n",
    "#check why\n",
    "'''\n",
    "for f in failedresults:\n",
    "    CCF_pos = np.where(np.array(cleaned.columns)==f)[0][0]\n",
    "    #CCFs[CCF_pos]\n",
    "    recoveredModels.append(fit_sfs_models(CCFs[CCF_pos]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370fd8e-ea5b-457d-951d-601e9b95671d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc629167-a16a-4add-9ff1-fa1bbcf6e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[c[0][0][0] for c in CCFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ee7f9-929e-47be-a8c1-28f9ebbf7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37145b4d-e1ef-4308-b9a5-eecd5578b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dd022-112a-4df6-bf15-82cb9e2d092a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b518132-fc03-4c4d-96a0-dd13a4ee57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380ee71-ce13-4068-acca-0518ad9c574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784616f-bed6-4757-9243-328d3673ab3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a4ee9-aeb3-4d06-9ebb-bf2a7aa17d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d5bd0-81d5-484f-a02f-4a69f005f1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CCF_names[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c374c-358b-4663-af29-84cdd6118a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa = []\n",
    "for c in range(0,len(CCF_names)):\n",
    "    npa.append([CCF_names[c],CCF_data[c],CCF_scores[c],CCF_best_lags[c],models_results.loc[CCF_names[c]],training,testing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312414cd-da8f-46d3-8bb2-f556d4d0c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npa[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36f618-f6d4-4169-ae95-020c6c3b27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275fe2a-8d23-4eed-a7e9-64c5c09787f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deriveWinners(npa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cc210-f210-4975-8fba-0fbcd5c5d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_ = clientFunction(deriveWinners,npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711a43-eae4-46e3-9953-b002713df0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_\n",
    "\n",
    "results_winners_ = pd.DataFrame(np.array([item[1] for item in winners_]))#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_winners_.index = [item[0] for item in winners_]\n",
    "\n",
    "winners_results = results_winners_.reindex(raw_int.columns)\n",
    "\n",
    "winners_results.columns = ['winners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989166e3-cf1d-4277-ba15-8799011f836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd17564-5d2c-40ff-b888-e57373a932e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winner_ = \n",
    "#pd.DataFrame([item[1] for item in winner_s]).set_index([[item[0] for item in winner_]]).loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929194b-5575-45cd-a308-379a80be0cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378030e9-57b7-402b-b2bf-63178dfebc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e9903-a22e-40e1-92b8-b5704f5ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "winners_results = pd.DataFrame([results_winners_]).T\n",
    "winners_results.index = results_winners_index\n",
    "winners_results = winners_results.loc[raw_int.columns]\n",
    "winners_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10893-9a8f-4790-b2d6-5b3130df0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c74aa-d6f8-4eb1-b5a9-a3792c6a557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels(npa_):\n",
    "    \n",
    "    #[name,winners_,ccf_data,ccf_score,ccf_lags,ndif_results.iloc[c],sndif_results.iloc[c],training,testing]\n",
    "    \n",
    "    name = npa_[0]\n",
    "    \n",
    "    winners_ = npa_[1]\n",
    "    data_final = npa_[2].dropna()\n",
    "    ccf_scores = npa_[3]\n",
    "    best_lags = npa_[4]\n",
    "    nonseasonal = CCF_package = npa_[5]\n",
    "    seasonal = CCF_package = npa_[6]\n",
    "    train = npa_[7]\n",
    "    train = npa_[8]\n",
    "    \n",
    "    if name in problem_children:\n",
    "        return([name,['error','error'],'error','error','error','error','error','error'])\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "    \n",
    "    model_pos = np.where(models_results.index==name)[0][0]\n",
    "    \n",
    "    if(str(npa_[1])=='error'):\n",
    "        return([name,['error','error'],'error','error','error','error','error','error'])\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    \n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "    \n",
    "    lagatposition = []\n",
    "    lagatposition.append([name,0])\n",
    "    for s in range(0,len(winners_)):\n",
    "        #print(winners_[s])\n",
    "        #lagposition.append(np.where(ccf_scores.columns==winners_[s])[0][0])\n",
    "        #print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        #print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        lagatposition.append([winners_[s],best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]]])\n",
    "\n",
    "    interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "    X_inter = pd.DataFrame(interaction.fit_transform(data_final[winners_].dropna()),columns=interaction.get_feature_names(input_features=data_final[winners_].columns) ).set_index(data_final.dropna().index)\n",
    "    \n",
    "    X_train = sm.add_constant(X_inter).loc[train].dropna()\n",
    "    X_test = sm.add_constant(X_inter).loc[test].dropna()\n",
    "    data_w_inter = pd.concat([data_final['target'],sm.add_constant(X_inter)],axis=1).dropna()\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "\n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(data_w_inter.columns)*.75), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=1,\n",
    "              cv=numCV)\n",
    "\n",
    "    data_w_inter_train= data_w_inter.loc[train]\n",
    "    data_w_inter_test= data_w_inter.loc[test]\n",
    "    \n",
    "    fitted = s_f_s.fit(data_w_inter_train.loc[:, ~data_w_inter_train.columns.isin(['target'])], pd.DataFrame(data_w_inter_train['target']))\n",
    "    \n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "    \n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_p = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "    \n",
    "    #just regular non interactions over training\n",
    "    results_train = sm.OLS(pd.DataFrame(data_w_inter_train['target']),data_w_inter_train[winners_]).fit()\n",
    "    \n",
    "    models = []\n",
    "    models.append(results_train)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    summaries.append(results_train.summary())\n",
    "    \n",
    "    #using polynomial interactions over all data\n",
    "    results_all = sm.OLS(data_w_inter['target'].dropna(),data_w_inter[winners_p]).fit()\n",
    "    \n",
    "    models.append(results_all)\n",
    "\n",
    "    summaries.append(results_all.summary())\n",
    "    \n",
    "    #training, for MAPE\n",
    "    train_forecast = results_train.predict(data_w_inter_train[winners_])\n",
    "    test_forecast = results_train.predict(data_w_inter_test[winners_])\n",
    "\n",
    "    MAPE_in_sample = MAPE(data_w_inter_train['target'],train_forecast)\n",
    "    MAPE_out_sample = MAPE(data_w_inter_test['target'],test_forecast)\n",
    "\n",
    "    inverses = []\n",
    "\n",
    "    inverses.append([name,sndif_results.loc[name][0],ndif_results.loc[name][0]])    \n",
    "\n",
    "    for w in winners_:\n",
    "        inverses.append([w,sndif_results.loc[w][0],ndif_results.loc[w][0]])\n",
    "    \n",
    "    return([name,[MAPE_in_sample,MAPE_out_sample],models,summaries,lagatposition,inverses,data_w_inter,winners_p])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78e55037-21f5-449d-a6af-d44499515f43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e27b7-8ea7-49ed-bb72-0ba4e358fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10958a82-36dc-491b-bbd5-0731c4e29805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815310d1-b261-4a4d-88e9-33da92a6428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for c in range(0,len(CCF_names)):\n",
    "    #ndif_results.iloc[c],sndif_results.iloc[c]\n",
    "    name = CCF_names[c]\n",
    "    ccf_data = CCF_data[c]\n",
    "    ccf_score = CCF_scores[c]\n",
    "    ccf_lags = CCF_best_lags[c]\n",
    "    winners_ = winners_results.loc[raw_int.columns[c]][0]\n",
    "    #model_ = \n",
    "    \n",
    "    npa.append([name,winners_,ccf_data,ccf_score,ccf_lags,ndif_results.iloc[c],sndif_results.iloc[c],training,testing])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c5e54-9d38-4eae-be23-f04fac9bdc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61b075-1fce-4c4d-b0d7-bece865473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = runModels(npa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00648aca-f10e-406b-9092-219e340bf1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ae622-8288-4abd-80f5-0621d2a566af",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartClientFunction()    \n",
    "ranModels = clientFunction(runModels,npa)\n",
    "restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0db97-3ceb-4599-8375-579685399dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_results.loc['MSPUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b0522-41be-486f-a204-de915675fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[item[0] for item in ranModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd72b01-7f97-4f7f-82fc-08ff7544bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranModels[0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a841cc-8c9f-418b-8144-0d8ffb7e20ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44641c-40ea-4d12-bdb5-2f95cb89d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d6277-bfd3-4574-b8fb-2c7d2a2c0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for r in range(0,len(ranModels)):\n",
    "#    print(ranModels[r][0])\n",
    "#    print(ranModels[r][5])\n",
    "    \n",
    "#[item[5] for item in ranModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1bf74-a5bc-4e4e-bc49-0d15f1f6bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(([item[5] for item in ranModels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df235e65-1b44-4d54-bb38-1d05f4191457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranModels_ = pd.concat([pd.DataFrame([item[1] for item in ranModels]),pd.DataFrame(np.array([item[2] for item in ranModels])),pd.DataFrame(np.array([item[3] for item in ranModels])),pd.DataFrame(np.array([item[4] for item in ranModels])),pd.DataFrame(np.array([item[5] for item in ranModels])),pd.DataFrame(np.array([item[7] for item in ranModels]))],axis=1)\n",
    "\n",
    "ranModels_.index = [item[0] for item in ranModels]\n",
    "\n",
    "ranModels_.columns = ['in-sample-mape','out-sample-mape', 'models', 'summaries','lags','seasonal_non','winners_p']\n",
    "\n",
    "ranModels_ = ranModels_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26488ae2-0876-4171-85c3-c96f47164082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranModels_names = [item[0] for item in ranModels]\n",
    "ranModels_data = np.array([item[6] for item in ranModels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc6fc0-8568-4754-8681-6b99d524f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in ranModels:\n",
    "    #print(i[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e1fb8-5905-44fd-96e2-927325a87b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c114f0a-bd44-4a20-8cc5-06799be05431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(ranModels_['out-sample-mape'].replace([np.inf, -np.inf], np.nan).dropna()=='error')\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0f15a-bfed-41b6-9f61-d3dc5ea6fd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b60bc9-0d1d-4967-bf20-8372dbcfa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ = ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2ad15-550f-4a79-b030-2be97f86374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e82a4e-4cc6-4e94-933a-845c7e14b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "runningTotal = 0\n",
    "values = []\n",
    "for c in range(0,len(cleaned_)):\n",
    "    values.append(float(cleaned_.iloc[c]))\n",
    "    #print(runningTotal)\n",
    "   \n",
    "'''\n",
    "#print(runningTotal/len(cleaned_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7937-26b4-462b-8340-9cc2a1b09a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(values).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d1848-970c-435c-b11d-a230165fca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91ef2b-4a22-41a9-94a9-031e261aa225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702161dc-506e-4504-a771-3321bc0e8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned_[cleaned_!=\"error\"])\n",
    "#plt.show()\n",
    "#cleaned_ = cleaned_[cleaned_!=\"error\"]\n",
    "filters_out = ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float).quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')\n",
    "#cleaned_.quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "filters_in = ranModels_[['in-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float).quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')\n",
    "#cleaned_[(cleaned_<=filters.iloc[3]) * (cleaned_>=filters.iloc[1])].hist()\n",
    "#subset = cleaned_[(cleaned_<=filters.iloc[2])]\n",
    "cleaned_[(cleaned_<=filters_out.iloc[2])].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae0b30-ca6e-4b8a-b708-e1d8b696e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0cb65-7fb9-4540-96ca-a02f5bd5f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ranModels_results.dropna())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a67708-db59-4759-96e2-4a8528b5e919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c03b0-dad5-404f-9be7-c0b9fde65e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae111b61-ede2-4d78-8ae5-4b110bbfbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in decent_models:\n",
    "    #print(c)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92af28a-54e8-4242-a414-695bd8aead34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35337139-4dfa-427b-ba48-bde03efe4dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29ff21-918d-46a3-a061-81be3def6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranModels_.iloc[113][0]=='error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd19e32-12d9-4df4-badb-4aef0ca67201",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in = []\n",
    "for x in range(0,len(ranModels_['models'])):\n",
    "    if(ranModels_.iloc[x][0]=='error'):\n",
    "        r_sqr_in.append('error')\n",
    "    else:\n",
    "        #print(ranModels_['in_model'][x].rsquared)\n",
    "        r_sqr_in.append(ranModels_['models'][x][0].rsquared)\n",
    "        \n",
    "r_sqr_full = []\n",
    "for x in range(0,len(ranModels_['models'])):\n",
    "    if(ranModels_.iloc[x][1]=='error'):\n",
    "        r_sqr_full.append('error')\n",
    "    else:\n",
    "        #print(ranModels_['in_model'][x].rsquared)\n",
    "        r_sqr_full.append(ranModels_['models'][x][1].rsquared)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933181f-a81a-4a51-83cb-806236dd67ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377f34-6e0b-429c-b1f7-1b52c6e3819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in_ = pd.DataFrame(r_sqr_in).replace('error',np.nan).set_index(raw_int.columns).dropna()\n",
    "r_sqr_full_ =  pd.DataFrame(r_sqr_full).replace('error',np.nan).set_index(raw_int.columns).dropna()\n",
    "\n",
    "filters = pd.concat([filters_in,filters_out,r_sqr_in_.quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear'),r_sqr_full_.quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')],axis=1)\n",
    "filters.columns = ['in-sample-mape','out-sample-mape','r_sqr_in','r_sqr_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1a696-126c-4b73-8eac-764711d49b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b0352-d2e5-4a25-a276-21697a6206b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242b51a-f6f5-4f45-bd9e-c2c52a9e2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "together = pd.concat([ranModels_[['in-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float),ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float),r_sqr_in_,r_sqr_full_],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c7445-fc3b-4bc5-8979-e90b82291268",
   "metadata": {},
   "outputs": [],
   "source": [
    "together.columns = ['in-sample-mape','out-sample-mape','r_sqr_in','r_sqr_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b787a8-1664-48d2-a796-6b0c7c809156",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in_.hist()\n",
    "r_sqr_full_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f2cc7-0166-4692-bb25-133cf36f26ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c9a26-f8f3-4b4e-8340-2d01f1d996d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49c296-b096-40b6-81fc-01502050c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "decent_models = together[((together['out-sample-mape'] <=filters['out-sample-mape'].iloc[3])*(together['r_sqr_in']>=filters['r_sqr_in'].iloc[5]))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5497519-793d-4a7b-98fb-ac53d4420b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decent_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5237a-13eb-4ee5-8c17-3fae30d2d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_results.loc[decent_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68fd40-4f00-4c2e-8e4c-8ff9b4c67778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs[np.where(raw_int.columns=='CSUSHPINSA')[0][0]][1].loc[training].dropna()['DFII10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af465375-9849-45b7-aff0-87c30e090678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544081d-4853-4cf2-84e1-5e46ae72c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vars_ = list()\n",
    "vars_.append('target')\n",
    "for v in [*ranModels_.loc[decent_models].loc['CSUSHPINSA'][2].model.exog_names[1:]]:\n",
    "    vars_.append(v)\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f68f5-9ded-4deb-8291-3adfcf3901f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e8861-78a7-4800-9a36-b0c8ec824bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs_[np.where(raw_int.columns=='CSUSHPINSA')[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c2c50-70e4-4fe3-9176-37c03fcaa47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd0c9-4134-449a-82e8-86d3e5fc7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CCFs[np.where(raw_int.columns=='CSUSHPINSA')[0][0]][1].loc[training].dropna()[vars_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012d225-dc4c-4751-b341-ca923a6a6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars = [item[0] for item in ranModels_.loc[decent_models].iloc[m][5]][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0ff71-edd4-4161-a24c-7342adb77e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winners_results,ranModels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ee604-7fb7-4343-96ab-a2e5cbc47ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(CCF_names==decent_models[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2fc96-0fd8-40f3-b7d0-d0079371a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfea0bc-2613-44e0-a031-b2507c73bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][2][1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05370aae-e3f0-468a-a0f4-001cad6b2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(np.array(CCF_names)==CCF_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb76cd-5f73-403b-aa95-41acdefa8ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78bdfb-60fe-4d28-a93a-375b91fc51b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad0efe-e79d-45c0-b17d-6c9d5206c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e0e09-41b7-4e8d-b45a-912ae9029ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ada3e-589a-4771-b805-6a47f8acd7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e3211-c2ab-4bbe-9a4c-14df1df79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_sample_training_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f83fa-6c4c-41f3-8b99-a507514673d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCF_data[np.where(np.array(CCF_names)==CCF_names[ccf_position])[0][0]].loc[training][vars_].dropna().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683d1b1-8914-4cff-8c65-7d1a6d9357bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1111b-93ec-485a-95b2-27478e150fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181e27a-c546-4a7b-8e58-f7d3f1ae4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_metrics.loc[decent_models[m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b982469-c0ef-43d8-986f-c541ae873820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65325df4-27d1-488f-bd70-318dc57cc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    #return([name,[MAPE_in_sample,MAPE_out_sample],models,summaries,lagatposition,inverses])\n",
    "\n",
    "    #seasonal = inverses[0][1][1]\n",
    "    #nonseasonal = inverses[0][2][1]\n",
    "    \n",
    "    #print(season, seasonal, nonseasonal)\n",
    "\n",
    "    #print(raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0])])\n",
    "    \n",
    "    train_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    train_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    print(train_prior_date)\n",
    "    #print(train_prior_date_1)\n",
    "    train_xi=raw_int[name].loc[train_prior_date:train_prior_date_1]\n",
    "\n",
    "    undiffed_train = pd.DataFrame(undiff(temp_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "    undiffed_train_forecast = pd.DataFrame(undiff(train_forecast, seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "\n",
    "    test_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    test_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    test_xi = raw_int[name].loc[test_prior_date:test_prior_date_1]\n",
    "\n",
    "    #[raw_int[name].loc[temp_train['target'].index[-1]]]\n",
    "    undiffed_test_forecast = pd.DataFrame(undiff(test_forecast, seasonal, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "    undiffed_test = pd.DataFrame(undiff(temp_test['target'].dropna(), 0, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.plot(raw_int[name])\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_test],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train_forecast,undiffed_test_forecast],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_train_forecast],axis=1))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_test,undiffed_test_forecast],axis=1))\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi=raw_int[name].loc[prior_date:prior_date_1]\n",
    "\n",
    "    undiffed_ = pd.DataFrame(undiff(data_final['target'].dropna(), seasonal, nonseasonal, xi),columns=['target']).set_index(data_final['target'].dropna().index)\n",
    "\n",
    "    prior_date_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi_=raw_int[name].loc[prior_date_:prior_date_1_]\n",
    "\n",
    "    undiffed_forecast = pd.DataFrame(undiff(results.fittedvalues, seasonal, nonseasonal, xi_),columns=['target']).set_index(results.fittedvalues.index)\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47811b33-7b09-48dd-b43f-1954376163f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e44e0-dbb0-4a1f-beef-da1e8847ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undiff(out_sample_training_prediction, seasonal, nonseasonal,test_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72bd4b-4b8d-484c-bae4-bcb9b4731306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ae215-e4ef-486c-9fdc-9d0924cd9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b20d9-d6ec-48f6-9c13-3d66d263a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac90b15-f698-4f28-ab46-61065e39b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb72163-9f6e-4319-a63e-195552cabfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5df61a-c4ee-4743-a1ba-045d74b1ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c2b6f-bb7b-4bcc-98ad-0ec887a35d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5aab52-0132-45c5-87ed-469c03fd0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c7992-4789-4d68-8834-c47b1527b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe3b6e-aa12-4f17-b4b8-cbc3da57109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918c621-06c2-4c5d-acd3-6fae2215fba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b1890-8863-4315-9418-bd7f192e6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c12dd1-f920-4ba1-9f0f-1b137f6a82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int[name].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16aa900-df2d-44b5-88a9-0dcda373593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6e5f6-6662-406e-9bde-e4bb221c7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_['target'].dropna(), seasonal, nonseasonal,train_xi),columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf787-cef0-44d0-b37d-8e4b9468dd36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e837e-469d-4e55-b3a8-7e64ac029479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028177b-ac2b-40b4-bc8e-870eeca9bcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7039f-ff81-4203-9d59-cefee6af6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranModels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c858bf-977f-4060-b4e9-6b3cf58d0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(0,len(ranModels_.loc[decent_models])):\n",
    "    #if(ranModels_.loc[decent_models].iloc[m][2].rsquared>filters['r_sqr'].iloc[3]):\n",
    "    if(ranModels_.loc[decent_models].iloc[m][2][0].rsquared>filters['r_sqr_in'].iloc[3]):\n",
    "        ccf_position = np.where(np.array(CCF_names) == decent_models[m])[0][0]\n",
    "        name = ranModels_.loc[decent_models].index[m]\n",
    "        #winners_p = ranModels_.loc[decent_models].index[m][7]\n",
    "        #print(data_metrics.loc[name])\n",
    "        vars_ = ['target',*winners_results.loc[name][0]]\n",
    "        #print(winners_results.loc[name][0])\n",
    "        print(name, ':' ,*vars_)\n",
    "        #CCF_data.loc[name]\n",
    "        #dir(runModels(npa[0])[2][0])\n",
    "        print(\"seasonal non:\",ranModels_.loc[decent_models].iloc[m][5])\n",
    "        print(\"lags:\",ranModels_.loc[decent_models].iloc[m][4])\n",
    "        print(CCF_data[ccf_position][vars_].dropna().index[1])\n",
    "        print(training[-1])        \n",
    "        print(\"in_sample R2: \", ranModels_.loc[decent_models].iloc[m][2][0].rsquared)\n",
    "        print(\"out_sample R2: \", ranModels_.loc[decent_models].iloc[m][2][1].rsquared)\n",
    "        print(\"in sample mape:\",ranModels_.loc[decent_models].iloc[m][0])\n",
    "        print(\"out sample mape:\",ranModels_.loc[decent_models].iloc[m][1])        \n",
    "        print(ranModels_.loc[decent_models].iloc[m][3][0])\n",
    "        #ranModels_.loc[decent_models].iloc[m][2][0]\n",
    "        print(ranModels_.loc[decent_models].iloc[m][3][1])\n",
    "        print(auto_arima(ranModels_.loc[decent_models].iloc[m][2][1].resid))\n",
    "        \n",
    "        #print(CCF_data[ccf_position][vars_].dropna().describe())\n",
    "        #in sample training prediction\n",
    "        \n",
    "        ranModels_.loc[decent_models].iloc[m][5]\n",
    "        \n",
    "        seasonal = ranModels_.loc[decent_models].iloc[m][5][0][1]\n",
    "        \n",
    "        nonseasonal = ranModels_.loc[decent_models].iloc[m][5][0][2]\n",
    "        #print(nonseasonal)\n",
    "        #print(\"difference:\", \"seasonal:\", seasonal, \"nonseasonal:\",nonseasonal)\n",
    "        \n",
    "        data_ = ranModels_data[np.where(np.array(ranModels_names)==name)[0][0]]\n",
    "        #CCF_data[np.where(np.array(CCF_names)==CCF_names[ccf_position])[0][0]]\n",
    "        \n",
    "        #data_ = pd.concat([data_['target'],pd.DataFrame(interaction.fit_transform(data_[winners_].dropna()),columns=interaction.get_feature_names(input_features=data_[winners_].columns) )],axis=1)\n",
    "        \n",
    "        #arima_ = auto_arima(data_[name],x=data_[winners_p]),d=0,D=0)\n",
    "        #print(arima_)\n",
    "        \n",
    "        \n",
    "        #print(data_[vars_].dropna())\n",
    "            \n",
    "        '''\n",
    "        data_train = pd.concat([data_.loc[training]['target'],pd.DataFrame(interaction.fit_transform(data_.loc[training][winners_results.loc[name][0]].dropna()),columns=interaction.get_feature_names(input_features=data_.loc[training][winners_results.loc[name][0]].dropna().columns) )],axis=1)\n",
    "        \n",
    "        data_test = pd.concat([data_.loc[testing]['target'],pd.DataFrame(interaction.fit_transform(data_.loc[testing][winners_results.loc[name][0]].dropna()),columns=interaction.get_feature_names(input_features=data_.loc[testing][winners_results.loc[name][0]].dropna().columns) )],axis=1)\n",
    "        \n",
    "        train_prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_train['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "        train_prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_train['target'].index[0]).ravel()[0]-1]\n",
    "        \n",
    "        train_xi=raw_int[name].loc[train_prior_date:train_prior_date_1]\n",
    "        \n",
    "        undiffed_train = pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)\n",
    "    \n",
    "        test_prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_test['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "        test_prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_test['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "        test_xi = raw_int[name].loc[test_prior_date:test_prior_date_1]\n",
    "\n",
    "        in_sample_training_prediction = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_train)\n",
    "        \n",
    "        undiffed_in_sample_training_prediction = pd.DataFrame(undiff(in_sample_training_prediction, seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)\n",
    "        \n",
    "        #out_sample training prediction\n",
    "        out_sample_training_prediction = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_test)\n",
    "\n",
    "        undiffed_out_sample_training_prediction = pd.DataFrame(undiff(out_sample_training_prediction, seasonal, nonseasonal,test_xi),columns=['target'])\n",
    "        \n",
    "        #training model applied to all data\n",
    "        training_prediction_all_data = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_[vars_].dropna())\n",
    "\n",
    "        undiffed_all_training_prediction = np.cumsum(pd.DataFrame(undiff(training_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index))\n",
    "        \n",
    "        #full model all data fit\n",
    "        #inverse log\n",
    "        #full_prediction_all_data = np.cumsum(unlog(ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][1].predict(data_[vars_].dropna())))\n",
    "        full_prediction_all_data = (ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][1].predict(data_[vars_].dropna()))\n",
    "        \n",
    "        #undiffed_all_full_prediction = np.cumsum(unlog(pd.DataFrame(undiff(full_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        undiffed_all_full_prediction = np.cumsum((pd.DataFrame(undiff(full_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "\n",
    "        #original_data = np.cumsum(unlog(pd.DataFrame(undiff(data_[vars_].dropna()['target'], seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        original_data = np.cumsum((pd.DataFrame(undiff(data_[vars_].dropna()['target'], seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        \n",
    "        #original_data = cleaned.loc[full_prediction_all_data.index][decent_models[m]]\n",
    "        \n",
    "        #combined = pd.concat([pd.DataFrame(training_prediction_all_data), pd.DataFrame(full_prediction_all_data), pd.DataFrame(original_data)],axis=1)\n",
    "        \n",
    "        combined = pd.concat([pd.DataFrame(undiffed_all_training_prediction), pd.DataFrame(undiffed_all_full_prediction), pd.DataFrame(original_data)],axis=1)\n",
    "        \n",
    "        combined.columns = [\"training\",\"full\",\"original\"]\n",
    "        #plt.plot(original_data)\n",
    "        #plt.plot(training_prediction_all_data)\n",
    "        #plt.plot(full_prediction_all_data)\n",
    "        plt.plot(combined)\n",
    "        plt.legend([\"training\",\"full\",\"original\"],loc='upper left')\n",
    "        \n",
    "        plt.show()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d0f36-2519-448d-8f17-0662fb890d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(ranModels_.loc[decent_models].iloc[m][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28034305-002f-498a-bff6-bb51a9ca0354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac0e15-ed83-4066-a895-1c41dcd207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now sorted by model return pos\n",
    "'''\n",
    "batchSet = np.array(CCFs)[pos]\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "client.restart()\n",
    "\n",
    "future = client.map(runModels, batchSet,batch_size=64)\n",
    "\n",
    "models_ran = client.gather(future)\n",
    "client.restart()\n",
    "client.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc598c3-4245-4c17-b901-c48bb61f1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2db4d5-b4de-4527-8a5a-6b9e59d2122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train = temp_train[winners_]\n",
    "\n",
    "y_train = temp_train['target']\n",
    "\n",
    "kfold = KFold(n_splits=numCV, shuffle=True)\n",
    "\n",
    "#used for pcorr kfolds as well as best subsets\n",
    "train_ = []\n",
    "test_ = []\n",
    "\n",
    "kfold.get_n_splits(X_train.index)\n",
    "\n",
    "for train_indices, test_indices in kfold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n",
    "\n",
    "threshold = .05\n",
    "\n",
    "set_ = list(winners_)\n",
    "\n",
    "max_pvalue = 1\n",
    "\n",
    "subset = temp_train[np.concatenate([['target'],winners_])]\n",
    "\n",
    "n=len(subset)\n",
    "\n",
    "while(max_pvalue>=threshold):\n",
    "\n",
    "    dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "    p_values = pd.DataFrame(2*dist.cdf(-abs(subset.pcorr()['target']))).T\n",
    "    p_values.columns = list(subset.columns)\n",
    "\n",
    "    max_pname = p_values.idxmax(axis=1)[0]\n",
    "    max_pvalue = p_values[max_pname].values[0]\n",
    "\n",
    "    #print(max_pvalue, max_pname)\n",
    "\n",
    "    #to prevent errors, always return 1 value\n",
    "    if len(set_)==1:\n",
    "        break\n",
    "\n",
    "    if (max_pvalue > threshold):\n",
    "\n",
    "        set_.remove(max_pname)\n",
    "        temp = [target]\n",
    "        temp.extend(set_)\n",
    "        subset = subset[temp]\n",
    "\n",
    "        max_pname=\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31693bd1-5256-45ee-8d2b-8175abe30528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015629e-d203-4586-b48f-35065094fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "small_set = random.sample(list(np.sort(cleaned.columns)),1)\n",
    "\n",
    "runs = []\n",
    "for chosen in small_set:\n",
    "    runs.append(run_analysis(chosen))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698e28f-3010-4e64-9edf-5f359aab2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('chosen', chosen, 'training vs holdout f test for equal variance', training_vs_holdout_f_test[1])\n",
    "'''\n",
    "#CV Plot\n",
    "fig = plot_sfs(fitted.get_metric_dict(), kind='std_err')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.savefig(str(target)+'.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "#print(metric_table)\n",
    "plt.plot(metric_table['avg_score'])\n",
    "plt.savefig(str(target)+'metric.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "for w in range(0,len(winners_)):\n",
    "    print(winners_[w])\n",
    "    value = np.where(raw_int.columns==winners_[w])[0][0]\n",
    "    print(inverses[w])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==winners_[w])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "\n",
    "\n",
    "print(seasonal)\n",
    "print(nonseasonal)\n",
    "\n",
    "print(chosen,'Population', 'Equal mean:', equal_mean, ', ', 'Population', 'Equal variance:', equal_var)\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "value = np.where(raw_int.columns==chosen)[0][0]\n",
    "\n",
    "#print(\n",
    "print('sndif:', sndif[value])\n",
    "print('ndif:', ndif[value])\n",
    "\n",
    "for w in set_:\n",
    "    plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "    plt.show()        \n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n",
    "\n",
    "#for w in winners_:\n",
    "sn.set_theme(style=\"ticks\")\n",
    "\n",
    "t = temp_train[np.concatenate([['target'],winners_])]\n",
    "t_ = t[['target']]\n",
    "t_.columns = ['target2']\n",
    "#t_.rename('target2')\n",
    "t = pd.concat([t,t_],axis=1)\n",
    "sn.pairplot(t, hue=\"target\")\n",
    "#plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "for s in range(0,len(set_)):\n",
    "    print(np.where(ccf_scores.columns==set_[s])[0][0])\n",
    "\n",
    "print(MAPE(temp_test['target'],test_forecast))\n",
    "\n",
    "index_ = []\n",
    "\n",
    "for w in set_:\n",
    "    print(w)\n",
    "    value = np.where(raw_int.columns==w)[0][0]\n",
    "    index_.append(value)\n",
    "    inverses.append([w,sndif[value],ndif[value]])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==set_[s])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab30499-2191-4f82-b1ee-a2087973c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d08d6-1f0c-4447-be2d-a3a6b91a1fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e6ab6-e639-4dce-8db4-e29a2d729119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4440f99-f158-43d1-9108-6967fc0122aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77cb1-9235-4db8-ab3e-826f65c44330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0058905-36bc-476c-b52a-b8fde036eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ccf_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543fec-bd07-4bbf-b3d0-b1431bcba01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577961c-4929-4071-8f22-97381fead1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224de44f-3fc4-4630-85ac-622a7d8d3c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35a30-937e-4751-836a-8cf447037e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask = dd.from_pandas(data_final,npartitions=128)\n",
    "#data_final_dask_w_y = dd.concat([cleaned[[y_name]],data_final_dask.compute()],axis=1)\n",
    "#names_ = ['target']\n",
    "#names_.extend(cleaned.columns)\n",
    "#data_final_dask_w_y.columns = names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2b44-72f9-46b4-b3fc-a10c46fd0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask.apply(np.cumsum,axis=1).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce954cbf-4eca-4d46-a2af-afa25e3e88f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13186e-5615-44b8-8593-067501c7fcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2c216-e4cc-4ce5-aead-bcb283cd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c54e-9bd1-4012-b11a-6a28f1cc8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int[chosen])\n",
    "#plt.plot(cleaned[chosen])\n",
    "#plt.plot(data_final_dask_w_y[chosen].compute())\n",
    "#plt.plot(data_final_dask_w_y[['target']].compute().loc[training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2259a1-3d45-43b5-9f1a-4715ed7adf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sort(data_final_dask_w_y.compute().isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a92423-63d4-4d38-85ed-dc9e910eef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17484b9-be53-4ab5-ae8c-1b43b45e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "#pd.concat([target,zca1],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755a17-dfa2-479d-a3f9-d91134239c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fe348-072f-4814-a7c3-af7f24cf7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "newindex = []\n",
    "\n",
    "for i in range(0,len(temp_train.index)):\n",
    "    newindex.append(temp_train.index[i])\n",
    "\n",
    "for i in range(0,nonseasonal):\n",
    "    newindex.append(last_day_of_month(temp_train.index[-1] + pd.DateOffset(90*i)))\n",
    "    \n",
    "len(newindex)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa1c1d-2570-4358-9aae-d501ba283957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51702ec-ba0b-48f1-bdc5-6f22cae90e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "future = client.map(regress, X)\n",
    "\n",
    "results = []\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "    \n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df_.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0d63e-85ca-449b-8390-aeeecb71313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaler = StandardScaler()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "#scaler.fit(np.array(data_final_dask_w_y[['target']].compute().loc[training]).reshape(-1, 1))\n",
    "\n",
    "New_Names = list(data_final_dask_w_y.columns.difference(['target']))\n",
    "\n",
    "outer_dataset = data_final_dask_w_y.compute().loc[training].dropna()\n",
    "target = outer_dataset[['target']]\n",
    "\n",
    "subset = pd.concat([target,outer_dataset[New_Names]],axis=1)\n",
    "\n",
    "num_folds = 2\n",
    "#kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "#train, test = kfold.get_n_splits(outer_dataset.index)\n",
    "\n",
    "p_threshold = .05\n",
    "\n",
    "iteration = 0\n",
    "max_pvalue = 1\n",
    "\n",
    "while(max_pvalue>=.05):\n",
    "#\n",
    "    print(chosen)\n",
    "    \n",
    "    print(New_Names)\n",
    "    \n",
    "    n_p_values = pd.DataFrame()\n",
    "\n",
    "    p_values = []\n",
    "    \n",
    "    #parallelize here (x16)\n",
    "    for n in New_Names:\n",
    "        #print(n)\n",
    "        New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "        p_values.append(pvalues(n))\n",
    "        \n",
    "    p_values_df = pd.DataFrame(p_values,index=New_Names)\n",
    "    print(p_values_df)\n",
    "\n",
    "    max_pname = New_Names[np.argmax(p_values_df)]\n",
    "    max_pvalue = p_values[np.argmax(p_values_df)]\n",
    "\n",
    "    #n_p_values = pd.concat([n_p_values,p_values],axis=0)\n",
    "    #print(n_p_values)\n",
    "\n",
    "    if (max_pvalue > .05):\n",
    "        print([max_pname, max_pvalue])\n",
    "        #New_Names.remove(max_pname)\n",
    "        #New_Names_testing = list(np.array(New_Names_testing)[(np.array(New_Names_testing)!=max_pname)])\n",
    "        New_Names = list(np.array(New_Names)[(np.array(New_Names)!=max_pname)])\n",
    "        temp = ['target']\n",
    "        temp.extend(New_Names)\n",
    "        subset = subset[temp]\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40460a2a-3b85-4e98-a95e-792e089b57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c159e1b-117f-48fc-87f8-b402c6310ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_temp = data_final_dask_w_y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f421c1-f54c-4de0-a658-f83efe327bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset[New_Names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1eec-b1c3-4ec2-9c10-4cdd03192cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523b67a-6bd8-46a1-91e7-345d9fc2f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "includes = []\n",
    "for c in subset.columns:\n",
    "    index = np.argwhere(data_final_dask_w_y.columns==c)[0][0]\n",
    "    includes.append(index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12096a-43ea-4eff-aee9-1c47bb6230cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53efc9-e332-4828-b7b3-a8f3cf70118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = train(data_final_dask_w_y[subset.columns].compute().loc[training].dropna())\n",
    "#subset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f337a-3486-4c7e-b469-74ce5d877360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = regress(data_final_dask_w_y[subset.columns].compute().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abd359-b2e1-4af7-9a7d-8a3d17434be0",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
