{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842ae64-4502-42d2-aeab-22d1cd96e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install clustergram pandas_profiling scipy sklearn statsmodels IPython dtale matplotlib rpy2 seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49edd-ccdb-4a5a-9ede-a9b3c081ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in ~/.bashrc\n",
    "#LD_PRELOAD=\"/mnt/distvol/R/4.1.2/lib64/R/lib/LibR.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96046e-bb6b-420f-b6b1-9524e60fe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fracdiff import fdiff\n",
    "#import urbangrammar-graphics as ugg\n",
    "%matplotlib inline\n",
    "import os\n",
    "from clustergram import Clustergram\n",
    "from concurrent.futures import ALL_COMPLETED\n",
    "from concurrent.futures import wait\n",
    "from dask.distributed import as_completed\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import Semaphore\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from numpy import absolute\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from pandas_profiling import ProfileReport\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.utils import diff_inv\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.rinterface_lib import openrlib\n",
    "from scipy import stats\n",
    "from scipy.cluster.vq import vq\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import *\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "from sklearn.utils import as_float_array\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import statsmodels.api as sm\n",
    "import IPython\n",
    "import concurrent.futures\n",
    "import dask.dataframe as dd\n",
    "import datetime\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import pmdarima\n",
    "import pycorrelate\n",
    "import random\n",
    "import re\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.situation\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import shap\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "import sys\n",
    "import time\n",
    "if not sys.warnoptions:\n",
    "\timport warnings\n",
    "\twarnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a8c73-5c94-4d9a-bf1b-9ffbe6836975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = get_config()\n",
    "libpath = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = (\n",
    "    rpy2.situation.r_ld_library_path_from_subprocess(openrlib.R_HOME) +\n",
    "    libpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45c105-205f-4f2b-9526-b8373682df9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465a19f-5039-4627-8b7b-23d0b18f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001  \n",
    "    if p < alpha: \n",
    "        # null hypothesis: x comes from a normal distribution\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def returnYeo (x,training=False):\n",
    "    if(bool(training)):\n",
    "        xt, _ = stats.yeojohnson(x.loc[training])\n",
    "        xt = pd.DataFrame(xt)\n",
    "    else:\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        xt = pd.DataFrame(xt)        \n",
    "    return([xt,_])\n",
    "\n",
    "def regress(dd_df,numCV=2):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    print(\"y needs to be named 'target', regress only uses the variable names, it doesn't use index's.  You apply that using .fit on this functions return\")\n",
    "    #dd_df = data_final\n",
    "    variables=dd_df.columns\n",
    "    target = variables[0]\n",
    "    te = pd.DataFrame(dd_df['target']) \n",
    "    te.index = ([*dd_df.index])\n",
    "    #te.columns = ['target']\n",
    "    col_names = variables[~variables.isin(['target'])].ravel()\n",
    "\n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(col_names)*.05), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=1,\n",
    "              cv=numCV)\n",
    "\n",
    "    return (s_f_s)\n",
    "\n",
    "def last_day_of_month(date):\n",
    "    return date.replace(day=1) + relativedelta(months=1) - relativedelta(days=1)\n",
    "\n",
    "def findknee(xdata):\n",
    "    rate_of_change=(xdata[0]-xdata[-1])/(len(xdata)-1)\n",
    "    #print(rate_of_change)\n",
    "    delta = xdata-xdata[-1]\n",
    "    deltas = []\n",
    "    deltas.append(delta[0])\n",
    "    for d in range(1,len(xdata)):\n",
    "        deltas.append(deltas[d-1]-rate_of_change)\n",
    "    #print(deltas)\n",
    "    for d in range(0,len(xdata)):\n",
    "        deltas[d]=delta[d]-deltas[d]\n",
    "    return(np.abs(deltas))\n",
    "    \n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def formula_from_cols(df, y):\n",
    "    return y + ' ~ ' + ' + '.join([col for col in df.columns if not col==y])\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "#yeho\n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    if (len(data.columns)==1):\n",
    "        inner_scale, l = returnYeo(data)\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)        \n",
    "    else:\n",
    "        for i in range(0,len(data.columns)):\n",
    "            inner_scale, l = returnYeo(data.iloc[:,i])\n",
    "            inner_scale.set_index(data.index)\n",
    "\n",
    "            transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "            transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "\n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, regularization=1e-5, copy=False):\n",
    "      self.regularization = regularization\n",
    "      self.copy = copy\n",
    "  def fit(self, X, y=None):\n",
    "      X = as_float_array(X, copy=self.copy)\n",
    "      self.mean_ = np.mean(X, axis=0)\n",
    "      X = X - self.mean_\n",
    "      sigma = np.dot(X.T, X) / (X.shape[0] - 1)\n",
    "      U, S, V = np.linalg.svd(sigma)\n",
    "      tmp = np.dot(U, np.diag(1 / np.sqrt(S + self.regularization)))\n",
    "      self.components_ = np.dot(tmp, U.T)\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "      X_transformed = X - self.mean_\n",
    "      X_transformed = np.dot(X_transformed, self.components_.T)\n",
    "      return X_transformed\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "    \"\"\"\n",
    "    Cross correlation with a maximum number of lags.\n",
    "\n",
    "    `x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "    The return vaue has length 2*maxlag + 1.\n",
    "    \"\"\"\n",
    "    py = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "    T = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "                   strides=(-py.strides[0], py.strides[0]))\n",
    "    px = np.pad(x, maxlag, mode='constant')\n",
    "    if mode == 'dot':       # get lagged dot product\n",
    "        return T.dot(px)\n",
    "    elif mode == 'corr':    # gets Pearson correlation\n",
    "        return (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "               (np.std(T, axis=1) * np.std(px)) \n",
    "    \n",
    "def train(partition):\n",
    "    est = LinearRegression()\n",
    "    est.fit(partition[New_Names].values, partition['target'])\n",
    "    return est\n",
    "\n",
    "    '''\n",
    "    \n",
    "def nv_diff_sets(v_of_i,dataset,f_casts):\n",
    "\n",
    "  s_=sndif_[which(colnames(raw)==var_of_int)]\n",
    "  d_=ndif_[which(colnames(raw)==var_of_int)]\n",
    "  \n",
    "  startRow = c()\n",
    "  for (r in rownames(dataset[1:d_,,drop=FALSE])):\n",
    "    startRow = c(startRow,which(rownames(raw)==r))\n",
    "  \n",
    "  data_ = c(na.omit(c(dataset[,var_of_int], f_casts)))\n",
    "  \n",
    "  if(s_==0):\n",
    "    inv_d = diffinv(data_,differences=d_,xi=raw[startRow,var_of_int])\n",
    "  else:  \n",
    "    inv_d = diffinv(diffinv(data_,differences = d_, xi=raw[startRow,var_of_int]), differences = s_,xi=raw[startRow:(startRow+season-1),var_of_int])\n",
    "    \n",
    "  return(inv_d)\n",
    "'''\n",
    "#define F-test function\n",
    "def f_test(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    f = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic \n",
    "    dfn = x.size-1 #define degrees of freedom numerator \n",
    "    dfd = y.size-1 #define degrees of freedom denominator \n",
    "    p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic \n",
    "    return f, p\n",
    "\n",
    "def lagpad(x, k):\n",
    "    length=np.full(abs(k), np.NaN)\n",
    "    #print(length)\n",
    "    #k=k-1\n",
    "    if (k>0):\n",
    "        result = np.concatenate([length,x[0:(len(x)-k)]])\n",
    "    elif (k<0):\n",
    "        result= np.concatenate([(x[abs(k):(len(x))]),length])\n",
    "    else:\n",
    "        result= x\n",
    "    return(result)\n",
    "\n",
    "def lag(data):\n",
    "    return lagpad(data,1)\n",
    "\n",
    "def sndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[2]\n",
    "    #print(index)\n",
    "    data = raw_int[name].loc[index]\n",
    "    #print(data)\n",
    "    return([name,pmdarima.arima.nsdiffs(data.dropna(),m=npa_[1])])\n",
    "\n",
    "def ndif_(npa_):\n",
    "    name = npa_[0]\n",
    "    index = npa_[1]\n",
    "    data = deseasoned[name].loc[index]\n",
    "\n",
    "    score = pmdarima.arima.ndiffs(data.dropna())\n",
    "    \n",
    "    if(score==0):\n",
    "        score = 1\n",
    "    return([name,score])\n",
    "\n",
    "def collect():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "def clientFunction(function_name,vars_):\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    future_ = client.map(function_name,vars_)\n",
    "    \n",
    "    results = []\n",
    "    #my intent was to capture future objects vs results and this gave me results\n",
    "    for f_ in as_completed(future_):\n",
    "        if(f_.status==\"error\"):\n",
    "            results.append(\"error\")\n",
    "        else:\n",
    "            results.append(f_.result()) \n",
    "\n",
    "    client.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "def returnElement(v):\n",
    "    return(v[0])\n",
    "\n",
    "def returnResults(v):\n",
    "    return(v[1])\n",
    "\n",
    "def restartClientFunction():\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    client.restart()\n",
    "    client.close()\n",
    "\n",
    "def ts_cv_split (dataset):\n",
    "    #rmse = []\n",
    "\n",
    "    both_ = []\n",
    "    #train_ = []\n",
    "    #test_ = []\n",
    "    for train_index, test_index in tscv.split(outer_dataset.index):\n",
    "        #train_.append(train_index)\n",
    "        #test_.append(test_index)\n",
    "        both_.append([train_index,test_index])    \n",
    "    return(both_)\n",
    "\n",
    "def return_ts_cv_data (indexes):\n",
    "    dataset=outer_dataset\n",
    "    #print(indexes[0])\n",
    "    return([dataset.iloc[indexes[0]],dataset.iloc[indexes[1]]])\n",
    "\n",
    "def cv_pcor_check (npa_):\n",
    "    \n",
    "    #data = npa_\n",
    "    n = npa_[2]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "    #print(npa_[0])\n",
    "    \n",
    "    #dataset= outer_dataset\n",
    "    #train_index = npa_[0]\n",
    "    #print(train_index)\n",
    "    #test_index = npa_[1]\n",
    "    \n",
    "    #I don't need it to do training/test splits, but I had advanced ideas that would apply linear models to a test partition and go with the best error reduction... \n",
    "    # but partial correlations are just that except they don't take into consideration training/test partitions\n",
    "\n",
    "    #target.iloc[training].iloc[train_index]\n",
    "    subset_train = npa_[0]#dataset.iloc[train_index]\n",
    "    train_index = subset_train.index\n",
    "    subset_train = subset_train.dropna()\n",
    "    subset_test = npa_[1]#dataset.iloc[test_index]\n",
    "    #return(subset_test)\n",
    "    test_index = subset_test.index\n",
    "    subset_test = subset_test.dropna()\n",
    "    \n",
    "    y_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train['target'])\n",
    "    y_fore_no_x = y_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    y_resid_no_x = y_fore_no_x.ravel()-subset_test['target']\n",
    "    \n",
    "    x_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], subset_train[n])\n",
    "    x_fore_no_x = x_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    x_resid_no_x = x_fore_no_x.ravel()-subset_test[n]\n",
    "    \n",
    "    cor_resid = pd.concat([pd.DataFrame(y_resid_no_x),pd.DataFrame(x_resid_no_x)],axis=1).corr()\n",
    "    #model_name = ols(formula_from_cols(subset, 'target'),data=data_final_dask_w_y[subset.columns].compute().iloc[train_index]).fit()\n",
    "    #print(model_name.summary())\n",
    "\n",
    "    #skip y and states\n",
    "    #set_ = subset.loc[:, ~subset.columns.isin([target])].columns.tolist()\n",
    "    \n",
    "    c_value = np.array(cor_resid).ravel()[1]\n",
    "    \n",
    "    return(c_value)\n",
    "\n",
    "#correlation p values\n",
    "def pvalues(n):\n",
    "    #n = New_Names[0]\n",
    "    New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "\n",
    "    p_values = pd.DataFrame()\n",
    "    #inner_c_values = []\n",
    "\n",
    "    #outer_dataset is derived from trainings\n",
    "    indexes = ts_cv_split(outer_dataset)\n",
    "    \n",
    "    data = clientFunction(return_ts_cv_data,indexes)\n",
    "    #print(data)\n",
    "    #print(data)\n",
    "    new_data = []\n",
    "    \n",
    "    for d in data:\n",
    "        #print(d[0])\n",
    "        #print(d[1])\n",
    "        #print(n)\n",
    "        new_data.append([d[0],d[1],n])\n",
    "    #inner_c_values = []\n",
    "    #print(new_data[0][0])\n",
    "    #print(cv_pcor_check(new_data[0]))\n",
    "    #here test against holdout data is done\n",
    "    inner_c_values = clientFunction(cv_pcor_check,new_data)\n",
    "    print(inner_c_values)\n",
    "    #loops\n",
    "    \n",
    "    #for d in data:\n",
    "        #inner_c_values.append(cv_pcor_check(d))\n",
    "\n",
    "    n_ = len(indexes[1][0]) \n",
    "\n",
    "    dist = scipy.stats.beta(n_/2 - 1, n_/2 - 1, loc=-1, scale=2)\n",
    "    p_value = 2*dist.cdf(-abs(np.mean(inner_c_values)))\n",
    "    temp = pd.DataFrame([chosen,n,p_value]).T\n",
    "    temp.columns = ['target','test','p']\n",
    "\n",
    "    if(np.isnan(p_value)):\n",
    "        #print(n)\n",
    "        #print(inner_c_values)\n",
    "        p_value = 0\n",
    "    #p_values = pd.concat([p_values,temp],axis=0)\n",
    "    return(p_value)\n",
    "\n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "\n",
    "def undiff(data, seasonal, nonseasonal, xi):\n",
    "    \n",
    "    print(\"you have to know what xi for which use case you are going to use\")\n",
    "    \n",
    "    #nonseasonal\n",
    "    if(nonseasonal!=0 and seasonal==0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,1,nonseasonal)\n",
    "        return(temp_[-len(data):])\n",
    "        \n",
    "    #seasonal\n",
    "    if(seasonal!=0 and nonseasonal == 0):\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        temp_ = diff_inv(temp,season,1)\n",
    "        return(temp_[-len(data):])\n",
    "    \n",
    "    #both\n",
    "    #(for now force seasonal to 1)\n",
    "    if(seasonal==1 and nonseasonal == 1):\n",
    "        \n",
    "        '''\n",
    "        temp = np.concatenate([np.array(xi),np.array(data)])\n",
    "        #print(temp)\n",
    "        temp_ = temp\n",
    "        \n",
    "        print(type(xi))\n",
    "        initial_non_seasonal_delta = xi.iloc[season+nonseasonal]-xi.iloc[season]\n",
    "        print(initial_non_seasonal_delta)\n",
    "        \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        #print(initial_seasonal_delta)\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(temp_)])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "        '''\n",
    "                #temp = data\n",
    "\n",
    "        temp_ = np.concatenate([np.array(xi),np.array(data)])\n",
    "        '''\n",
    "         for s in range(seasonal,0):\n",
    "\n",
    "            print(s)\n",
    "            initial_seasonal_delta = xi.iloc[season*s]-xi.iloc[0]\n",
    "            '''\n",
    "            \n",
    "        initial_seasonal_delta = xi.iloc[season]-xi.iloc[0]\n",
    "        s_diffed_cat = np.concatenate([[np.array(initial_seasonal_delta)],np.array(data.dropna())])\n",
    "\n",
    "        ns_undiffed = diff_inv(s_diffed_cat,1,1)[-len(temp_):]\n",
    "\n",
    "        ns_diffed_cat = np.concatenate([np.array(xi[1:(season+1)]),np.array(ns_undiffed)])\n",
    "        s_undiffed = diff_inv(ns_diffed_cat,season,1)[-len(ns_undiffed):]\n",
    "\n",
    "        return(s_undiffed[-len(data):])\n",
    "\n",
    "    #non seasonal\n",
    "    #undiff(temp_test['target'].dropna(), 0, nonseasonal,[raw_int[chosen].loc[temp_train['target'].index[-1]]])\n",
    "    #test\n",
    "    #undiff(temp_test[chosen],seasonal,nonseasonal,raw_int[chosen].loc[temp_train['target'].index[-1:]])\n",
    "    #train\n",
    "    #train_prior_date = raw_int[chosen].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal]\n",
    "    #train_xi=[raw_int[chosen].loc[train_prior_date]]\n",
    "    #undiff(temp_train['target'], seasonal, nonseasonal,xi)\n",
    "\n",
    "    #seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).dropna(),1,0,raw_int[chosen][0:season])\n",
    "\n",
    "    #non seasonal and seasonal\n",
    "    #undiff(raw_int[chosen].diff(periods=4).diff().dropna(),seasonal,nonseasonal,raw_int[chosen][0:season+nonseasonal])\n",
    "\n",
    "def difference(data, seasonal, nonseasonal):\n",
    "\n",
    "    if seasonal > 0:\n",
    "        return(data.diff(periods=season).diff(nonseasonal))\n",
    "    elif season > 0:\n",
    "        return(data.diff(nonseasonal))\n",
    "    else:\n",
    "        return(data)\n",
    "    \n",
    "'''\n",
    "def do_task_returnCCFs(x, sem):\n",
    "    with sem:\n",
    "        time.sleep(1)\n",
    "        return returnCCFs(x)\n",
    "'''\n",
    "    \n",
    "def fit_sfs_models(npa_):\n",
    "    \n",
    "    #[CCF_names[c],CCF_data[c],CCF_scores[c],CCF_best_lags[c]]\n",
    "\n",
    "    name = npa_[0]\n",
    "    #print(name)\n",
    "    data_final = npa_[1]\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[training].dropna()\n",
    "    temp_test = data_final.loc[testing].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    s_f_s = regress(temp_train)\n",
    "\n",
    "    target = temp_train.columns[0]\n",
    "    #.fit is X, y format\n",
    "    if not sys.warnoptions:\n",
    "        import warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        fitted = s_f_s.fit(temp_train.loc[:, ~temp_train.columns.isin(['target'])], pd.DataFrame(temp_train['target']))\n",
    "        \n",
    "    return([name,fitted])\n",
    "\n",
    "#loads training, testing indexs from host\n",
    "def getDataMetrics(npa_):\n",
    "\n",
    "    name = npa_[0]\n",
    "    #print(name)\n",
    "    data_final = pd.DataFrame(npa_[1])\n",
    "    train = npa_[2]\n",
    "    test = npa_[3]\n",
    "    \n",
    "    #if(str(CCF_package[0][0][2][0])=='nan'):\n",
    "        #return([name,['error','error']])\n",
    "    #else:\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    #if p < .05, we reject the null hypothesis that the two populations have equal variance.\n",
    "    training_vs_holdout_f_test = f_test(temp_train,temp_test)\n",
    "\n",
    "    t_test = []\n",
    "    equal_var = False\n",
    "\n",
    "    if(training_vs_holdout_f_test[1]>.05):\n",
    "        equal_var = True\n",
    "        t_test.append(stats.ttest_ind(temp_train,temp_test,equal_var=True))\n",
    "    else:\n",
    "        t_test.append(stats.ttest_ind(temp_train,temp_test,equal_var=False))\n",
    "\n",
    "    equal_mean = False\n",
    "    #test if equal mean\n",
    "    if(t_test[0][1]>.05):\n",
    "        equal_mean = True\n",
    "        \n",
    "    train_norm = False\n",
    "    test_norm = False\n",
    "    if(testNormal(temp_train)):\n",
    "        train_norm=True\n",
    "        \n",
    "    if(testNormal(temp_test)):\n",
    "        test_norm = True\n",
    "\n",
    "    return([name,[equal_var,equal_mean,[train_norm,test_norm]]])\n",
    "\n",
    "def deriveWinners(npa_):\n",
    "    name = npa_[0]\n",
    "\n",
    "    data_final = npa_[1]\n",
    "\n",
    "    ccf_scores = npa_[2]\n",
    "\n",
    "    best_lags = npa_[3]\n",
    "\n",
    "    models_results_ = npa_[4]\n",
    "    \n",
    "    train = npa_[5]\n",
    "    test = npa_[6]\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "\n",
    "    #model_pos = np.where(models_results_.index==name)[0][0]\n",
    "    #model_pos = np.where(np.array(models_results)==name)[0][0]\n",
    "    \n",
    "    if(str(models_results_)=='nan'):\n",
    "            return([name,'error'])    \n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    #return(name)\n",
    "\n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "    fitted = models_results_[0]\n",
    "\n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "\n",
    "    winners = metric_table[metric_table['avg_score']<(np.std(metric_table['avg_score'])+np.min(metric_table['avg_score']))].tail(1)['feature_names'].index\n",
    "    winners_ = np.asarray(fitted.get_metric_dict()[winners[0]]['feature_names'])\n",
    "\n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_ = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "\n",
    "    return([name,winners_])\n",
    "\n",
    "def log_(x):\n",
    "    x_log = np.log(abs(x))*np.sign(x)\n",
    "    x_log[x.round(2)==0]=0\n",
    "    return(x_log)\n",
    "\n",
    "def unlog(x):\n",
    "    raised = 10 ** x.dropna().round(2)\n",
    "    raised[x.dropna().round(2)==0] = 0\n",
    "    return(raised)\n",
    "\n",
    "def ret_ccf(npa_):\n",
    "    #y_name = npa_[0]\n",
    "    y_name = npa_.columns[0]\n",
    "    x_name = npa_.columns[1]\n",
    "    #x_name = npa_[1]\n",
    "    #index = npa_[2]\n",
    "    index = npa_.index\n",
    "    \n",
    "    #data = cleaned.loc[index].dropna()\n",
    "    data = npa_.loc[index].dropna()\n",
    "    \n",
    "    y = np.array(data.iloc[:,data.columns==y_name]).ravel()\n",
    "    \n",
    "    x = np.array(data.iloc[:,data.columns==x_name]).ravel()\n",
    "    #print(x)\n",
    "    #ccf = statsmodels.tsa.stattools.ccf(x,y)\n",
    "    ccf = crosscorrelation(x,y, ccf_max_lag, mode='corr')\n",
    "    #print(ccf)\n",
    "    return([y_name,x_name,ccf])\n",
    "\n",
    "#uses cleaned (i.e. diffed) as data source \n",
    "def returnCCFs(npa_):\n",
    "    name = npa_[0]\n",
    "    input_data = npa_[1]\n",
    "    #print(input_data)\n",
    "    #chosen = 'LXXRCSA'\n",
    "\n",
    "    ccf_ = []\n",
    "\n",
    "    npa = []\n",
    "\n",
    "    #chosen = cleaned.columns[random.randint(0,len(cleaned.columns)-1)]\n",
    "    #chosen = 'MSPUS'\n",
    "    #chosen = 'LXXRCSA'\n",
    "    \n",
    "    #y_name = input_data.columns[input_data.columns==chosen].values[0]\n",
    "\n",
    "    #x_names = input_data.columns[input_data.columns!=chosen]\n",
    "    \n",
    "    y_name = input_data.columns[input_data.columns==name].values[0]\n",
    "    #x_names = cleaned.columns[(cleaned.columns!=cleaned.columns[0])]\n",
    "    x_names = input_data.columns\n",
    "    #print(x_names)\n",
    "\n",
    "    for s in range(0,len(x_names)):\n",
    "        #y_name = y_name_\n",
    "        x_name = x_names[s]\n",
    "        #print(x_name)\n",
    "        #npa.append([y_name,x_name,training])\n",
    "        #print([y_name,x_name])\n",
    "        npa.append(input_data[[y_name,x_name]])\n",
    "\n",
    "    ccf_ = list(map(ret_ccf,npa))\n",
    "    #clientFunction(ret_ccf,npa)\n",
    "    \n",
    "    #y = np.array(input_data.iloc[:,input_data.columns==y_name]).ravel()\n",
    "    #x = y\n",
    "    #last one is for comparing with itself to ensure 0 lag ccf is 1\n",
    "    #ccf_.append([y_name,y_name,crosscorrelation(x,y, ccf_max_lag, mode='corr')])\n",
    "    #ccf_.append([np.array([y_name,y_name]).reshape(2,1),crosscorrelation(x,y, 4, mode='corr')])#\n",
    "\n",
    "    range_ = [*range(-ccf_max_lag,ccf_max_lag+1)].copy()\n",
    "\n",
    "    ccf_scores = pd.DataFrame()\n",
    "\n",
    "    for c in ccf_:\n",
    "        y = c[0]\n",
    "        x = c[1]\n",
    "        ar_ = pd.DataFrame(c[2])\n",
    "        ar_.index = range_\n",
    "        ar_.columns = [x]\n",
    "        #print(y,x,[ccf_scores,ar_])\n",
    "        ccf_scores = pd.concat([ccf_scores,ar_],axis=1)\n",
    "\n",
    "    #derive optimally lagged dataset\n",
    "\n",
    "    data_final = pd.DataFrame()\n",
    "\n",
    "    best_lags = []\n",
    "    #don't want the last one because it's a repeat of chosen?  causes an error?\n",
    "    #for c in ccf_scores.columns[:-1]:\n",
    "    #run through ccf_scores (which are based on training) and apply to whole dataset\n",
    "    for c in ccf_scores.columns:\n",
    "        #print(c)\n",
    "        temp = ccf_scores[ccf_scores.index>0][c]\n",
    "        bl = ccf_scores.index[ccf_scores.index>0][np.argmax(abs(temp))]\n",
    "        best_lags.append(abs(bl))\n",
    "        data = pd.DataFrame(lagpad(cleaned[c],bl))\n",
    "        data.index = cleaned.index\n",
    "        data.columns = [c]\n",
    "        data_final = pd.concat([data_final,data],axis=1)\n",
    "\n",
    "    #doesn't need to be shift, because all other values are offset by at least 1 lag\n",
    "    temp = pd.DataFrame(cleaned[name])\n",
    "    temp.columns = ['target']\n",
    "    data_final = pd.concat([temp,data_final],axis=1)\n",
    "\n",
    "    return([name, data_final,ccf_scores, best_lags])\n",
    "    #return([name, ccf_,data_final,ccf_scores, best_lags])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ef083-5f57-410b-8c5a-0b476293b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned['CSUSHPINSA'][training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6b876-1953-4937-bc06-3c05123d53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(lagpad(cleaned['T5YIFR'][training],2)).set_index(cleaned['T5YIFR'][training].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3a271-22ea-4418-aeb1-f7a61baa52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(raw_int.columns=='CSUSHPINSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8f442-3084-4c8d-b4e8-09ff479bf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62e042-4e51-48a6-86e1-3e054f6a8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emp = returnCCFs([raw_int.columns[np.where(raw_int.columns=='CSUSHPINSA')][0],cleaned.loc[training]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd5850-59d0-4226-8e9c-57a3e1071c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c692af-7715-4c1e-8bac-14c45a6b7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp[2]['CSUSHPINSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe68fc3-2e5d-4f8b-b715-a9f1755c7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(temp[1].columns)\n",
    "#['CSUSHPINSA'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18d71-3543-40ec-a30c-a23da921c220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b8239-aff7-41e3-a3d8-e4af4ac3d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fcbc9-b5dc-420b-a29e-2d36aebbb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e958a51-c9e2-4aa4-a56a-fa7b21fef44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCV = 2\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "\n",
    "ccf_max_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a75df-bb32-49a6-9fb6-1275c50118bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8522fc-a4da-4a03-a113-ab647a07910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"all_data.csv\",index_col=0)\n",
    "raw.index = pd.to_datetime(raw.index)\n",
    "\n",
    "#fillna(method='bfill')\n",
    "raw_int = raw.interpolate(method='time').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f46ab1-885b-445b-aad6-d4216c46acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381b0b6-e08c-4b8e-ab95-f18116a375e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_test_split(raw_int.index, test_size=.33, random_state=0, shuffle=False)\n",
    "\n",
    "test_sets = []\n",
    "\n",
    "for i in indexes:\n",
    "    test_sets.append(raw_int.index.difference(i))\n",
    "    \n",
    "training = indexes[0]\n",
    "testing = indexes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31cb10-77cb-49e6-95fe-daf9070147a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539ddc5-f4d2-405a-b6b5-463192afa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta = (raw_int-raw_int.shift()).dropna()\n",
    "#raw_delta = (raw_int - raw_int.apply(lag,0)).dropna()\n",
    "#raw_delta.head()\n",
    "\n",
    "#raw_delta.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd80bd-da12-4330-bb5d-fa81b6a9eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3655-065a-4b5f-bf22-1f20181c718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0,len(raw_int.columns)):\n",
    "        \n",
    "#np.max(sndif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a754c9b-7e97-41d4-85be-74b8ea10e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95b5fa-44cc-4ea7-adb1-7f21bd8b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.diff().dropna().apply(pmdarima.arima.nsdiffs(m=4))\n",
    "\n",
    "sndif = []\n",
    "\n",
    "season = 4\n",
    "maxn = season\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],maxn,training])\n",
    "    \n",
    "sndif = clientFunction(sndif_,npa)\n",
    "\n",
    "results_sndif = pd.DataFrame(pd.DataFrame([item[1] for item in sndif])).set_index(item[0] for item in sndif)\n",
    "\n",
    "sndif_results = results_sndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ababf-02b0-4970-8b22-749ccc9fc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sndif_results[sndif_results>1].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5a829-815c-4f59-a37c-30ba2f6f094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sndif_results.loc[sndif_results[sndif_results>1].dropna().index]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72172de8-1877-4150-a2a5-d2c4176d5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sndif_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6555d44-61b8-4a1d-8243-7d90c20a91ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224b0db-c35f-4fd3-b689-f8c48f95ff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f04907-0899-47f3-b0ba-2b49ccd31f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76094108-7c4b-42a8-8165-2e392c6dc8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed4047-3025-4b11-87d3-4de4587550ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510867fd-2eaf-4ca6-b9e5-886d31f91af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fbb73-2973-4ca1-9d6f-e1dee5d9487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't preserve na's...\n",
    "#len(pmdarima.utils.diff(temp,1,1).ravel())\n",
    "\n",
    "deseasoned = pd.DataFrame()\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = sndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    if(compare*season == 0):\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "    else:\n",
    "        #print(compare)\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "        if(compare>0):\n",
    "            for d in range(0,compare):\n",
    "                temp = pd.DataFrame(temp.values.ravel()-lagpad(temp.values.ravel(),1*season)).set_index(temp.index)\n",
    "                temp.columns = raw_int.iloc[:,[i]].columns\n",
    "    deseasoned = pd.concat([deseasoned,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070ea74-f10c-44be-8afa-bcadf80835f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([pd.DataFrame(raw_int[names].columns),pd.DataFrame(raw_int.columns)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c31988-eb80-4626-acf7-b058904f7db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f34f6d-9da4-460f-9f4b-ad79333d480b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f972-961c-4202-aae0-d6d9b3445422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_(npa[0])\n",
    "#sndif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee439e23-992e-4dce-8cad-524c2f95eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif = []\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],training])\n",
    "    \n",
    "ndif = clientFunction(ndif_,npa)    \n",
    "\n",
    "results_ndif = pd.DataFrame(pd.DataFrame([item[1] for item in ndif])).set_index(item[0] for item in ndif)\n",
    "\n",
    "ndif_results = results_ndif.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556689a-0f4e-4111-a5fa-30da2d1985da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaa60d-8804-4476-af02-bc5813637247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2455f-2517-4844-a92d-f0870c4ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876d330-9fc9-484b-8be9-562cebe91ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bbabb-94ff-47b2-8ee3-56fe70ff46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    compare = ndif_results.loc[raw_int.columns[i]][0]\n",
    "    \n",
    "    temp_ = deseasoned[[raw_int.columns[i]]]\n",
    "    colnames = temp_.columns\n",
    "    if compare>0:\n",
    "        #print(ndif[i])\n",
    "        for d in range(0,compare):\n",
    "            #print(d)\n",
    "            #\n",
    "            #print(temp_.columns)\n",
    "            #temp_ = pd.DataFrame(temp_.values.ravel()-lagpad(temp_.values.ravel(),1)).set_index(temp_.index)\n",
    "            #temp_.columns = colnames\n",
    "            #if(d==1):\n",
    "                #print(raw_int.columns[i])\n",
    "            temp_ = temp_.diff()\n",
    "    temp_.columns = deseasoned[[raw_int.columns[i]]].columns\n",
    "    deseasoned_differenced = pd.concat([deseasoned_differenced,temp_],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0674d6d-026c-4d0f-bfb5-6d076165a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6874c8-c189-422d-8743-6d398590d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309a8f4-665b-473b-b35f-ceb1cbcb7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.interpolate(method='time').isna().sum().sum()\n",
    "#.fillna(method='bfill')\n",
    "#raw_int = raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7c307-5b10-4e14-936c-3665c4579e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfebf96-1bd9-41ed-855d-7ada55f8682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40eced-b085-4283-a47d-ca42e2967734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445377f0-481e-4147-8396-662f98b29fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "cleaned = deseasoned_differenced.interpolate(method='time')#.dropna()\n",
    "\n",
    "#cleaned_log = log_(cleaned)#np.log(abs(cleaned))*np.sign(cleaned)\n",
    "#cleaned_log[cleaned.round(2)==0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50144f7-dad5-4eec-ad90-120093d16b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dff07-2cf2-456d-9684-ae29c9628487",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['ASPUS'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa62b7e-72be-431f-bc75-b945481216cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(deseasoned_differenced.interpolate(method='time'),2)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc1b23-ea20-462b-a7eb-187202d5254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c28a1-d38f-4a76-a0e4-6867ccd7fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_log.to_csv(\"cleaned.csv\",index=True, index_label='Date')\n",
    "cleaned.to_csv(\"cleaned.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20c01-c2c8-40d6-9fbe-1e0f65b15b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned = cleaned_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b78028-85ae-436f-808c-1cddf0378cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f822cb-9735-4ddc-b9e9-59cb4cfd1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(skew).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844722f-c44b-4c74-9fa6-30e62bbce479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(kurtosis).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80396d-33c8-41b7-988c-23784d06bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.dropna().apply(adfuller).iloc[1,].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec687a0-fe63-4c31-9c00-fd7fe14afe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc83c74-4729-4b1f-9fd4-6f1ec4f1ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415e0c7-f5dc-4f8d-a5d9-a2b5d7aa9078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8ab6-1c71-465c-8e78-cead6902b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_list = []\n",
    "\n",
    "for c in cleaned.columns:\n",
    "\n",
    "    normal_list.append(testNormal(cleaned[[c]].loc[training].dropna()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94dc80-0ed0-484e-b90b-60b80cf6832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76476328-04a1-42f1-a12b-1e9c748e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = pd.DataFrame()\n",
    "lambdas = []\n",
    "for c in range(0,len(cleaned.columns)):\n",
    "    if(normal_list[c]==1):\n",
    "\n",
    "        newData = pd.concat([newData,cleaned[cleaned.columns[c]]],axis=1)\n",
    "        lambdas.append(0)\n",
    "    else:\n",
    "        train_, l = transform_boxcox(cleaned[[cleaned.columns[c]]].loc[training].dropna())\n",
    "        train_.index = cleaned[[cleaned.columns[c]]].loc[training].dropna().index\n",
    "        test_ = transform_boxcox_l(cleaned[[cleaned.columns[c]]].loc[testing],l)   \n",
    "        \n",
    "        newData = pd.concat([newData,pd.concat([train_,test_])],axis=1)\n",
    "        lambdas.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ababa-7c07-4961-a4ff-57b4455ad8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#plt.plot(newData.dropna().iloc[:,102])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f551c10-3c73-4146-9dad-06d284671e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf510b6-1a26-4b71-a0fe-5930fc33a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv(\"newData.csv\",index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85aaac8-a8e5-4eaf-987b-8d314cff6536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86f1b6-2583-4dfd-98a8-16e07cd6806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num = 10\n",
    "#%matplotlib inline\n",
    "#testNormal(cleaned.iloc[:,num]).dropna().plot.hist()\n",
    "#plt.show()\n",
    "#cleaned.iloc[:,num].dropna().plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c6968-d2c6-4ee8-9fb9-8e0521118c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a320-0a65-4655-a883-7979a533bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb0918-211c-4e91-96d2-ed65662ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are stationary?\n",
    "%matplotlib inline\n",
    "pd.DataFrame(cleaned.dropna().apply(adfuller).iloc[1,]).iloc[:,0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44357db8-49cd-4001-b834-7708f0b0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in cleaned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64a2b4-4999-44c7-a16a-022499effcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6f0e4-00b9-4d1f-a0d5-c96148ba8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.cumsum(x_names=='BOGZ1FL105015105Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10040ac7-710f-4822-ac65-dd624ea1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(cleaned.iloc[:,raw.columns=='BACDINA066MNFRBNY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f5bde-8c64-44d0-97c6-955504a29dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in cleaned.columns:\n",
    "    #print(y_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb03f9-0620-4717-aa8b-d42d540bac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cc7dd-2b41-45c8-8968-0570b4db0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndif_results.loc['NROU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17870b03-f234-4f36-adb6-c072d3ff5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_results.loc['NROU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3842ba-3b4a-4abb-ac5d-2a210de4d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int['NROU'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117df49-d347-468a-a616-8639af7cd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbab82-1828-4023-b9d3-d969a007ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af3d68-47a0-49b7-9d13-22e7af5708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "\n",
    "for c in raw_int.columns:\n",
    "    npa.append([c,cleaned.loc[training]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed004af-9d43-4dd1-87d9-3b80b81b076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "#in order\n",
    "future = client.map(returnCCFs, npa)\n",
    "\n",
    "CCFs_ = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "'''\n",
    "#for chosen in small_set:\n",
    "#    run_analysis(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5392e41-a93f-4e4b-b5d1-b64863cfc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#([name,data_final,ccf_scores, best_lags])\n",
    "#[item[4] for item in CCFs_][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96fdad-1d9b-414f-9792-c49cd4ee6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CCFs_data = pd.DataFrame([item[1] for item in CCFs_]).set_index([[item[0][0][0] for item in CCFs]])\n",
    "CCF_names = [item[0] for item in CCFs_]\n",
    "CCF_data = [item[1] for item in CCFs_]\n",
    "CCF_scores = [item[2] for item in CCFs_]\n",
    "CCF_best_lags = [item[3] for item in CCFs_]\n",
    "\n",
    "#CCFs.columns = ['equal_var','equal_mean']\n",
    "#.loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb830e-ccfd-4206-abf2-5d35bae8abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDataMetrics(CCFs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492690d6-cda1-4207-93cc-ae2c92032abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12160ac-7d89-477a-9d35-6360fcae1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(CCFs[113][0][0][2][0])=='nan'\n",
    "\n",
    "#I don't want to derive metrics on training data\n",
    "\n",
    "indexes_ = train_test_split(cleaned.loc[training].dropna().index, test_size=.5, random_state=0, shuffle=False)\n",
    "\n",
    "npa = []\n",
    "\n",
    "for n in cleaned.columns:\n",
    "    name = n\n",
    "    data = cleaned[n]\n",
    "    train = indexes_[0]\n",
    "    test = indexes_[1]\n",
    "    npa.append([name,data,train,test])\n",
    "\n",
    "metrics = clientFunction(getDataMetrics,npa)\n",
    "\n",
    "'''\n",
    "metrics = []\n",
    "\n",
    "for a in range(0,len(CCFs)):\n",
    "    if(str(CCFs[a][0][0][2][0])=='nan'):\n",
    "        print(a)\n",
    "        print(raw_int.columns[a])\n",
    "        metrics.append('nan')\n",
    "    else:\n",
    "        metrics.append(getDataMetrics(np.array(CCFs)[a]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d365a-810b-410b-a2fc-3ba1dbeb50e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f87df-4385-4067-be9b-a4fa5cbbf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_metrics = pd.DataFrame([item[1] for item in metrics]).set_index([[item[0] for item in metrics]]).loc[raw_int.columns]\n",
    "data_metrics.columns = ['equal_var','equal_mean','normal_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1561-60ed-47cc-b13d-64fbded0713f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd6018-f934-4cfb-a4f5-3e44c2e972ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = np.where(cleaned.columns==chosen)\n",
    "#list(CCFs[pos[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1f770-1fe4-4482-a467-f125e366036f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a09c9d-7b90-4970-80e8-63ea3b53afca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161d336-6dcd-465f-86e5-d26a29a38cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_sfs_models(CCFs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4668ce3-caf9-4a13-9795-8088f967b9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708134a-fba0-4520-a906-551b18de0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pd.concat([pd.DataFrame(cleaned['ASPUS']),pd.DataFrame(lagpad(cleaned['AWHAETP'],-1)).set_index(cleaned['AWHAETP'].index)],axis=1)\n",
    "'''\n",
    "len(training)\n",
    "len(temp.index)\n",
    "\n",
    "temp = pd.concat([pd.DataFrame(cleaned['ASPUS']),pd.DataFrame(lagpad(cleaned['AWHAETP'],0)).set_index(np.array(cleaned['AWHAETP'].index))],axis=1).dropna()\n",
    "temp = temp[(temp.iloc[:,1].index>=training[0])*(temp.iloc[:,1].index<=training[-1])]\n",
    "x = temp.iloc[:,1]\n",
    "y = temp.iloc[:,0]\n",
    "print(crosscorrelation(np.array(x),np.array(y), ccf_max_lag, mode='corr'))\n",
    "print(temp.corr())\n",
    "display(temp)\n",
    "'''\n",
    "\n",
    "#temp.loc[training].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045774ea-e4a4-4619-ae4c-535c5cc34769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fbe647-6922-4274-9781-b76659ea0d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c0246-c14e-41f0-88da-b41f69aa1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa = []\n",
    "\n",
    "#queue size\n",
    "for c in range(0, len(CCFs_)):\n",
    "    npa.append([CCF_names[c],CCF_data[c]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b58a9-9208-4f9a-8c80-27a2c857a767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be6620-ee60-457f-9753-217703cd7824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5b24f-46d3-4713-a377-fe31ac67ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA as ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69099516-9fc4-4257-871d-4d155238a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch parallel\n",
    "distance = 148\n",
    "\n",
    "models_ = []\n",
    "print(len(npa))\n",
    "for r in range(0,(len(raw_int.columns)),distance):\n",
    "    print(r,r+distance)\n",
    "    \n",
    "    #print(npa[r])\n",
    "    #print((npa[r]+distance))\n",
    "    \n",
    "    batchset = npa[r:min(r+distance,len(CCFs_))]\n",
    "    #CCFs_[npa[r]:min(npa[r]+distance,len(CCFs))]\n",
    "\n",
    "    client = Client('192.168.3.100:8786')\n",
    "    #clear ram before starting queue\n",
    "    client.restart()\n",
    "\n",
    "    future = clientFunction(fit_sfs_models, batchset)\n",
    "\n",
    "    for m in future:\n",
    "        models_.append(m)\n",
    "\n",
    "client.close()\n",
    "'''\n",
    "#nonbatch\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "#small_set = random.sample(list(np.sort(cleaned.columns)),4)\n",
    "\n",
    "future = client.map(fit_sfs_models, CCFs, batch_size=64)\n",
    "\n",
    "models_ = client.gather(future)\n",
    "\n",
    "client.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f8173-6f05-438f-9540-c8efa77a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cad131-3bc7-4aea-b391-0119e7de6c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb6d78-cf31-4a12-b28e-f3c8058ec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([item[0] for item in models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312c98c-6b7d-46b9-aba1-d96839a57987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78009921-5472-4085-8e91-8b3e40263aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_models_ = pd.DataFrame([item[1] for item in models_])#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_models_.index = [item[0] for item in models_]\n",
    "\n",
    "models_results = results_models_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bd868-c8a1-4474-abc9-21a8bb279f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2b098-3bd4-496f-a9f4-52a34c4f27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df88414-e90c-44c8-baf9-3cd01687d778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0065-c6f1-4011-9cef-570729ca106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b4431-0885-483f-8dcd-c3b9d8385bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62f9d3-79ac-470d-8150-eceac3506248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7acd51-a0b1-48b1-b102-f5baffecff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#str(models_results.loc[models_results.index[113]].values)=='[nan]'\n",
    "'''\n",
    "start = 0\n",
    "for m in models_results.index:\n",
    "    start = start + 1\n",
    "    print(start)\n",
    "    #if(np.isnan(models_results.loc[m])):\n",
    "    #if(models_results.loc[m]):\n",
    "    print(models_results.loc[m])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71414428-917d-4757-ad2d-e4ab5b4092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_order = []\n",
    "for m in models_results:\n",
    "    if(m[1]=='error'):\n",
    "        print('do nothing')\n",
    "        #model_order.append('error')\n",
    "    else:\n",
    "        model_order.append(m[1])\n",
    "     \n",
    "#valid positions due to error (investigating showed large # of 0's in independent term).    \n",
    "pos = []\n",
    "for m in model_order:\n",
    "    if (m=='error'):\n",
    "        print('do nothing')\n",
    "    else:\n",
    "        pos.append(*np.where(np.array(cleaned.columns)==m)[0])\n",
    "        \n",
    "mask = np.ones(len(cleaned.columns), dtype=bool)\n",
    "mask[pos] = False\n",
    "\n",
    "failedresults = []\n",
    "for m in cleaned.columns[mask]:\n",
    "    failedresults.append(m)\n",
    "                \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa089ada-47d6-46fe-a6a7-c7bd635beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isnan(np.array(models_results)[113][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f8bca-b18f-4aa1-b33a-54f570d5d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models with errors\n",
    "\n",
    "problem_children = []\n",
    "\n",
    "for m in range(0,len(models_results.index)):\n",
    "    if(str(models_results.loc[models_results.index[m]].values)=='[nan]'):\n",
    "        problem_children.append(models_results.index[m])\n",
    "        \n",
    "        #print problematic models\n",
    "#plt.plot(raw_int.loc[:,['USREC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6e31-e8dc-4635-aadb-7e0e6f5f37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problem_children)\n",
    "#for p in problem_children:\n",
    "#    print(np.where(models_results.index==p)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a16f94-59f8-48a1-8837-e13ee3df164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoveredModels = []\n",
    "\n",
    "#check why\n",
    "'''\n",
    "for f in failedresults:\n",
    "    CCF_pos = np.where(np.array(cleaned.columns)==f)[0][0]\n",
    "    #CCFs[CCF_pos]\n",
    "    recoveredModels.append(fit_sfs_models(CCFs[CCF_pos]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370fd8e-ea5b-457d-951d-601e9b95671d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc629167-a16a-4add-9ff1-fa1bbcf6e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[c[0][0][0] for c in CCFs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ee7f9-929e-47be-a8c1-28f9ebbf7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37145b4d-e1ef-4308-b9a5-eecd5578b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dd022-112a-4df6-bf15-82cb9e2d092a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b518132-fc03-4c4d-96a0-dd13a4ee57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380ee71-ce13-4068-acca-0518ad9c574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784616f-bed6-4757-9243-328d3673ab3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a4ee9-aeb3-4d06-9ebb-bf2a7aa17d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c374c-358b-4663-af29-84cdd6118a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for c in range(0,len(CCF_names)):\n",
    "    npa.append([CCF_names[c],CCF_data[c],CCF_scores[c],CCF_best_lags[c],models_results.loc[CCF_names[c]],training,testing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312414cd-da8f-46d3-8bb2-f556d4d0c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npa[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36f618-f6d4-4169-ae95-020c6c3b27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275fe2a-8d23-4eed-a7e9-64c5c09787f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deriveWinners(npa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cc210-f210-4975-8fba-0fbcd5c5d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_ = clientFunction(deriveWinners,npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97711a43-eae4-46e3-9953-b002713df0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_\n",
    "\n",
    "results_winners_ = pd.DataFrame(np.array([item[1] for item in winners_]))#.set_index([item[0] for item in models_])\n",
    "\n",
    "results_winners_.index = [item[0] for item in winners_]\n",
    "\n",
    "winners_results = results_winners_.reindex(raw_int.columns)\n",
    "\n",
    "winners_results.columns = ['winners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989166e3-cf1d-4277-ba15-8799011f836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd17564-5d2c-40ff-b888-e57373a932e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winner_ = \n",
    "#pd.DataFrame([item[1] for item in winner_s]).set_index([[item[0] for item in winner_]]).loc[raw_int.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929194b-5575-45cd-a308-379a80be0cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378030e9-57b7-402b-b2bf-63178dfebc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e9903-a22e-40e1-92b8-b5704f5ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "winners_results = pd.DataFrame([results_winners_]).T\n",
    "winners_results.index = results_winners_index\n",
    "winners_results = winners_results.loc[raw_int.columns]\n",
    "winners_results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10893-9a8f-4790-b2d6-5b3130df0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c74aa-d6f8-4eb1-b5a9-a3792c6a557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels(npa_):\n",
    "    \n",
    "    #[name,winners_,ccf_data,ccf_score,ccf_lags,ndif_results.iloc[c],sndif_results.iloc[c],training,testing]\n",
    "    \n",
    "    name = npa_[0]\n",
    "    \n",
    "    winners_ = npa_[1]\n",
    "    data_final = npa_[2].dropna()\n",
    "    ccf_scores = npa_[3]\n",
    "    best_lags = npa_[4]\n",
    "    nonseasonal = CCF_package = npa_[5]\n",
    "    seasonal = CCF_package = npa_[6]\n",
    "    train = npa_[7]\n",
    "    train = npa_[8]\n",
    "    \n",
    "    if name in problem_children:\n",
    "        return([name,['error','error'],'error','error','error','error','error','error'])\n",
    "\n",
    "    cleaned_name_pos = np.where(np.array(cleaned.columns)==name)[0][0]\n",
    "    \n",
    "    model_pos = np.where(models_results.index==name)[0][0]\n",
    "    \n",
    "    if(str(npa_[1])=='error'):\n",
    "        return([name,['error','error'],'error','error','error','error','error','error'])\n",
    "\n",
    "    #print(data_final).describe()\n",
    "    #data_final = list(data_final)\n",
    "    #.compute().loc[training],training,testing\n",
    "    temp_train = data_final.loc[train].dropna()\n",
    "    temp_test = data_final.loc[test].dropna()\n",
    "\n",
    "    #drop zero variance columns\n",
    "    drop = temp_train.columns[temp_train.apply(np.std)==0]\n",
    "    \n",
    "    temp_train.drop(drop,axis=1,inplace=True)\n",
    "    \n",
    "    lagatposition = []\n",
    "    lagatposition.append([name,0])\n",
    "    for s in range(0,len(winners_)):\n",
    "        #print(winners_[s])\n",
    "        #lagposition.append(np.where(ccf_scores.columns==winners_[s])[0][0])\n",
    "        #print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        #print(best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]])\n",
    "        lagatposition.append([winners_[s],best_lags[np.where(ccf_scores.columns==winners_[s])[0][0]]])\n",
    "\n",
    "    interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "    X_inter = pd.DataFrame(interaction.fit_transform(data_final[winners_].dropna()),columns=interaction.get_feature_names(input_features=data_final[winners_].columns) ).set_index(data_final.dropna().index)\n",
    "    \n",
    "    X_train = sm.add_constant(X_inter).loc[train].dropna()\n",
    "    X_test = sm.add_constant(X_inter).loc[test].dropna()\n",
    "    data_w_inter = pd.concat([data_final['target'],sm.add_constant(X_inter)],axis=1).dropna()\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "\n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=np.int(len(data_w_inter.columns)*.75), \n",
    "              forward=True, \n",
    "              floating=True, \n",
    "              scoring='neg_mean_absolute_percentage_error',\n",
    "              n_jobs=1,\n",
    "              cv=numCV)\n",
    "\n",
    "    data_w_inter_train= data_w_inter.loc[train]\n",
    "    data_w_inter_test= data_w_inter.loc[test]\n",
    "    \n",
    "    fitted = s_f_s.fit(data_w_inter_train.loc[:, ~data_w_inter_train.columns.isin(['target'])], pd.DataFrame(data_w_inter_train['target']))\n",
    "    \n",
    "    metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "    \n",
    "    knee_last = np.min(np.where(np.round([*metric_table['avg_score']],6)==np.round(np.max([*metric_table['avg_score']]),6)))\n",
    "\n",
    "    #elbow method beats the other method predictive wise\n",
    "    temp_df = findknee(np.array(metric_table['avg_score'][0:(knee_last+1)]))\n",
    "    winners_p = np.asarray(metric_table.iloc[np.min(np.where([temp_df==np.max(temp_df)])[1])]['feature_names'])\n",
    "    \n",
    "    #just regular non interactions over training\n",
    "    results_train = sm.OLS(pd.DataFrame(data_w_inter_train['target']),data_w_inter_train[winners_]).fit()\n",
    "    \n",
    "    models = []\n",
    "    models.append(results_train)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    summaries.append(results_train.summary())\n",
    "    \n",
    "    #using polynomial interactions over all data\n",
    "    results_all = sm.OLS(data_w_inter['target'].dropna(),data_w_inter[winners_p]).fit()\n",
    "    \n",
    "    models.append(results_all)\n",
    "\n",
    "    summaries.append(results_all.summary())\n",
    "    \n",
    "    #training, for MAPE\n",
    "    train_forecast = results_train.predict(data_w_inter_train[winners_])\n",
    "    test_forecast = results_train.predict(data_w_inter_test[winners_])\n",
    "\n",
    "    MAPE_in_sample = MAPE(data_w_inter_train['target'],train_forecast)\n",
    "    MAPE_out_sample = MAPE(data_w_inter_test['target'],test_forecast)\n",
    "\n",
    "    inverses = []\n",
    "\n",
    "    inverses.append([name,sndif_results.loc[name][0],ndif_results.loc[name][0]])    \n",
    "\n",
    "    for w in winners_:\n",
    "        inverses.append([w,sndif_results.loc[w][0],ndif_results.loc[w][0]])\n",
    "    \n",
    "    return([name,[MAPE_in_sample,MAPE_out_sample],models,summaries,lagatposition,inverses,data_w_inter,winners_p])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78e55037-21f5-449d-a6af-d44499515f43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e27b7-8ea7-49ed-bb72-0ba4e358fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10958a82-36dc-491b-bbd5-0731c4e29805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815310d1-b261-4a4d-88e9-33da92a6428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for c in range(0,len(CCF_names)):\n",
    "    #ndif_results.iloc[c],sndif_results.iloc[c]\n",
    "    name = CCF_names[c]\n",
    "    ccf_data = CCF_data[c]\n",
    "    ccf_score = CCF_scores[c]\n",
    "    ccf_lags = CCF_best_lags[c]\n",
    "    winners_ = winners_results.loc[raw_int.columns[c]][0]\n",
    "    #model_ = \n",
    "    \n",
    "    npa.append([name,winners_,ccf_data,ccf_score,ccf_lags,ndif_results.iloc[c],sndif_results.iloc[c],training,testing])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c5e54-9d38-4eae-be23-f04fac9bdc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61b075-1fce-4c4d-b0d7-bece865473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = runModels(npa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00648aca-f10e-406b-9092-219e340bf1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ae622-8288-4abd-80f5-0621d2a566af",
   "metadata": {},
   "outputs": [],
   "source": [
    "restartClientFunction()    \n",
    "ranModels = clientFunction(runModels,npa)\n",
    "restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0db97-3ceb-4599-8375-579685399dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sndif_results.loc['MSPUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b0522-41be-486f-a204-de915675fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[item[0] for item in ranModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd72b01-7f97-4f7f-82fc-08ff7544bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranModels[0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a841cc-8c9f-418b-8144-0d8ffb7e20ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44641c-40ea-4d12-bdb5-2f95cb89d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels[2][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d6277-bfd3-4574-b8fb-2c7d2a2c0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for r in range(0,len(ranModels)):\n",
    "#    print(ranModels[r][0])\n",
    "#    print(ranModels[r][5])\n",
    "    \n",
    "#[item[5] for item in ranModels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1bf74-a5bc-4e4e-bc49-0d15f1f6bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(([item[5] for item in ranModels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "df235e65-1b44-4d54-bb38-1d05f4191457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranModels_ = pd.concat([pd.DataFrame([item[1] for item in ranModels]),pd.DataFrame(np.array([item[2] for item in ranModels])),pd.DataFrame(np.array([item[3] for item in ranModels])),pd.DataFrame(np.array([item[4] for item in ranModels])),pd.DataFrame(np.array([item[5] for item in ranModels])),pd.DataFrame(np.array([item[7] for item in ranModels]))],axis=1)\n",
    "\n",
    "ranModels_.index = [item[0] for item in ranModels]\n",
    "\n",
    "ranModels_.columns = ['in-sample-mape','out-sample-mape', 'models', 'summaries','lags','seasonal_non','winners_p']\n",
    "\n",
    "ranModels_ = ranModels_.reindex(raw_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "26488ae2-0876-4171-85c3-c96f47164082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranModels_names = [item[0] for item in ranModels]\n",
    "ranModels_data = np.array([item[6] for item in ranModels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc6fc0-8568-4754-8681-6b99d524f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in ranModels:\n",
    "    #print(i[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e1fb8-5905-44fd-96e2-927325a87b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c114f0a-bd44-4a20-8cc5-06799be05431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(ranModels_['out-sample-mape'].replace([np.inf, -np.inf], np.nan).dropna()=='error')\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0f15a-bfed-41b6-9f61-d3dc5ea6fd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "37b60bc9-0d1d-4967-bf20-8372dbcfa96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ = ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2ad15-550f-4a79-b030-2be97f86374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e82a4e-4cc6-4e94-933a-845c7e14b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "runningTotal = 0\n",
    "values = []\n",
    "for c in range(0,len(cleaned_)):\n",
    "    values.append(float(cleaned_.iloc[c]))\n",
    "    #print(runningTotal)\n",
    "   \n",
    "'''\n",
    "#print(runningTotal/len(cleaned_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7937-26b4-462b-8340-9cc2a1b09a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(values).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d1848-970c-435c-b11d-a230165fca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91ef2b-4a22-41a9-94a9-031e261aa225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "702161dc-506e-4504-a771-3321bc0e8227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'out-sample-mape'}>]], dtype=object)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(cleaned_[cleaned_!=\"error\"])\n",
    "#plt.show()\n",
    "#cleaned_ = cleaned_[cleaned_!=\"error\"]\n",
    "filters_out = ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float).quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')\n",
    "#cleaned_.quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "filters_in = ranModels_[['in-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float).quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')\n",
    "#cleaned_[(cleaned_<=filters.iloc[3]) * (cleaned_>=filters.iloc[1])].hist()\n",
    "#subset = cleaned_[(cleaned_<=filters.iloc[2])]\n",
    "cleaned_[(cleaned_<=filters_out.iloc[2])].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae0b30-ca6e-4b8a-b708-e1d8b696e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0cb65-7fb9-4540-96ca-a02f5bd5f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ranModels_results.dropna())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a67708-db59-4759-96e2-4a8528b5e919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c03b0-dad5-404f-9be7-c0b9fde65e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae111b61-ede2-4d78-8ae5-4b110bbfbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in decent_models:\n",
    "    #print(c)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92af28a-54e8-4242-a414-695bd8aead34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35337139-4dfa-427b-ba48-bde03efe4dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29ff21-918d-46a3-a061-81be3def6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranModels_.iloc[113][0]=='error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd19e32-12d9-4df4-badb-4aef0ca67201",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in = []\n",
    "for x in range(0,len(ranModels_['models'])):\n",
    "    if(ranModels_.iloc[x][0]=='error'):\n",
    "        r_sqr_in.append('error')\n",
    "    else:\n",
    "        #print(ranModels_['in_model'][x].rsquared)\n",
    "        r_sqr_in.append(ranModels_['models'][x][0].rsquared)\n",
    "        \n",
    "r_sqr_full = []\n",
    "for x in range(0,len(ranModels_['models'])):\n",
    "    if(ranModels_.iloc[x][1]=='error'):\n",
    "        r_sqr_full.append('error')\n",
    "    else:\n",
    "        #print(ranModels_['in_model'][x].rsquared)\n",
    "        r_sqr_full.append(ranModels_['models'][x][1].rsquared)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933181f-a81a-4a51-83cb-806236dd67ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377f34-6e0b-429c-b1f7-1b52c6e3819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in_ = pd.DataFrame(r_sqr_in).replace('error',np.nan).set_index(raw_int.columns).dropna()\n",
    "r_sqr_full_ =  pd.DataFrame(r_sqr_full).replace('error',np.nan).set_index(raw_int.columns).dropna()\n",
    "\n",
    "filters = pd.concat([filters_in,filters_out,r_sqr_in_.quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear'),r_sqr_full_.quantile(q=[.02, .09, .25, .5, .75, .91, .98], interpolation='linear')],axis=1)\n",
    "filters.columns = ['in-sample-mape','out-sample-mape','r_sqr_in','r_sqr_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1a696-126c-4b73-8eac-764711d49b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b0352-d2e5-4a25-a276-21697a6206b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242b51a-f6f5-4f45-bd9e-c2c52a9e2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "together = pd.concat([ranModels_[['in-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float),ranModels_[['out-sample-mape']].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().astype(float),r_sqr_in_,r_sqr_full_],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c7445-fc3b-4bc5-8979-e90b82291268",
   "metadata": {},
   "outputs": [],
   "source": [
    "together.columns = ['in-sample-mape','out-sample-mape','r_sqr_in','r_sqr_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b787a8-1664-48d2-a796-6b0c7c809156",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_in_.hist()\n",
    "r_sqr_full_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f2cc7-0166-4692-bb25-133cf36f26ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c9a26-f8f3-4b4e-8340-2d01f1d996d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49c296-b096-40b6-81fc-01502050c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "decent_models = together[((together['out-sample-mape'] <=filters['out-sample-mape'].iloc[3])*(together['r_sqr_in']>=filters['r_sqr_in'].iloc[5]))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5497519-793d-4a7b-98fb-ac53d4420b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decent_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5237a-13eb-4ee5-8c17-3fae30d2d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_results.loc[decent_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68fd40-4f00-4c2e-8e4c-8ff9b4c67778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs[np.where(raw_int.columns=='CSUSHPINSA')[0][0]][1].loc[training].dropna()['DFII10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af465375-9849-45b7-aff0-87c30e090678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544081d-4853-4cf2-84e1-5e46ae72c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vars_ = list()\n",
    "vars_.append('target')\n",
    "for v in [*ranModels_.loc[decent_models].loc['CSUSHPINSA'][2].model.exog_names[1:]]:\n",
    "    vars_.append(v)\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f68f5-9ded-4deb-8291-3adfcf3901f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e8861-78a7-4800-9a36-b0c8ec824bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs_[np.where(raw_int.columns=='CSUSHPINSA')[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c2c50-70e4-4fe3-9176-37c03fcaa47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCFs[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd0c9-4134-449a-82e8-86d3e5fc7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CCFs[np.where(raw_int.columns=='CSUSHPINSA')[0][0]][1].loc[training].dropna()[vars_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012d225-dc4c-4751-b341-ca923a6a6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars = [item[0] for item in ranModels_.loc[decent_models].iloc[m][5]][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0ff71-edd4-4161-a24c-7342adb77e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winners_results,ranModels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ee604-7fb7-4343-96ab-a2e5cbc47ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(CCF_names==decent_models[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2fc96-0fd8-40f3-b7d0-d0079371a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfea0bc-2613-44e0-a031-b2507c73bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][2][1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05370aae-e3f0-468a-a0f4-001cad6b2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(np.array(CCF_names)==CCF_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb76cd-5f73-403b-aa95-41acdefa8ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78bdfb-60fe-4d28-a93a-375b91fc51b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad0efe-e79d-45c0-b17d-6c9d5206c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e0e09-41b7-4e8d-b45a-912ae9029ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ada3e-589a-4771-b805-6a47f8acd7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e3211-c2ab-4bbe-9a4c-14df1df79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_sample_training_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f83fa-6c4c-41f3-8b99-a507514673d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCF_data[np.where(np.array(CCF_names)==CCF_names[ccf_position])[0][0]].loc[training][vars_].dropna().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683d1b1-8914-4cff-8c65-7d1a6d9357bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1111b-93ec-485a-95b2-27478e150fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181e27a-c546-4a7b-8e58-f7d3f1ae4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_metrics.loc[decent_models[m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b982469-c0ef-43d8-986f-c541ae873820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65325df4-27d1-488f-bd70-318dc57cc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    #return([name,[MAPE_in_sample,MAPE_out_sample],models,summaries,lagatposition,inverses])\n",
    "\n",
    "    #seasonal = inverses[0][1][1]\n",
    "    #nonseasonal = inverses[0][2][1]\n",
    "    \n",
    "    #print(season, seasonal, nonseasonal)\n",
    "\n",
    "    #print(raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0])])\n",
    "    \n",
    "    train_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    train_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_train['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    print(train_prior_date)\n",
    "    #print(train_prior_date_1)\n",
    "    train_xi=raw_int[name].loc[train_prior_date:train_prior_date_1]\n",
    "\n",
    "    undiffed_train = pd.DataFrame(undiff(temp_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "    undiffed_train_forecast = pd.DataFrame(undiff(train_forecast, seasonal, nonseasonal, train_xi),columns=['target']).set_index(temp_train.index)\n",
    "\n",
    "    test_prior_date = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    test_prior_date_1 = raw_int[name].index[np.argwhere(data_final.index==temp_test['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "    test_xi = raw_int[name].loc[test_prior_date:test_prior_date_1]\n",
    "\n",
    "    #[raw_int[name].loc[temp_train['target'].index[-1]]]\n",
    "    undiffed_test_forecast = pd.DataFrame(undiff(test_forecast, seasonal, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "    undiffed_test = pd.DataFrame(undiff(temp_test['target'].dropna(), 0, nonseasonal,test_xi),columns=['target']).set_index(temp_test.index)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.plot(raw_int[name])\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_test],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train_forecast,undiffed_test_forecast],axis=0))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_train,undiffed_train_forecast],axis=1))\n",
    "    plt.show()\n",
    "    plt.plot(pd.concat([undiffed_test,undiffed_test_forecast],axis=1))\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_final['target'].dropna().index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi=raw_int[name].loc[prior_date:prior_date_1]\n",
    "\n",
    "    undiffed_ = pd.DataFrame(undiff(data_final['target'].dropna(), seasonal, nonseasonal, xi),columns=['target']).set_index(data_final['target'].dropna().index)\n",
    "\n",
    "    prior_date_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "    prior_date_1_ = raw_int[name].index[np.argwhere(raw_int.index==results.fittedvalues.index[0]).ravel()[0]-1]\n",
    "\n",
    "    xi_=raw_int[name].loc[prior_date_:prior_date_1_]\n",
    "\n",
    "    undiffed_forecast = pd.DataFrame(undiff(results.fittedvalues, seasonal, nonseasonal, xi_),columns=['target']).set_index(results.fittedvalues.index)\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47811b33-7b09-48dd-b43f-1954376163f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e44e0-dbb0-4a1f-beef-da1e8847ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undiff(out_sample_training_prediction, seasonal, nonseasonal,test_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72bd4b-4b8d-484c-bae4-bcb9b4731306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ae215-e4ef-486c-9fdc-9d0924cd9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b20d9-d6ec-48f6-9c13-3d66d263a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac90b15-f698-4f28-ab46-61065e39b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb72163-9f6e-4319-a63e-195552cabfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5df61a-c4ee-4743-a1ba-045d74b1ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c2b6f-bb7b-4bcc-98ad-0ec887a35d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5aab52-0132-45c5-87ed-469c03fd0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c7992-4789-4d68-8834-c47b1527b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranModels_.loc[decent_models].iloc[m][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe3b6e-aa12-4f17-b4b8-cbc3da57109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918c621-06c2-4c5d-acd3-6fae2215fba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b1890-8863-4315-9418-bd7f192e6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonseasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c12dd1-f920-4ba1-9f0f-1b137f6a82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int[name].diff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16aa900-df2d-44b5-88a9-0dcda373593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6e5f6-6662-406e-9bde-e4bb221c7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(undiff(data_['target'].dropna(), seasonal, nonseasonal,train_xi),columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf787-cef0-44d0-b37d-8e4b9468dd36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e837e-469d-4e55-b3a8-7e64ac029479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028177b-ac2b-40b4-bc8e-870eeca9bcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7039f-ff81-4203-9d59-cefee6af6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranModels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "07c858bf-977f-4060-b4e9-6b3cf58d0f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETOTALUSQ176N : target ETOTALUSQ176N LOGC\n",
      "seasonal non: [['ETOTALUSQ176N', 0, 1], ['ETOTALUSQ176N', 0, 1], ['LOGC', 0, 1]]\n",
      "lags: [['ETOTALUSQ176N', 0], ['ETOTALUSQ176N', 1], ['LOGC', 2]]\n",
      "2009-03-31 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.9925595567859333\n",
      "out_sample R2:  0.014359466387315667\n",
      "in sample mape: 4.038587263158572\n",
      "out sample mape: 2.588305770520933\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.993\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.992\n",
      "Method:                 Least Squares   F-statistic:                              1134.\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                    8.10e-19\n",
      "Time:                        02:01:54   Log-Likelihood:                         -88.299\n",
      "No. Observations:                  19   AIC:                                      180.6\n",
      "Df Residuals:                      17   BIC:                                      182.5\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "ETOTALUSQ176N     1.0038      0.021     47.608      0.000       0.959       1.048\n",
      "LOGC              1.5758      3.951      0.399      0.695      -6.761       9.912\n",
      "==============================================================================\n",
      "Omnibus:                       29.790   Durbin-Watson:                   3.062\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.335\n",
      "Skew:                          -2.337   Prob(JB):                     1.07e-14\n",
      "Kurtosis:                      10.709   Cond. No.                         188.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.014\n",
      "Model:                            OLS   Adj. R-squared:                 -0.031\n",
      "Method:                 Least Squares   F-statistic:                    0.3132\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):              0.733\n",
      "Time:                        02:01:54   Log-Likelihood:                -258.12\n",
      "No. Observations:                  46   AIC:                             522.2\n",
      "Df Residuals:                      43   BIC:                             527.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                229.2721     10.476     21.886      0.000     208.146     250.398\n",
      "LOGC                 -18.2852     34.435     -0.531      0.598     -87.731      51.160\n",
      "ETOTALUSQ176N LOGC     0.0664      0.151      0.439      0.663      -0.238       0.371\n",
      "==============================================================================\n",
      "Omnibus:                        9.067   Durbin-Watson:                   0.111\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):                3.342\n",
      "Skew:                          -0.338   Prob(JB):                        0.188\n",
      "Kurtosis:                       1.866   Cond. No.                     1.56e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.56e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept\n",
      "NROU : target DFII10 M2V NROU USSTHPI\n",
      "seasonal non: [['NROU', 0, 1], ['DFII10', 0, 1], ['M2V', 0, 1], ['NROU', 0, 1], ['USSTHPI', 0, 1]]\n",
      "lags: [['NROU', 0], ['DFII10', 3], ['M2V', 1], ['NROU', 1], ['USSTHPI', 3]]\n",
      "2009-06-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.9979935713090361\n",
      "out_sample R2:  0.9975095271557365\n",
      "in sample mape: 4.1163762620656055\n",
      "out sample mape: 5.989020487126978\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.998\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.997\n",
      "Method:                 Least Squares   F-statistic:                              1865.\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                    4.98e-20\n",
      "Time:                        02:02:38   Log-Likelihood:                          120.43\n",
      "No. Observations:                  19   AIC:                                     -232.9\n",
      "Df Residuals:                      15   BIC:                                     -229.1\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "DFII10        -0.0016      0.001     -2.974      0.009      -0.003      -0.000\n",
      "M2V           -0.0027      0.002     -1.485      0.158      -0.007       0.001\n",
      "NROU           1.0307      0.029     35.242      0.000       0.968       1.093\n",
      "USSTHPI     2.506e-05   4.61e-05      0.544      0.594   -7.31e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        2.459   Durbin-Watson:                   0.822\n",
      "Prob(Omnibus):                  0.292   Jarque-Bera (JB):                1.891\n",
      "Skew:                           0.745   Prob(JB):                        0.388\n",
      "Kurtosis:                       2.589   Cond. No.                     1.59e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 1.59e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.998\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.997\n",
      "Method:                 Least Squares   F-statistic:                              5741.\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                    5.57e-56\n",
      "Time:                        02:02:38   Log-Likelihood:                          290.83\n",
      "No. Observations:                  46   AIC:                                     -575.7\n",
      "Df Residuals:                      43   BIC:                                     -570.2\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "NROU             1.0562      0.043     24.569      0.000       0.970       1.143\n",
      "NROU^2           5.0778      4.629      1.097      0.279      -4.257      14.413\n",
      "NROU USSTHPI    -0.0034      0.002     -1.835      0.073      -0.007       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        1.130   Durbin-Watson:                   0.132\n",
      "Prob(Omnibus):                  0.568   Jarque-Bera (JB):                0.993\n",
      "Skew:                           0.142   Prob(JB):                        0.609\n",
      "Kurtosis:                       2.339   Cond. No.                     3.10e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 3.1e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      " ARIMA(2,0,3)(0,0,0)[0]          \n",
      "LQDT : target PSAVERT USPHCI DSEY\n",
      "seasonal non: [['LQDT', 0, 1], ['PSAVERT', 0, 1], ['USPHCI', 0, 2], ['DSEY', 1, 1]]\n",
      "lags: [['LQDT', 0], ['PSAVERT', 3], ['USPHCI', 4], ['DSEY', 3]]\n",
      "2010-06-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.5748165117072681\n",
      "out_sample R2:  0.2943251588482021\n",
      "in sample mape: 643.431473236064\n",
      "out sample mape: 111.5020600754474\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.575\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.495\n",
      "Method:                 Least Squares   F-statistic:                              7.210\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                     0.00281\n",
      "Time:                        02:02:18   Log-Likelihood:                         -30.897\n",
      "No. Observations:                  19   AIC:                                      67.79\n",
      "Df Residuals:                      16   BIC:                                      70.63\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "PSAVERT       -0.1803      0.114     -1.588      0.132      -0.421       0.060\n",
      "USPHCI        -0.1168      0.069     -1.695      0.109      -0.263       0.029\n",
      "DSEY          -0.5727      0.169     -3.399      0.004      -0.930      -0.215\n",
      "==============================================================================\n",
      "Omnibus:                        1.012   Durbin-Watson:                   1.533\n",
      "Prob(Omnibus):                  0.603   Jarque-Bera (JB):                0.804\n",
      "Skew:                          -0.463   Prob(JB):                        0.669\n",
      "Kurtosis:                       2.603   Cond. No.                         3.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.294\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.279\n",
      "Method:                 Least Squares   F-statistic:                              18.77\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                    8.17e-05\n",
      "Time:                        02:02:18   Log-Likelihood:                         -72.671\n",
      "No. Observations:                  46   AIC:                                      147.3\n",
      "Df Residuals:                      45   BIC:                                      149.2\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "DSEY^2         0.0393      0.009      4.332      0.000       0.021       0.058\n",
      "==============================================================================\n",
      "Omnibus:                       40.781   Durbin-Watson:                   1.700\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              163.753\n",
      "Skew:                           2.173   Prob(JB):                     2.76e-36\n",
      "Kurtosis:                      11.158   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      " ARIMA(0,0,0)(0,0,0)[0]          \n",
      "MCD : target IC4WSA WILLLRGCAPVAL MCD\n",
      "seasonal non: [['MCD', 0, 1], ['IC4WSA', 0, 1], ['WILLLRGCAPVAL', 0, 1], ['MCD', 0, 1]]\n",
      "lags: [['MCD', 0], ['IC4WSA', 1], ['WILLLRGCAPVAL', 1], ['MCD', 1]]\n",
      "2008-12-31 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.5427225783202035\n",
      "out_sample R2:  0.5182666738139002\n",
      "in sample mape: 255.9345960503697\n",
      "out sample mape: 75.53964460345668\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.543\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.457\n",
      "Method:                 Least Squares   F-statistic:                              6.330\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                     0.00491\n",
      "Time:                        02:02:18   Log-Likelihood:                         -48.805\n",
      "No. Observations:                  19   AIC:                                      103.6\n",
      "Df Residuals:                      16   BIC:                                      106.4\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "IC4WSA         2.746e-06   1.33e-06      2.067      0.055   -7.01e-08    5.56e-06\n",
      "WILLLRGCAPVAL     0.0006      0.000      1.912      0.074   -6.33e-05       0.001\n",
      "MCD               0.2650      0.321      0.826      0.421      -0.415       0.945\n",
      "==============================================================================\n",
      "Omnibus:                        1.592   Durbin-Watson:                   2.526\n",
      "Prob(Omnibus):                  0.451   Jarque-Bera (JB):                0.457\n",
      "Skew:                           0.324   Prob(JB):                        0.796\n",
      "Kurtosis:                       3.398   Cond. No.                     3.02e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 3.02e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.518\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.485\n",
      "Method:                 Least Squares   F-statistic:                              15.42\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                    5.92e-07\n",
      "Time:                        02:02:18   Log-Likelihood:                         -107.52\n",
      "No. Observations:                  46   AIC:                                      221.0\n",
      "Df Residuals:                      43   BIC:                                      226.5\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "MCD                   0.3410      0.184      1.855      0.070      -0.030       0.712\n",
      "WILLLRGCAPVAL^2    9.659e-08   3.41e-08      2.836      0.007    2.79e-08    1.65e-07\n",
      "WILLLRGCAPVAL MCD -5.064e-05   5.54e-05     -0.914      0.366      -0.000    6.11e-05\n",
      "==============================================================================\n",
      "Omnibus:                        2.023   Durbin-Watson:                   2.299\n",
      "Prob(Omnibus):                  0.364   Jarque-Bera (JB):                1.134\n",
      "Skew:                           0.148   Prob(JB):                        0.567\n",
      "Kurtosis:                       3.710   Cond. No.                     1.30e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 1.3e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      " ARIMA(0,0,1)(0,0,0)[0] intercept\n",
      "MYFW : target TREAST FHN XLB\n",
      "seasonal non: [['MYFW', 0, 1], ['TREAST', 0, 1], ['FHN', 0, 1], ['XLB', 0, 1]]\n",
      "lags: [['MYFW', 0], ['TREAST', 1], ['FHN', 1], ['XLB', 1]]\n",
      "2008-12-31 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.5332177556872997\n",
      "out_sample R2:  0.171752271489801\n",
      "in sample mape: 79.67741627695058\n",
      "out sample mape: 142.5439169167548\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.533\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.446\n",
      "Method:                 Least Squares   F-statistic:                              6.092\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                     0.00575\n",
      "Time:                        02:02:34   Log-Likelihood:                         -68.833\n",
      "No. Observations:                  19   AIC:                                      143.7\n",
      "Df Residuals:                      16   BIC:                                      146.5\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "TREAST      2.732e-05   6.96e-06      3.927      0.001    1.26e-05    4.21e-05\n",
      "FHN           -0.1723      0.443     -0.389      0.703      -1.112       0.767\n",
      "XLB            0.1051      0.281      0.374      0.713      -0.491       0.701\n",
      "==============================================================================\n",
      "Omnibus:                        8.905   Durbin-Watson:                   1.558\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                6.115\n",
      "Skew:                          -1.262   Prob(JB):                       0.0470\n",
      "Kurtosis:                       4.164   Cond. No.                     7.41e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 7.41e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.133\n",
      "Method:                 Least Squares   F-statistic:                     4.458\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):             0.0174\n",
      "Time:                        02:02:34   Log-Likelihood:                -154.86\n",
      "No. Observations:                  46   AIC:                             315.7\n",
      "Df Residuals:                      43   BIC:                             321.2\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.6604      1.184      3.935      0.000       2.272       7.049\n",
      "FHN            0.0623      0.292      0.214      0.832      -0.526       0.650\n",
      "TREAST XLB -1.576e-06   5.53e-07     -2.849      0.007   -2.69e-06   -4.61e-07\n",
      "==============================================================================\n",
      "Omnibus:                        5.224   Durbin-Watson:                   1.396\n",
      "Prob(Omnibus):                  0.073   Jarque-Bera (JB):                6.570\n",
      "Skew:                          -0.099   Prob(JB):                       0.0374\n",
      "Kurtosis:                       4.841   Cond. No.                     2.21e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.21e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      " ARIMA(0,1,1)(0,0,0)[0]          \n",
      "NEAR : target TREAST FHN XLB\n",
      "seasonal non: [['NEAR', 0, 1], ['TREAST', 0, 1], ['FHN', 0, 1], ['XLB', 0, 1]]\n",
      "lags: [['NEAR', 0], ['TREAST', 1], ['FHN', 1], ['XLB', 1]]\n",
      "2008-12-31 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.5332177556872997\n",
      "out_sample R2:  0.17175227169222274\n",
      "in sample mape: 79.67741627695058\n",
      "out sample mape: 142.5439169167548\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.533\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.446\n",
      "Method:                 Least Squares   F-statistic:                              6.092\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                     0.00575\n",
      "Time:                        02:02:54   Log-Likelihood:                         -68.833\n",
      "No. Observations:                  19   AIC:                                      143.7\n",
      "Df Residuals:                      16   BIC:                                      146.5\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "TREAST      2.732e-05   6.96e-06      3.927      0.001    1.26e-05    4.21e-05\n",
      "FHN           -0.1723      0.443     -0.389      0.703      -1.112       0.767\n",
      "XLB            0.1051      0.281      0.374      0.713      -0.491       0.701\n",
      "==============================================================================\n",
      "Omnibus:                        8.905   Durbin-Watson:                   1.558\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                6.115\n",
      "Skew:                          -1.262   Prob(JB):                       0.0470\n",
      "Kurtosis:                       4.164   Cond. No.                     7.41e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 7.41e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.133\n",
      "Method:                 Least Squares   F-statistic:                     4.458\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):             0.0174\n",
      "Time:                        02:02:54   Log-Likelihood:                -154.86\n",
      "No. Observations:                  46   AIC:                             315.7\n",
      "Df Residuals:                      43   BIC:                             321.2\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.6604      1.184      3.935      0.000       2.272       7.049\n",
      "FHN            0.0623      0.292      0.214      0.832      -0.526       0.650\n",
      "TREAST XLB -1.576e-06   5.53e-07     -2.849      0.007   -2.69e-06   -4.61e-07\n",
      "==============================================================================\n",
      "Omnibus:                        5.224   Durbin-Watson:                   1.396\n",
      "Prob(Omnibus):                  0.073   Jarque-Bera (JB):                6.570\n",
      "Skew:                          -0.099   Prob(JB):                       0.0374\n",
      "Kurtosis:                       4.841   Cond. No.                     2.21e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.21e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      " ARIMA(0,1,1)(0,0,0)[0]          \n",
      "SITE : target M1V MICH POP JJU\n",
      "seasonal non: [['SITE', 0, 1], ['M1V', 0, 1], ['MICH', 0, 1], ['POP', 1, 1], ['JJU', 0, 1]]\n",
      "lags: [['SITE', 0], ['M1V', 1], ['MICH', 2], ['POP', 4], ['JJU', 3]]\n",
      "2010-09-30 00:00:00\n",
      "2016-12-31 00:00:00\n",
      "in_sample R2:  0.4706689771627601\n",
      "out_sample R2:  0.07534129392241196\n",
      "in sample mape: 217.00453309987859\n",
      "out sample mape: 117.9768576465537\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.471\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.330\n",
      "Method:                 Least Squares   F-statistic:                              3.334\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                      0.0384\n",
      "Time:                        02:03:06   Log-Likelihood:                         -53.704\n",
      "No. Observations:                  19   AIC:                                      115.4\n",
      "Df Residuals:                      15   BIC:                                      119.2\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "M1V           -3.0742      1.263     -2.433      0.028      -5.767      -0.381\n",
      "MICH          12.5353      6.466      1.939      0.072      -1.246      26.316\n",
      "POP           -0.0004      0.004     -0.108      0.916      -0.008       0.008\n",
      "JJU           -0.1179      0.097     -1.217      0.242      -0.324       0.089\n",
      "==============================================================================\n",
      "Omnibus:                        2.073   Durbin-Watson:                   1.328\n",
      "Prob(Omnibus):                  0.355   Jarque-Bera (JB):                0.884\n",
      "Skew:                           0.509   Prob(JB):                        0.643\n",
      "Kurtosis:                       3.284   Cond. No.                     2.70e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 2.7e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 target   R-squared (uncentered):                   0.075\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.055\n",
      "Method:                 Least Squares   F-statistic:                              3.667\n",
      "Date:                Sun, 16 Jan 2022   Prob (F-statistic):                      0.0619\n",
      "Time:                        02:03:06   Log-Likelihood:                         -142.90\n",
      "No. Observations:                  46   AIC:                                      287.8\n",
      "Df Residuals:                      45   BIC:                                      289.6\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "M1V JJU       -0.5652      0.295     -1.915      0.062      -1.160       0.029\n",
      "==============================================================================\n",
      "Omnibus:                        2.330   Durbin-Watson:                   1.890\n",
      "Prob(Omnibus):                  0.312   Jarque-Bera (JB):                1.368\n",
      "Skew:                           0.260   Prob(JB):                        0.505\n",
      "Kurtosis:                       3.665   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      " ARIMA(0,0,0)(0,0,0)[0]          \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for m in range(0,len(ranModels_.loc[decent_models])):\n",
    "    #if(ranModels_.loc[decent_models].iloc[m][2].rsquared>filters['r_sqr'].iloc[3]):\n",
    "    if(ranModels_.loc[decent_models].iloc[m][2][0].rsquared>filters['r_sqr_in'].iloc[3]):\n",
    "        ccf_position = np.where(np.array(CCF_names) == decent_models[m])[0][0]\n",
    "        name = ranModels_.loc[decent_models].index[m]\n",
    "        #winners_p = ranModels_.loc[decent_models].index[m][7]\n",
    "        #print(data_metrics.loc[name])\n",
    "        vars_ = ['target',*winners_results.loc[name][0]]\n",
    "        #print(winners_results.loc[name][0])\n",
    "        print(name, ':' ,*vars_)\n",
    "        #CCF_data.loc[name]\n",
    "        #dir(runModels(npa[0])[2][0])\n",
    "        print(\"seasonal non:\",ranModels_.loc[decent_models].iloc[m][5])\n",
    "        print(\"lags:\",ranModels_.loc[decent_models].iloc[m][4])\n",
    "        print(CCF_data[ccf_position][vars_].dropna().index[1])\n",
    "        print(training[-1])        \n",
    "        print(\"in_sample R2: \", ranModels_.loc[decent_models].iloc[m][2][0].rsquared)\n",
    "        print(\"out_sample R2: \", ranModels_.loc[decent_models].iloc[m][2][1].rsquared)\n",
    "        print(\"in sample mape:\",ranModels_.loc[decent_models].iloc[m][0])\n",
    "        print(\"out sample mape:\",ranModels_.loc[decent_models].iloc[m][1])        \n",
    "        print(ranModels_.loc[decent_models].iloc[m][3][0])\n",
    "        #ranModels_.loc[decent_models].iloc[m][2][0]\n",
    "        print(ranModels_.loc[decent_models].iloc[m][3][1])\n",
    "        print(auto_arima(ranModels_.loc[decent_models].iloc[m][2][1].resid))\n",
    "        \n",
    "        #print(CCF_data[ccf_position][vars_].dropna().describe())\n",
    "        #in sample training prediction\n",
    "        \n",
    "        ranModels_.loc[decent_models].iloc[m][5]\n",
    "        \n",
    "        seasonal = ranModels_.loc[decent_models].iloc[m][5][0][1]\n",
    "        \n",
    "        nonseasonal = ranModels_.loc[decent_models].iloc[m][5][0][2]\n",
    "        #print(nonseasonal)\n",
    "        #print(\"difference:\", \"seasonal:\", seasonal, \"nonseasonal:\",nonseasonal)\n",
    "        \n",
    "        data_ = ranModels_data[np.where(np.array(ranModels_names)==name)[0][0]]\n",
    "        #CCF_data[np.where(np.array(CCF_names)==CCF_names[ccf_position])[0][0]]\n",
    "        \n",
    "        #data_ = pd.concat([data_['target'],pd.DataFrame(interaction.fit_transform(data_[winners_].dropna()),columns=interaction.get_feature_names(input_features=data_[winners_].columns) )],axis=1)\n",
    "        \n",
    "        #arima_ = auto_arima(data_[name],x=data_[winners_p]),d=0,D=0)\n",
    "        #print(arima_)\n",
    "        \n",
    "        \n",
    "        #print(data_[vars_].dropna())\n",
    "            \n",
    "        '''\n",
    "        data_train = pd.concat([data_.loc[training]['target'],pd.DataFrame(interaction.fit_transform(data_.loc[training][winners_results.loc[name][0]].dropna()),columns=interaction.get_feature_names(input_features=data_.loc[training][winners_results.loc[name][0]].dropna().columns) )],axis=1)\n",
    "        \n",
    "        data_test = pd.concat([data_.loc[testing]['target'],pd.DataFrame(interaction.fit_transform(data_.loc[testing][winners_results.loc[name][0]].dropna()),columns=interaction.get_feature_names(input_features=data_.loc[testing][winners_results.loc[name][0]].dropna().columns) )],axis=1)\n",
    "        \n",
    "        train_prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_train['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "        train_prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_train['target'].index[0]).ravel()[0]-1]\n",
    "        \n",
    "        train_xi=raw_int[name].loc[train_prior_date:train_prior_date_1]\n",
    "        \n",
    "        undiffed_train = pd.DataFrame(undiff(data_train['target'], seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)\n",
    "    \n",
    "        test_prior_date = raw_int[name].index[np.argwhere(raw_int.index==data_test['target'].index[0]).ravel()[0]-nonseasonal-(seasonal*season)]\n",
    "        test_prior_date_1 = raw_int[name].index[np.argwhere(raw_int.index==data_test['target'].index[0]).ravel()[0]-1]\n",
    "\n",
    "        test_xi = raw_int[name].loc[test_prior_date:test_prior_date_1]\n",
    "\n",
    "        in_sample_training_prediction = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_train)\n",
    "        \n",
    "        undiffed_in_sample_training_prediction = pd.DataFrame(undiff(in_sample_training_prediction, seasonal, nonseasonal, train_xi),columns=['target']).set_index(data_train.index)\n",
    "        \n",
    "        #out_sample training prediction\n",
    "        out_sample_training_prediction = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_test)\n",
    "\n",
    "        undiffed_out_sample_training_prediction = pd.DataFrame(undiff(out_sample_training_prediction, seasonal, nonseasonal,test_xi),columns=['target'])\n",
    "        \n",
    "        #training model applied to all data\n",
    "        training_prediction_all_data = ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][0].predict(data_[vars_].dropna())\n",
    "\n",
    "        undiffed_all_training_prediction = np.cumsum(pd.DataFrame(undiff(training_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index))\n",
    "        \n",
    "        #full model all data fit\n",
    "        #inverse log\n",
    "        #full_prediction_all_data = np.cumsum(unlog(ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][1].predict(data_[vars_].dropna())))\n",
    "        full_prediction_all_data = (ranModels_.loc[decent_models].loc[CCF_names[ccf_position]]['models'][1].predict(data_[vars_].dropna()))\n",
    "        \n",
    "        #undiffed_all_full_prediction = np.cumsum(unlog(pd.DataFrame(undiff(full_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        undiffed_all_full_prediction = np.cumsum((pd.DataFrame(undiff(full_prediction_all_data, seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "\n",
    "        #original_data = np.cumsum(unlog(pd.DataFrame(undiff(data_[vars_].dropna()['target'], seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        original_data = np.cumsum((pd.DataFrame(undiff(data_[vars_].dropna()['target'], seasonal, nonseasonal,train_xi),columns=['target']).set_index(data_[vars_].dropna().index)))\n",
    "        \n",
    "        #original_data = cleaned.loc[full_prediction_all_data.index][decent_models[m]]\n",
    "        \n",
    "        #combined = pd.concat([pd.DataFrame(training_prediction_all_data), pd.DataFrame(full_prediction_all_data), pd.DataFrame(original_data)],axis=1)\n",
    "        \n",
    "        combined = pd.concat([pd.DataFrame(undiffed_all_training_prediction), pd.DataFrame(undiffed_all_full_prediction), pd.DataFrame(original_data)],axis=1)\n",
    "        \n",
    "        combined.columns = [\"training\",\"full\",\"original\"]\n",
    "        #plt.plot(original_data)\n",
    "        #plt.plot(training_prediction_all_data)\n",
    "        #plt.plot(full_prediction_all_data)\n",
    "        plt.plot(combined)\n",
    "        plt.legend([\"training\",\"full\",\"original\"],loc='upper left')\n",
    "        \n",
    "        plt.show()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d0f36-2519-448d-8f17-0662fb890d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(ranModels_.loc[decent_models].iloc[m][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28034305-002f-498a-bff6-bb51a9ca0354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac0e15-ed83-4066-a895-1c41dcd207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now sorted by model return pos\n",
    "'''\n",
    "batchSet = np.array(CCFs)[pos]\n",
    "client = Client('192.168.3.100:8786')\n",
    "\n",
    "client.restart()\n",
    "\n",
    "future = client.map(runModels, batchSet,batch_size=64)\n",
    "\n",
    "models_ran = client.gather(future)\n",
    "client.restart()\n",
    "client.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc598c3-4245-4c17-b901-c48bb61f1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2db4d5-b4de-4527-8a5a-6b9e59d2122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train = temp_train[winners_]\n",
    "\n",
    "y_train = temp_train['target']\n",
    "\n",
    "kfold = KFold(n_splits=numCV, shuffle=True)\n",
    "\n",
    "#used for pcorr kfolds as well as best subsets\n",
    "train_ = []\n",
    "test_ = []\n",
    "\n",
    "kfold.get_n_splits(X_train.index)\n",
    "\n",
    "for train_indices, test_indices in kfold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n",
    "\n",
    "threshold = .05\n",
    "\n",
    "set_ = list(winners_)\n",
    "\n",
    "max_pvalue = 1\n",
    "\n",
    "subset = temp_train[np.concatenate([['target'],winners_])]\n",
    "\n",
    "n=len(subset)\n",
    "\n",
    "while(max_pvalue>=threshold):\n",
    "\n",
    "    dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "    p_values = pd.DataFrame(2*dist.cdf(-abs(subset.pcorr()['target']))).T\n",
    "    p_values.columns = list(subset.columns)\n",
    "\n",
    "    max_pname = p_values.idxmax(axis=1)[0]\n",
    "    max_pvalue = p_values[max_pname].values[0]\n",
    "\n",
    "    #print(max_pvalue, max_pname)\n",
    "\n",
    "    #to prevent errors, always return 1 value\n",
    "    if len(set_)==1:\n",
    "        break\n",
    "\n",
    "    if (max_pvalue > threshold):\n",
    "\n",
    "        set_.remove(max_pname)\n",
    "        temp = [target]\n",
    "        temp.extend(set_)\n",
    "        subset = subset[temp]\n",
    "\n",
    "        max_pname=\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31693bd1-5256-45ee-8d2b-8175abe30528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015629e-d203-4586-b48f-35065094fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "small_set = random.sample(list(np.sort(cleaned.columns)),1)\n",
    "\n",
    "runs = []\n",
    "for chosen in small_set:\n",
    "    runs.append(run_analysis(chosen))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698e28f-3010-4e64-9edf-5f359aab2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('chosen', chosen, 'training vs holdout f test for equal variance', training_vs_holdout_f_test[1])\n",
    "'''\n",
    "#CV Plot\n",
    "fig = plot_sfs(fitted.get_metric_dict(), kind='std_err')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.savefig(str(target)+'.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "metric_table = pd.DataFrame(fitted.get_metric_dict()).T\n",
    "#print(metric_table)\n",
    "plt.plot(metric_table['avg_score'])\n",
    "plt.savefig(str(target)+'metric.png', dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "for w in range(0,len(winners_)):\n",
    "    print(winners_[w])\n",
    "    value = np.where(raw_int.columns==winners_[w])[0][0]\n",
    "    print(inverses[w])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==winners_[w])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "\n",
    "\n",
    "print(seasonal)\n",
    "print(nonseasonal)\n",
    "\n",
    "print(chosen,'Population', 'Equal mean:', equal_mean, ', ', 'Population', 'Equal variance:', equal_var)\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "value = np.where(raw_int.columns==chosen)[0][0]\n",
    "\n",
    "#print(\n",
    "print('sndif:', sndif[value])\n",
    "print('ndif:', ndif[value])\n",
    "\n",
    "for w in set_:\n",
    "    plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "    plt.show()        \n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[winners_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n",
    "\n",
    "#for w in winners_:\n",
    "sn.set_theme(style=\"ticks\")\n",
    "\n",
    "t = temp_train[np.concatenate([['target'],winners_])]\n",
    "t_ = t[['target']]\n",
    "t_.columns = ['target2']\n",
    "#t_.rename('target2')\n",
    "t = pd.concat([t,t_],axis=1)\n",
    "sn.pairplot(t, hue=\"target\")\n",
    "#plt.scatter(temp_train[['target']], temp_train[[w]])\n",
    "\n",
    "\n",
    "print(chosen)\n",
    "\n",
    "for s in range(0,len(set_)):\n",
    "    print(np.where(ccf_scores.columns==set_[s])[0][0])\n",
    "\n",
    "print(MAPE(temp_test['target'],test_forecast))\n",
    "\n",
    "index_ = []\n",
    "\n",
    "for w in set_:\n",
    "    print(w)\n",
    "    value = np.where(raw_int.columns==w)[0][0]\n",
    "    index_.append(value)\n",
    "    inverses.append([w,sndif[value],ndif[value]])\n",
    "    print('lags:', best_lags[np.where(ccf_scores.columns==set_[s])[0][0]])\n",
    "    print('sndif:', sndif[value])\n",
    "    print('ndif:', ndif[value])\n",
    "\n",
    "#%matplotlib inline\n",
    "corrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).corr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "\n",
    "pcorrMatrix = pd.concat([temp_train['target'],temp_train[set_]],axis=1).pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(pcorrMatrix, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab30499-2191-4f82-b1ee-a2087973c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d08d6-1f0c-4447-be2d-a3a6b91a1fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e6ab6-e639-4dce-8db4-e29a2d729119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4440f99-f158-43d1-9108-6967fc0122aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77cb1-9235-4db8-ab3e-826f65c44330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0058905-36bc-476c-b52a-b8fde036eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ccf_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543fec-bd07-4bbf-b3d0-b1431bcba01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577961c-4929-4071-8f22-97381fead1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224de44f-3fc4-4630-85ac-622a7d8d3c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35a30-937e-4751-836a-8cf447037e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask = dd.from_pandas(data_final,npartitions=128)\n",
    "#data_final_dask_w_y = dd.concat([cleaned[[y_name]],data_final_dask.compute()],axis=1)\n",
    "#names_ = ['target']\n",
    "#names_.extend(cleaned.columns)\n",
    "#data_final_dask_w_y.columns = names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2b44-72f9-46b4-b3fc-a10c46fd0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask.apply(np.cumsum,axis=1).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce954cbf-4eca-4d46-a2af-afa25e3e88f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13186e-5615-44b8-8593-067501c7fcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2c216-e4cc-4ce5-aead-bcb283cd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c54e-9bd1-4012-b11a-6a28f1cc8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int[chosen])\n",
    "#plt.plot(cleaned[chosen])\n",
    "#plt.plot(data_final_dask_w_y[chosen].compute())\n",
    "#plt.plot(data_final_dask_w_y[['target']].compute().loc[training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2259a1-3d45-43b5-9f1a-4715ed7adf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sort(data_final_dask_w_y.compute().isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a92423-63d4-4d38-85ed-dc9e910eef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17484b9-be53-4ab5-ae8c-1b43b45e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "#pd.concat([target,zca1],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755a17-dfa2-479d-a3f9-d91134239c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fe348-072f-4814-a7c3-af7f24cf7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "newindex = []\n",
    "\n",
    "for i in range(0,len(temp_train.index)):\n",
    "    newindex.append(temp_train.index[i])\n",
    "\n",
    "for i in range(0,nonseasonal):\n",
    "    newindex.append(last_day_of_month(temp_train.index[-1] + pd.DateOffset(90*i)))\n",
    "    \n",
    "len(newindex)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa1c1d-2570-4358-9aae-d501ba283957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51702ec-ba0b-48f1-bdc5-6f22cae90e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "future = client.map(regress, X)\n",
    "\n",
    "results = []\n",
    "best = -1\n",
    "for f in as_completed(future):\n",
    "    results.append(f.result())\n",
    "    \n",
    "def y_subset(df):\n",
    "    \n",
    "    X = list ()\n",
    "    \n",
    "    for var_pos in range(0,len(df.columns)):\n",
    "        variables=df.columns\n",
    "        target=variables[var_pos]\n",
    "        #print(target)\n",
    "        #print(variables.isin([target]))\n",
    "        temp = pd.concat([pd.DataFrame(df[target]),df_.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "        #print(temp)\n",
    "        X.append(temp)\n",
    "    return(X)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0d63e-85ca-449b-8390-aeeecb71313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaler = StandardScaler()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "#scaler.fit(np.array(data_final_dask_w_y[['target']].compute().loc[training]).reshape(-1, 1))\n",
    "\n",
    "New_Names = list(data_final_dask_w_y.columns.difference(['target']))\n",
    "\n",
    "outer_dataset = data_final_dask_w_y.compute().loc[training].dropna()\n",
    "target = outer_dataset[['target']]\n",
    "\n",
    "subset = pd.concat([target,outer_dataset[New_Names]],axis=1)\n",
    "\n",
    "num_folds = 2\n",
    "#kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "#train, test = kfold.get_n_splits(outer_dataset.index)\n",
    "\n",
    "p_threshold = .05\n",
    "\n",
    "iteration = 0\n",
    "max_pvalue = 1\n",
    "\n",
    "while(max_pvalue>=.05):\n",
    "#\n",
    "    print(chosen)\n",
    "    \n",
    "    print(New_Names)\n",
    "    \n",
    "    n_p_values = pd.DataFrame()\n",
    "\n",
    "    p_values = []\n",
    "    \n",
    "    #parallelize here (x16)\n",
    "    for n in New_Names:\n",
    "        #print(n)\n",
    "        New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "        p_values.append(pvalues(n))\n",
    "        \n",
    "    p_values_df = pd.DataFrame(p_values,index=New_Names)\n",
    "    print(p_values_df)\n",
    "\n",
    "    max_pname = New_Names[np.argmax(p_values_df)]\n",
    "    max_pvalue = p_values[np.argmax(p_values_df)]\n",
    "\n",
    "    #n_p_values = pd.concat([n_p_values,p_values],axis=0)\n",
    "    #print(n_p_values)\n",
    "\n",
    "    if (max_pvalue > .05):\n",
    "        print([max_pname, max_pvalue])\n",
    "        #New_Names.remove(max_pname)\n",
    "        #New_Names_testing = list(np.array(New_Names_testing)[(np.array(New_Names_testing)!=max_pname)])\n",
    "        New_Names = list(np.array(New_Names)[(np.array(New_Names)!=max_pname)])\n",
    "        temp = ['target']\n",
    "        temp.extend(New_Names)\n",
    "        subset = subset[temp]\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40460a2a-3b85-4e98-a95e-792e089b57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restartClientFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c159e1b-117f-48fc-87f8-b402c6310ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_temp = data_final_dask_w_y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f421c1-f54c-4de0-a658-f83efe327bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset[New_Names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1eec-b1c3-4ec2-9c10-4cdd03192cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523b67a-6bd8-46a1-91e7-345d9fc2f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "includes = []\n",
    "for c in subset.columns:\n",
    "    index = np.argwhere(data_final_dask_w_y.columns==c)[0][0]\n",
    "    includes.append(index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12096a-43ea-4eff-aee9-1c47bb6230cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53efc9-e332-4828-b7b3-a8f3cf70118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = train(data_final_dask_w_y[subset.columns].compute().loc[training].dropna())\n",
    "#subset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f337a-3486-4c7e-b469-74ce5d877360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = regress(data_final_dask_w_y[subset.columns].compute().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abd359-b2e1-4af7-9a7d-8a3d17434be0",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
