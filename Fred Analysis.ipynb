{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842ae64-4502-42d2-aeab-22d1cd96e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install clustergram pandas_profiling scipy sklearn statsmodels IPython dtale matplotlib rpy2 seaborn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49edd-ccdb-4a5a-9ede-a9b3c081ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in ~/.bashrc\n",
    "#LD_PRELOAD=\"/mnt/distvol/R/4.1.2/lib64/R/lib/LibR.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96046e-bb6b-420f-b6b1-9524e60fe678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fracdiff import fdiff\n",
    "#import urbangrammar-graphics as ugg\n",
    "%matplotlib inline\n",
    "import os\n",
    "from clustergram import Clustergram\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from numpy import absolute\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from pandas_profiling import ProfileReport\n",
    "#from rpy2.robjects import pandas2ri\n",
    "from pmdarima.utils import diff_inv\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.rinterface_lib import openrlib\n",
    "from scipy import stats\n",
    "from scipy.cluster.vq import vq\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "from sklearn.utils import as_float_array\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import IPython\n",
    "import concurrent.futures\n",
    "import dask.dataframe as dd\n",
    "import datetime\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import pmdarima\n",
    "import pycorrelate\n",
    "import random\n",
    "import re\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.situation\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import shap\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a8c73-5c94-4d9a-bf1b-9ffbe6836975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = get_config()\n",
    "libpath = os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = (\n",
    "    rpy2.situation.r_ld_library_path_from_subprocess(openrlib.R_HOME) +\n",
    "    libpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465a19f-5039-4627-8b7b-23d0b18f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula_from_cols(df, y):\n",
    "    return y + ' ~ ' + ' + '.join([col for col in df.columns if not col==y])\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n",
    "\n",
    "class ZCA(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, regularization=1e-5, copy=False):\n",
    "      self.regularization = regularization\n",
    "      self.copy = copy\n",
    "  def fit(self, X, y=None):\n",
    "      X = as_float_array(X, copy=self.copy)\n",
    "      self.mean_ = np.mean(X, axis=0)\n",
    "      X = X - self.mean_\n",
    "      sigma = np.dot(X.T, X) / (X.shape[0] - 1)\n",
    "      U, S, V = np.linalg.svd(sigma)\n",
    "      tmp = np.dot(U, np.diag(1 / np.sqrt(S + self.regularization)))\n",
    "      self.components_ = np.dot(tmp, U.T)\n",
    "      return self\n",
    "  def transform(self, X):\n",
    "      X_transformed = X - self.mean_\n",
    "      X_transformed = np.dot(X_transformed, self.components_.T)\n",
    "      return X_transformed\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "    \"\"\"\n",
    "    Cross correlation with a maximum number of lags.\n",
    "\n",
    "    `x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "    This computes the same result as\n",
    "        numpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "    The return vaue has length 2*maxlag + 1.\n",
    "    \"\"\"\n",
    "    py = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "    T = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "                   strides=(-py.strides[0], py.strides[0]))\n",
    "    px = np.pad(x, maxlag, mode='constant')\n",
    "    if mode == 'dot':       # get lagged dot product\n",
    "        return T.dot(px)\n",
    "    elif mode == 'corr':    # gets Pearson correlation\n",
    "        return (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "               (np.std(T, axis=1) * np.std(px)) \n",
    "    \n",
    "def ret_ccf(npa_):\n",
    "    y_name = npa_[0]\n",
    "    x_name = npa_[1]\n",
    "    data = cleaned.loc[training]\n",
    "    y = np.array(data.iloc[:,data.columns==y_name]).ravel()\n",
    "    \n",
    "    x = np.array(data.iloc[:,data.columns==x_name]).ravel()\n",
    "    #print(x)\n",
    "    #ccf = statsmodels.tsa.stattools.ccf(x,y)\n",
    "    ccf = crosscorrelation(x,y, ccf_max_lag, mode='corr')\n",
    "    #print(ccf)\n",
    "    return([y_name,x_name,ccf])\n",
    "\n",
    "def train(partition):\n",
    "    est = LinearRegression()\n",
    "    est.fit(partition[New_Names].values, partition['target'])\n",
    "    return est\n",
    "\n",
    "\n",
    "def regress (df):\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    variables=df.columns\n",
    "    target = variables[0]\n",
    "    \n",
    "    temp = pd.concat([pd.DataFrame(df[target]),df.loc[:, ~df.columns.isin([target])]],axis=1)\n",
    "\n",
    "    name = str(target)+'.csv'\n",
    "    #print(name)\n",
    "    \n",
    "    s_f_s = sfs(lr, \n",
    "              k_features=len(df.columns)-1, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring='neg_mean_squared_error',\n",
    "              n_jobs=-1,\n",
    "              cv=10)\n",
    "    \n",
    "    s_f_s_f = s_f_s.fit(temp.loc[:, ~temp.columns.isin([target])], pd.DataFrame(temp[target]))\n",
    "    \n",
    "    #temp.to_csv(name)\n",
    "    return(s_f_s_f.get_metric_dict())\n",
    "    '''\n",
    "def nv_diff_sets(v_of_i,dataset,f_casts):\n",
    "\n",
    "  s_=sndif_[which(colnames(raw)==var_of_int)]\n",
    "  d_=ndif_[which(colnames(raw)==var_of_int)]\n",
    "  \n",
    "  startRow = c()\n",
    "  for (r in rownames(dataset[1:d_,,drop=FALSE])):\n",
    "    startRow = c(startRow,which(rownames(raw)==r))\n",
    "  \n",
    "  data_ = c(na.omit(c(dataset[,var_of_int], f_casts)))\n",
    "  \n",
    "  if(s_==0):\n",
    "    inv_d = diffinv(data_,differences=d_,xi=raw[startRow,var_of_int])\n",
    "  else:  \n",
    "    inv_d = diffinv(diffinv(data_,differences = d_, xi=raw[startRow,var_of_int]), differences = s_,xi=raw[startRow:(startRow+season-1),var_of_int])\n",
    "    \n",
    "  return(inv_d)\n",
    "'''\n",
    "\n",
    "def lagpad(x, k):\n",
    "    length=np.full(abs(k), np.NaN)\n",
    "    #print(length)\n",
    "    #k=k-1\n",
    "    if (k>0):\n",
    "        result = np.concatenate([length,x[0:(len(x)-k)]])\n",
    "    elif (k<0):\n",
    "        result= np.concatenate([(x[abs(k):(len(x))]),length])\n",
    "    else:\n",
    "        result= x\n",
    "    return(result)\n",
    "\n",
    "def lag(data):\n",
    "    return lagpad(data,1)\n",
    "\n",
    "def sndif_(npa_):\n",
    "    data = raw_int[npa_[0]]\n",
    "    return(pmdarima.arima.nsdiffs(data.dropna(),m=npa_[1]))\n",
    "\n",
    "def ndif_(npa_):\n",
    "    data = raw_int[npa_[0]]\n",
    "    return(pmdarima.arima.ndiffs(data.dropna()))\n",
    "\n",
    "def clientFunction(function_name,npa):\n",
    "    client = Client('192.168.3.100:8786',timeout=3)\n",
    "    future = client.map(function_name,npa)\n",
    "\n",
    "    results = []\n",
    "    for f in as_completed(future):\n",
    "        if(f.status==\"error\"):\n",
    "            results.append(\"error\")\n",
    "        else:\n",
    "            results.append(f.result())   \n",
    "\n",
    "    client.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6b876-1953-4937-bc06-3c05123d53b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e958a51-c9e2-4aa4-a56a-fa7b21fef44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a75df-bb32-49a6-9fb6-1275c50118bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8522fc-a4da-4a03-a113-ab647a07910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"all_data.csv\",index_col=0)\n",
    "raw.index = pd.to_datetime(raw.index)\n",
    "\n",
    "#fillna(method='bfill')\n",
    "raw_int = raw.interpolate(method='time').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381b0b6-e08c-4b8e-ab95-f18116a375e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539ddc5-f4d2-405a-b6b5-463192afa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta = (raw_int-raw_int.shift()).dropna()\n",
    "#raw_delta = (raw_int - raw_int.apply(lag,0)).dropna()\n",
    "#raw_delta.head()\n",
    "\n",
    "#raw_delta.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd80bd-da12-4330-bb5d-fa81b6a9eac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3655-065a-4b5f-bf22-1f20181c718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(0,len(raw_int.columns)):\n",
    "        \n",
    "#np.max(sndif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95b5fa-44cc-4ea7-adb1-7f21bd8b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_int.diff().dropna().apply(pmdarima.arima.nsdiffs(m=4))\n",
    "\n",
    "sndif = []\n",
    "\n",
    "season = 4\n",
    "maxn = season\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s],maxn, ])\n",
    "    \n",
    "sndif = clientFunction(sndif_,npa)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129f972-961c-4202-aae0-d6d9b3445422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee439e23-992e-4dce-8cad-524c2f95eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndif = []\n",
    "\n",
    "npa = []\n",
    "\n",
    "for s in range(0,len(raw_int.columns)):\n",
    "    npa.append([raw_int.columns[s]])\n",
    "    \n",
    "ndif = clientFunction(ndif_,npa)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556689a-0f4e-4111-a5fa-30da2d1985da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaa60d-8804-4476-af02-bc5813637247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't preserve na's...\n",
    "#len(pmdarima.utils.diff(temp,1,1).ravel())\n",
    "\n",
    "deseasoned = pd.DataFrame()\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    if(sndif[i]*season == 0):\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "    else:\n",
    "        temp = raw_int.iloc[:,[i]]\n",
    "        if(sndif[i]>0):\n",
    "            for d in range(0,sndif[i]):\n",
    "                temp = pd.DataFrame(temp.values.ravel()-lagpad(temp.values.ravel(),1*season)).set_index(temp.index)\n",
    "                temp.columns = raw_int.iloc[:,[i]].columns\n",
    "    deseasoned = pd.concat([deseasoned,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2455f-2517-4844-a92d-f0870c4ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876d330-9fc9-484b-8be9-562cebe91ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bbabb-94ff-47b2-8ee3-56fe70ff46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(raw_int.columns)):\n",
    "    temp_ = deseasoned.iloc[:,[i]]\n",
    "    colnames = temp_.columns\n",
    "    if ndif[i]>0:\n",
    "        #print(ndif[i])\n",
    "        for d in range(0,ndif[i]):\n",
    "            #print(d)\n",
    "            #\n",
    "            #print(temp_.columns)\n",
    "            #temp_ = pd.DataFrame(temp_.values.ravel()-lagpad(temp_.values.ravel(),1)).set_index(temp_.index)\n",
    "            #temp_.columns = colnames\n",
    "            temp = temp_.diff()\n",
    "    temp.columns = temp_.columns\n",
    "    deseasoned_differenced = pd.concat([deseasoned_differenced,temp],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0674d6d-026c-4d0f-bfb5-6d076165a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6874c8-c189-422d-8743-6d398590d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309a8f4-665b-473b-b35f-ceb1cbcb7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.interpolate(method='time').isna().sum().sum()\n",
    "#.fillna(method='bfill')\n",
    "#raw_int = raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7c307-5b10-4e14-936c-3665c4579e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseasoned_differenced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfebf96-1bd9-41ed-855d-7ada55f8682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in deseasoned_differenced.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445377f0-481e-4147-8396-662f98b29fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "cleaned = deseasoned_differenced.interpolate(method='time').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc1b23-ea20-462b-a7eb-187202d5254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(cleaned.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c28a1-d38f-4a76-a0e4-6867ccd7fdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41a320-0a65-4655-a883-7979a533bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb0918-211c-4e91-96d2-ed65662ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are stationary?\n",
    "%matplotlib inline\n",
    "pd.DataFrame(cleaned.apply(adfuller).iloc[1,]).iloc[:,0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44357db8-49cd-4001-b834-7708f0b0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in cleaned.columns:\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64a2b4-4999-44c7-a16a-022499effcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_test_split(cleaned.index, test_size=.5, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ccc9e4-ffe0-4cd2-9c70-0bc191f7b01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce058ee-84b4-4b09-a182-d4ff182ad7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = []\n",
    "\n",
    "for i in indexes:\n",
    "    test_sets.append(cleaned.index.difference(i))\n",
    "    \n",
    "training = indexes[0]\n",
    "testing = indexes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eb77b-84aa-47d2-bbc7-8d12ed27cdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf55c26-fb77-4e3d-a97a-c14faa92b397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdaa71-33d4-4ca8-b0cf-fb7ee258ae7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6f0e4-00b9-4d1f-a0d5-c96148ba8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.cumsum(x_names=='BOGZ1FL105015105Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10040ac7-710f-4822-ac65-dd624ea1cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(cleaned.iloc[:,raw.columns=='BACDINA066MNFRBNY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f5bde-8c64-44d0-97c6-955504a29dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_max_lag = 4\n",
    "\n",
    "#for c in cleaned.columns:\n",
    "    #print(y_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb03f9-0620-4717-aa8b-d42d540bac92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3842ba-3b4a-4abb-ac5d-2a210de4d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_ = []\n",
    "\n",
    "npa = []\n",
    "\n",
    "chosen = cleaned.columns[random.randint(0,len(cleaned.columns)-1)]\n",
    "print(chosen)\n",
    "y_name = cleaned.columns[cleaned.columns==chosen].values[0]\n",
    "#x_names = cleaned.columns[(cleaned.columns!=cleaned.columns[0])]\n",
    "x_names = cleaned.columns\n",
    "\n",
    "for s in range(0,len(x_names)):\n",
    "    #y_name = y_name_\n",
    "    x_name = x_names[s]\n",
    "    #print(x_name)\n",
    "    npa.append([y_name,x_name])\n",
    "    \n",
    "ccf_ = clientFunction(ret_ccf,npa)\n",
    "\n",
    "y = np.array(cleaned.iloc[:,cleaned.columns==y_name]).ravel()\n",
    "x = y\n",
    "#last one is for comparing with itsel to ensure 0 lag ccf is 1\n",
    "ccf_.append([y_name,y_name,crosscorrelation(x,y, ccf_max_lag, mode='corr')])\n",
    "#ccf_.append([np.array([y_name,y_name]).reshape(2,1),crosscorrelation(x,y, 4, mode='corr')])#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d08d6-1f0c-4447-be2d-a3a6b91a1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(cleaned[chosen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4440f99-f158-43d1-9108-6967fc0122aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = [*range(-ccf_max_lag,ccf_max_lag+1)].copy()\n",
    "\n",
    "ccf_scores = pd.DataFrame()\n",
    "\n",
    "for c in ccf_:\n",
    "    #print(c)\n",
    "    y = c[0]\n",
    "    x = c[1]\n",
    "    #print(x)\n",
    "    ar_ = pd.DataFrame(c[2])\n",
    "    #print(ar_)\n",
    "    ar_.index = range_\n",
    "    ar_.columns = [x]\n",
    "    #abs(ar_)\n",
    "    ccf_scores = pd.concat([ccf_scores,ar_],axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77cb1-9235-4db8-ab3e-826f65c44330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0058905-36bc-476c-b52a-b8fde036eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ccf_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543fec-bd07-4bbf-b3d0-b1431bcba01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive optimally lagged dataset\n",
    "\n",
    "data_final = pd.DataFrame()\n",
    "\n",
    "best_lags = []\n",
    "#don't want the last one\n",
    "for c in ccf_scores.columns[:-1]:\n",
    "    temp = ccf_scores[ccf_scores.index>0][c]\n",
    "    bl = ccf_scores.index[ccf_scores.index>0][np.argmax(abs(temp))]\n",
    "    best_lags.append(bl)\n",
    "    data = pd.DataFrame(lagpad(cleaned[c],bl))\n",
    "    data.index = cleaned[c].index\n",
    "    data.columns = [c]\n",
    "    data_final = pd.concat([data_final,data],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35a30-937e-4751-836a-8cf447037e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_dask = dd.from_pandas(data_final,npartitions=128)\n",
    "data_final_dask_w_y = dd.concat([cleaned[[y_name]],data_final_dask.compute()],axis=1)\n",
    "names_ = ['target']\n",
    "names_.extend(cleaned.columns)\n",
    "data_final_dask_w_y.columns = names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2b44-72f9-46b4-b3fc-a10c46fd0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final_dask.apply(np.cumsum,axis=1).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce954cbf-4eca-4d46-a2af-afa25e3e88f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13186e-5615-44b8-8593-067501c7fcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2c216-e4cc-4ce5-aead-bcb283cd801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33c54e-9bd1-4012-b11a-6a28f1cc8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(raw_int[chosen])\n",
    "#plt.plot(cleaned[chosen])\n",
    "#plt.plot(data_final_dask_w_y[chosen].compute())\n",
    "plt.plot(data_final_dask_w_y[['target']].compute().loc[training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2259a1-3d45-43b5-9f1a-4715ed7adf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a92423-63d4-4d38-85ed-dc9e910eef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17484b9-be53-4ab5-ae8c-1b43b45e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "\n",
    "zca1_subset = working_set[subset.columns.difference(['target',max_pname])].dropna()\n",
    "zca1 = zca.fit(zca1_subset)\n",
    "zca1_df = pd.DataFrame(zca1.transform(zca1_subset))\n",
    "zca1_df.columns = zca1_subset.columns\n",
    "zca1_df.index = zca1_subset.index\n",
    "#pd.concat([target,zca1],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd5876-0407-4d06-adc3-bb6e5d3ad84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620eabbd-bca0-4db4-a177-911270eeb318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada8bae-5194-4301-9cab-f75007eed0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New_Names[np.argmax(np.array(New_Names)==chosen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7720a-d946-427e-9a0b-24e8566f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = New_Names[3]\n",
    "#New_Names==n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37831a7d-5759-4f4c-8eef-5aca739e9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New_Names = (data_final_dask_w_y.columns.difference(['target']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51702ec-ba0b-48f1-bdc5-6f22cae90e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6903e8-322d-41b5-ae6f-2331ce3db115",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7be78e-c5fa-4b06-a21e-ec6603c89ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cbe3e-d83f-41f8-b5ac-58bb18769597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "rmse = []\n",
    "\n",
    "both_ = []\n",
    "#train_ = []\n",
    "#test_ = []\n",
    "for train_index, test_index in tscv.split(outer_dataset.index):\n",
    "    #train_.append(train_index)\n",
    "    #test_.append(test_index)\n",
    "    both_.append([train_index,test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c779b82-baa1-4498-877c-d5aebc75d889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5076e339-e72a-4e97-9560-bcc2ea1ef810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split (dataset):\n",
    "    both_ = []\n",
    "    #train_ = []\n",
    "    #test_ = []\n",
    "    for train_index, test_index in tscv.split(outer_dataset.index):\n",
    "        #train_.append(train_index)\n",
    "        #test_.append(test_index)\n",
    "        both_.append([train_index,test_index])    \n",
    "    return(both_)\n",
    "\n",
    "def cv_check (npa_):\n",
    "    dataset= outer_dataset\n",
    "    train_index = npa_[0]\n",
    "    #print(train_index)\n",
    "    test_index = npa_[1]\n",
    "    #I don't need it to do training/test splits, but I had advanced ideas that would apply linear models to a test partition and go with the best error reduction... \n",
    "    # but partial correlations are just that except they don't take into consideration training/test partitions\n",
    "\n",
    "    #target.iloc[training].iloc[train_index]\n",
    "    subset_train = dataset.iloc[train_index]\n",
    "    subset_test = dataset.iloc[test_index]\n",
    "\n",
    "    dist = scipy.stats.beta(n_/2 - 1, n_/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "    y_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], target.iloc[train_index])\n",
    "    y_fore_no_x = y_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    y_resid_no_x = y_fore_no_x.ravel()-subset_test['target']\n",
    "\n",
    "    x_reg_train_no_x = LinearRegression().fit(subset_train[New_Names_testing], target.iloc[train_index])\n",
    "    x_fore_no_x = x_reg_train_no_x.predict(subset_test[New_Names_testing])\n",
    "    x_resid_no_x = x_fore_no_x.ravel()-subset_test[n]\n",
    "\n",
    "    cor_resid = pd.concat([pd.DataFrame(y_resid_no_x),pd.DataFrame(x_resid_no_x)],axis=1).corr()\n",
    "    #model_name = ols(formula_from_cols(subset, 'target'),data=data_final_dask_w_y[subset.columns].compute().iloc[train_index]).fit()\n",
    "    #print(model_name.summary())\n",
    "\n",
    "    #skip y and states\n",
    "    #set_ = subset.loc[:, ~subset.columns.isin([target])].columns.tolist()\n",
    "\n",
    "    c_value = np.array(cor_resid).ravel()[1]\n",
    "\n",
    "    return(c_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e5daff40-348c-4722-b1ae-1f333c984e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4314668649612061,\n",
       " 0.14602706807003135,\n",
       " 0.9194595627649033,\n",
       " 0.9996928696052728,\n",
       " 0.9970097928413545]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78134a5-fcd5-48a4-aba8-3b82c8fb8c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b0f0d63e-85ca-449b-8390-aeeecb71313f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38996/1533055975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#inner_c_values = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0minner_c_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclientFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mn_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38996/1225314592.py\u001b[0m in \u001b[0;36mclientFunction\u001b[0;34m(function_name, npa)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclientFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnpa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'192.168.3.100:8786'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnpa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/py39_jupyterlab/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, key, workers, retries, resources, priority, allow_other_workers, fifo_timeout, actor, actors, pure, batch_size, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m         \u001b[0minternal_priority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m         futures = self._graph_to_futures(\n\u001b[0m\u001b[1;32m   1774\u001b[0m             \u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/py39_jupyterlab/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_graph_to_futures\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, priority, user_priority, resources, retries, fifo_timeout, actors)\u001b[0m\n\u001b[1;32m   2642\u001b[0m                     \u001b[0;34m\"fifo_timeout\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfifo_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2643\u001b[0m                     \u001b[0;34m\"actors\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2644\u001b[0;31m                     \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_computation_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2645\u001b[0m                 }\n\u001b[1;32m   2646\u001b[0m             )\n",
      "\u001b[0;32m/mnt/distvol/py39_jupyterlab/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_get_computation_code\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m   2570\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2572\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2573\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2574\u001b[0m                 \u001b[0;31m# Try to fine the source if we are in %%time or %%timeit magic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.9/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     OSError is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m-> 1024\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.9/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m   1005\u001b[0m     \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mistraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.9/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    815\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.9/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.9/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# Copy sys.modules in order to cope with changes while iterating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "#scaler.fit(np.array(data_final_dask_w_y[['target']].compute().loc[training]).reshape(-1, 1))\n",
    "\n",
    "New_Names = list(data_final_dask_w_y.columns.difference(['target']))\n",
    "\n",
    "outer_dataset = data_final_dask_w_y.compute().loc[training].dropna()\n",
    "target = outer_dataset[['target']]\n",
    "\n",
    "subset = pd.concat([target,outer_dataset[New_Names]],axis=1)\n",
    "\n",
    "num_folds = 2\n",
    "#kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "#train, test = kfold.get_n_splits(outer_dataset.index)\n",
    "\n",
    "p_threshold = .05\n",
    "\n",
    "iteration = 0\n",
    "max_pvalue = 1\n",
    "\n",
    "while(max_pvalue>=.05):\n",
    "    #\n",
    "    n_p_values = pd.DataFrame()\n",
    "    \n",
    "    #parallelize here (x16)\n",
    "    for n in New_Names:\n",
    "\n",
    "        New_Names_testing = list(np.array(New_Names)[(np.array(New_Names)!=n)])\n",
    "        \n",
    "        p_values = pd.DataFrame()\n",
    "        #inner_c_values = []\n",
    "        \n",
    "        inner_c_values = clientFunction(cv_check,cv_split(outer_dataset))   \n",
    "   \n",
    "        n_ = len(subset_test) \n",
    "\n",
    "        p_value = 2*dist.cdf(-abs(np.mean(inner_c_values)))\n",
    "        temp = pd.DataFrame([chosen,n,p_value]).T\n",
    "        temp.columns = ['target','test','p']\n",
    "\n",
    "        p_values = pd.concat([p_values,temp],axis=0)\n",
    "\n",
    "        #print(p_values)\n",
    "        #p_values_train = \n",
    "        #p_values_test = pd.DataFrame(2*dist.cdf(-abs(subset_test.pcorr()['target']))).T\n",
    "\n",
    "        #p_values = (p_values_train + p_values_test)/2\n",
    "        #p_values.columns = list(subset.columns)\n",
    "\n",
    "        #max_pname = p_values.idxmax(axis=1)[0]\n",
    "        #max_pvalue = p_values[max_pname].values[0]\n",
    "\n",
    "        #check correlation of residuals\n",
    "        #print(p_values)\n",
    "    n_p_values = pd.concat([n_p_values,p_values],axis=0)\n",
    "    print(n_p_values)\n",
    "    '''\n",
    "    if (max_pvalue > .05):\n",
    "        print([max_pname, max_pvalue])\n",
    "        #New_Names.remove(max_pname)\n",
    "        New_Names_testing = list(np.array(New_Names_testing)[(np.array(New_Names_testing)!=max_pname)])\n",
    "        temp = ['target']\n",
    "        temp.extend(New_Names_testing)\n",
    "        subset = subset[temp]\n",
    "    '''\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40460a2a-3b85-4e98-a95e-792e089b57ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c159e1b-117f-48fc-87f8-b402c6310ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_final_dask_w_y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f421c1-f54c-4de0-a658-f83efe327bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[New_Names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c1eec-b1c3-4ec2-9c10-4cdd03192cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(New_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403cde6-b5a7-45fb-a203-1c3973fd6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= ols(formula_from_cols(data_temp[New_Names], 'target'),data=data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d283b-526f-49ca-a7af-d846cd34611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523b67a-6bd8-46a1-91e7-345d9fc2f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "includes = []\n",
    "for c in subset.columns:\n",
    "    index = np.argwhere(data_final_dask_w_y.columns==c)[0][0]\n",
    "    includes.append(index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12096a-43ea-4eff-aee9-1c47bb6230cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "corrMatrix = data_final_dask_w_y[subset.columns].compute().loc[training].dropna().pcorr().sort_values(kind=\"quicksort\", by='target', ascending=False,key=abs)\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53efc9-e332-4828-b7b3-a8f3cf70118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = train(data_final_dask_w_y[subset.columns].compute().loc[training].dropna())\n",
    "#subset.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f337a-3486-4c7e-b469-74ce5d877360",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = regress(data_final_dask_w_y[subset.columns].compute().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8468939-ef88-4d8d-888f-fcdcf4d6e56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3e79d-be9b-4bcb-8923-b06fd610c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = subset.iloc[training]#subset.columns[1:]\n",
    "#print(variables[f])\n",
    "target=variables['target']\n",
    "fig = plot_sfs(reg, kind='std_err')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "#plt.savefig(str(target)+'.png', dpi=300, format='png', bbox_inches='tight')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef0a23-cc34-46c4-955f-5a69fec7693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = ols(formula_from_cols(subset, 'target'),data=data_final_dask_w_y[subset.columns].compute().dropna()).fit()\n",
    "model_name.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb85240-3752-466c-af1d-424719623c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af1a53-2324-4020-a6b7-7efa30315497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fab17-ac5e-4e68-86e6-f202f0a33a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
